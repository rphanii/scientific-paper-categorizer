abstract,category
"We investigated the effect of performing a mental arithmetic task with two levels of difficulty on the regulation of centre of foot pressure (COP) displacements during bipedal quiet standing in young healthy individuals. There was also a control condition in which no concurrent task was required. A space-time-domain analysis showed decreased COP displacements, along the antero-posterior axis, when participants concurrently performed the most difficult mental arithmetic task. Frequency-domain and stabilogram-diffusion analyses further suggested these decreased COP displacements to be associated with an increased stiffness and a reduction of the exploratory behaviours in the short term, respectively.",Biology
"Tethered particle motion is an experimental technique to monitor conformational changes in single molecules of DNA in real time, by observing the position fluctuations of a micrometer-size particle attached to the DNA. This article reviews some recent work on theoretical problems inherent in the interpretation of TPM experiments, both in equilibrium and dynamical aspects.",Biology
"We introduce and analyze a waiting time model for the accumulation of genetic changes. The continuous time conjunctive Bayesian network is defined by a partially ordered set of mutations and by the rate of fixation of each mutation. The partial order encodes constraints on the order in which mutations can fixate in the population, shedding light on the mutational pathways underlying the evolutionary process. We study a censored version of the model and derive equations for an EM algorithm to perform maximum likelihood estimation of the model parameters. We also show how to select the maximum likelihood poset. The model is applied to genetic data from different cancers and from drug resistant HIV samples, indicating implications for diagnosis and treatment.",Biology
"Cooperation plays a key role in the evolution of complex systems. However, the level of cooperation extensively varies with the topology of agent networks in the widely used models of repeated games. Here we show that cooperation remains rather stable by applying the reinforcement learning strategy adoption rule, Q-learning on a variety of random, regular, small-word, scale-free and modular network models in repeated, multi-agent Prisoners Dilemma and Hawk-Dove games. Furthermore, we found that using the above model systems other long-term learning strategy adoption rules also promote cooperation, while introducing a low level of noise (as a model of innovation) to the strategy adoption rules makes the level of cooperation less dependent on the actual network topology. Our results demonstrate that long-term learning and random elements in the strategy adoption rules, when acting together, extend the range of network topologies enabling the development of cooperation at a wider range of costs and temptations. These results suggest that a balanced duo of learning and innovation may help to preserve cooperation during the re-organization of real-world networks, and may play a prominent role in the evolution of self-organizing, complex systems.",Biology
"Random networks with specified degree distributions have been proposed as realistic models of population structure, yet the problem of dynamically modeling SIR-type epidemics in random networks remains complex. I resolve this dilemma by showing how the SIR dynamics can be modeled with a system of three nonlinear ODE's. The method makes use of the probability generating function (PGF) formalism for representing the degree distribution of a random network and makes use of network-centric quantities such as the number of edges in a well-defined category rather than node-centric quantities such as the number of infecteds or susceptibles. The PGF provides a simple means of translating between network and node-centric variables and determining the epidemic incidence at any time. The theory also provides a simple means of tracking the evolution of the degree distribution among susceptibles or infecteds. The equations are used to demonstrate the dramatic effects that the degree distribution plays on the final size of an epidemic as well as the speed with which it spreads through the population. Power law degree distributions are observed to generate an almost immediate expansion phase yet have a smaller final size compared to homogeneous degree distributions such as the Poisson. The equations are compared to stochastic simulations, which show good agreement with the theory. Finally, the dynamic equations provide an alternative way of determining the epidemic threshold where large-scale epidemics are expected to occur, and below which epidemic behavior is limited to finite-sized outbreaks.",Biology
"Two simple mathematical models of electric neuro-stimulation are derived and discussed. It is found that the common injected-charge model is less realistic than a model, in which a latency period, which follows after a short electric pulse, plays a role as important as the electric pulse. A stimulation signal is proposed that takes advantage of these findings and calls for experimental testing.",Biology
"This paper has been withdrawn by the author(s), due to the requirement of the journal it currently submitted to",Biology
"We predict various detectable mechanical responses to the presence of local DNA defects which are defined as short DNA segments exhibiting mechanical properties obviously different from the 50 nm persistence length based semiflexible polymer model. The defects discussed are kinks and flexible hinges either permanently fixed on DNA or thermally excited. Their effects on extension shift, the effective persistence length, the end-to-end distance distribution, and the cyclization probability are computed using a transfer-matrix method. Our predictions will be useful in future experimental designs to study DNA nicks or mismatch base pairs, mechanics of specific DNA sequences, and specific DNA-protein interaction using magnetic tweezer, fluorescence resonance energy transfer or plasmon resonance technique, and the traditional biochemistry cyclization probability measurements.",Biology
"As the past decade barely dawned, a fundamentally novel view of cancer relating to signal transduction through intracellular hormones/growth factors and their subunits began to unfold. Further along, it gained additional substance with the advent of the interdisciplinary fields of particle biology and peptide strings which explain (onco)protein dynamics in spacetime, for instance insulin-driven sub- and trans-cellular carcinogenesis, by physical principles. Here, this new understanding is expanded to introduce the concept of ""oncoprotein metastasis"" preceding cancer cell spread and, thereby, a particular emphasis is placed on its potential role in the emergence of the pre-metastatic niche. Consistent with this perception, yet unlike currently advocated treatments that target cancer cells only, future antineoplastic strategies should aim to mimic natural tumor suppressors as well as involve both (morphologically) normal and malignant cells. If validated in human patients with advanced cancer disease, its otherwise frequently lethal course may be halted and reversed just in time.",Biology
"The diversity of virus populations within single infected hosts presents a major difficulty for the natural immune response as well as for vaccine design and antiviral drug therapy. Recently developed pyrophosphate based sequencing technologies (pyrosequencing) can be used for quantifying this diversity by ultra-deep sequencing of virus samples. We present computational methods for the analysis of such sequence data and apply these techniques to pyrosequencing data obtained from HIV populations within patients harboring drug resistant virus strains. Our main result is the estimation of the population structure of the sample from the pyrosequencing reads. This inference is based on a statistical approach to error correction, followed by a combinatorial algorithm for constructing a minimal set of haplotypes that explain the data. Using this set of explaining haplotypes, we apply a statistical model to infer the frequencies of the haplotypes in the population via an EM algorithm. We demonstrate that pyrosequencing reads allow for effective population reconstruction by extensive simulations and by comparison to 165 sequences obtained directly from clonal sequencing of four independent, diverse HIV populations. Thus, pyrosequencing can be used for cost-effective estimation of the structure of virus populations, promising new insights into viral evolutionary dynamics and disease control strategies.",Biology
"In this paper, we analyze the electrotactic movement of Dictyostelium discoideum from the viewpoint of non-equilibrium statistical mechanics. Because we can observe fluctuating behavior of cellular trajectories, we analyze the probability distribution of the trajectories with the aid of the fluctuation theorem. Recently, the validity of the fluctuation theorem was verified in a colloidal system, and it has also been applied to granular systems, turbulent systems and chemical oscillatory waves to investigate some of their statistical properties that are not yet completely understood. Noting that the fluctuation theorem is potentially applicable to cellular electrotaxis, here we employ it to help us obtain a phenomenological model of this biological system.",Biology
"The problem of intermediates in the fossil record has been frequently discussed ever since Darwin. The extent of `gaps' (missing transitional stages) has been used to argue against gradual evolution from a common ancestor. Traditionally, gaps have often been explained by the improbability of fossilization and the discontinuous selection of found fossils. Here we take an analytical approach and demonstrate why, under certain sampling conditions, we may not expect intermediates to be found. Using a simple null model, we show mathematically that the question of whether a taxon sampled from some time in the past is likely to be morphologically intermediate to other samples (dated earlier and later) depends on the shape and dimensions of the underlying phylogenetic tree that connects the taxa, and the times from which the fossils are sampled.",Biology
"Degeneracy of the genetic code is a biological way to minimize effects of the undesirable mutation changes. Degeneration has a natural description on the 5-adic space of 64 codons $\mathcal{C}_5 (64) = \{n_0 + n_1 5 + n_2 5^2   : n_i = 1, 2, 3, 4 \} ,$ where $n_i$ are digits related to nucleotides as follows: C = 1, A = 2, T = U = 3, G = 4. The smallest 5-adic distance between codons joins them into 16 quadruplets, which under 2-adic distance decay into 32 doublets. p-Adically close codons are assigned to one of 20 amino acids, which are building blocks of proteins, or code termination of protein synthesis. We shown that genetic code multiplets are made of the p-adic nearest codons.",Biology
"With an automatic image analysis device, we studied the temporal distribution of the locomotor activity of E. orientalis and E. vuilleti during 24 h, and over several days to know whether the activity rhythms of these two Eupelmidae play a role in their competitive interactions. The analysis of locomotor activity rhythms of E. orientalis and E. vuilleti shows that the locomotor activity of both species presents daily cyclic variations. These two Eupelmidae have similar activity rhythms. Displacements of these parasitoids essentially take place during the photophase. But the activity of E. vuilleti is earlier, because the individuals of this species start their activity on average 4 to 5 h earlier than those of E. orientalis. E. vuilleti begins its displacements several hours before the onset of lighting, whereas E. orientalis is active only in the presence of the light. This shift of starting activity is thus a factor allowing these concurrent species to minimize their interactions during the cohabitation period in traditional granaries after the harvests of cowpea.",Biology
"This work is a study of the inter-relationship between parameters that principally affect metal up-take in the plant. The relationships between the concentration of metal in the growth medium, Cs, the concentration of metal absorbed by the plant, Cp, and the total biomass achieved, M, all of which are factors relevant to the efficiency of phytoremediation of the plant, have been investigated via the macro-physiological response of Brassica juncea seedlings to Ni(II) stress. The factorial growth experiments treated the Ni(II) concentration in the agar gel and the diurnal light quanta (DLQ) as independently variable parameters. Observations included the evidence of light enhancement of Ni toxicity at the root as well as at the whole plant level, the shoot mass index as a possible indicator of shoot metal sequestration in B. juncea, the logarithmic variation of Cp with Cs and the power-law dependence of M on Cp. The sum total of these observations indicate that for the metal accumulator B. juncea with regard to its capacity to accumulate Ni, the overall metabolic nature of the plant is important; neither rapid biomass increase nor a high metal concentration capability favor the removal of high metal mass from the medium, but rather the plant with the moderate photosynthetically driven biomass growth and moderate metal concentrations demonstrated the ability to remove the maximum mass of metal from the medium. The implications of these observations in the context of the perceived need in phytoremediation engineering to maximize Cp and M simultaneously in the same plant, are discussed.",Biology
"In a recent paper [C. Marr, M. Mueller-Linow, and M.-T. Huett, Phys. Rev. E 75, 041917 (2007)] we discuss the pronounced potential of real metabolic network topologies, compared to randomized counterparts, to regularize complex binary dynamics. In their comment [P. Holme and M. Huss, arXiv:0705.4084v1], Holme and Huss criticize our approach and repeat our study with more realistic dynamics, where stylized reaction kinetics are implemented on sets of pairwise reactions. The authors find no dynamic difference between the reaction sets recreated from the metabolic networks and randomized counterparts. We reproduce the author's observation and find that their algorithm leads to a dynamical fragmentation and thus eliminates the topological information contained in the graphs. Hence, their approach cannot rule out a connection between the topology of metabolic networks and the ubiquity of steady states.",Biology
"Noise and spatial degrees of freedom characterize most ecosystems. Some aspects of their influence on the coevolution of populations with cyclic interspecies competition have been demonstrated in recent experiments [e.g. B. Kerr et al., Nature {\bf 418}, 171 (2002)]. To reach a better theoretical understanding of these phenomena, we consider a paradigmatic spatial model where three species exhibit cyclic dominance. Using an individual-based description, as well as stochastic partial differential and deterministic reaction-diffusion equations, we account for stochastic fluctuations and spatial diffusion at different levels, and show how fascinating patterns of entangled spirals emerge. We rationalize our analysis by computing the spatio-temporal correlation functions and provide analytical expressions for the front velocity and the wavelength of the propagating spiral waves.",Biology
"In this paper a novel architecture for cortical computation has been proposed. This architecture is composed of computing paths consisting of neurons and synapses only. These paths have been decomposed into lateral, longitudinal and vertical components. Cortical computation has then been decomposed into lateral computation (LaC), longitudinal computation (LoC) and vertical computation (VeC). It has been shown that various loop structures in the cortical circuit play important roles in cortical computation as well as in memory storage and retrieval, keeping in conformity with the molecular basis of short and long term memory. A new learning scheme for the brain has also been proposed and how it is implemented within the proposed architecture has been explained. A number of mathematical results about the architecture have been proposed, many of which without proof.",Biology
"Three-dimensional (3D) chromatin structure is closely related to genome function, in particular transcription. However, the folding path of the chromatin fiber in the interphase nucleus is unknown. Here, we systematically measured the 3D physical distance between pairwise labeled genomic positions in gene-dense, highly transcribed domains and gene-poor less active areas on chromosomes 1 and 11 in G1 nuclei of human primary fibroblasts, using fluorescence in situ hybridization. Interpretation of our results and those published by others, based on polymer physics, shows that the folding of the chromatin fiber can be described as a polymer in a globular state (GS), maintained by intra-polymer attractive interactions that counteract self-avoidance forces. The GS polymer model is able to describe chromatin folding in as well the highly expressed domains as the lowly expressed ones, indicating that they differ in Kuhn length and chromatin compaction. Each type of genomic domain constitutes an ensemble of relatively compact globular folding states, resulting in a considerable cellto- cell variation between otherwise identical cells. We present evidence for different polymer folding regimes of the chromatin fiber on the length scale of a few mega base pairs and on that of complete chromosome arms (several tens of Mb). Our results present a novel view on the folding of the chromatin fiber in interphase and open the possibility to explore the nature of the intra-chromatin fiber interactions.",Biology
"In this paper a theoretical model of functioning of a neural circuit during a behavioral response has been proposed. A neural circuit can be thought of as a directed multigraph whose each vertex is a neuron and each edge is a synapse. It has been assumed in this paper that the behavior of such circuits is manifested through the collective behavior of neurons belonging to that circuit. Behavioral information of each neuron is contained in the coefficients of the fast Fourier transform (FFT) over the output spike train. Those coefficients form a vector in a multidimensional vector space. Behavioral dynamics of a neuronal network in response to strong aversive stimuli has been studied in a vector space in which a suitable pseudometric has been defined. The neurodynamical model of network behavior has been formulated in terms of existing memory, synaptic plasticity and feelings. The model has an analogy in classical electrostatics, by which the notion of force and potential energy has been introduced. Since the model takes input from each neuron in a network and produces a behavior as the output, it would be extremely difficult or may even be impossible to implement. But with the help of the model a possible explanation for an hitherto unexplained neurological observation in human brain has been offered. The model is compatible with a recent model of sequential behavioral dynamics. The model is based on electrophysiology, but its relevance to hemodynamics has been outlined.",Biology
"The relationship between the regulatory design and the functionality of molecular networks is a key issue in biology. Modules and motifs have been associated to various cellular processes, thereby providing anecdotal evidence for performance based localization on molecular networks. To quantify structure-function relationship we investigate similarities of proteins which are close in the regulatory network of the yeast Saccharomyces Cerevisiae. We find that the topology of the regulatory network show weak remnants of its history of network reorganizations, but strong features of co-regulated proteins associated to similar tasks. This suggests that local topological features of regulatory networks, including broad degree distributions, emerge as an implicit result of matching a number of needed processes to a finite toolbox of proteins.",Biology
This article reports about a novel extension of dissipative particle dynamics (DPD) that allows the study of the collective dynamics of complex chemical and structural systems in a spatially resolved manner with a combinatorially complex variety of different system constituents. We show that introducing multipolar interactions between particles leads to extended membrane structures emerging in a self-organized manner and exhibiting both the necessary mechanical stability for transport and fluidity so as to provide a two-dimensional self-organizing dynamic reaction environment for kinetic studies in the context of cell biology. We further show that the emergent dynamics of extended membrane bound objects is in accordance with scaling laws imposed by physics.,Biology
"The goal of this paper is to outline a scenario of emerging stochasticity in high-dimensional highly nonlinear systems, such as genetic regulatory networks (GRN). We focus attention on the fact that in such systems confluence of all the factors necessary for gene expression is a comparatively rare event, and only massive redundancy makes such events sufficiently frequent. An immediate consequence of this rareness is burstiness in mRNA and protein copy numbers, a well known experimentally observed effect. We introduce the concept of stochastic cooperativity and show that this phenomenon is a natural consequence of high dimensionality coupled with highly nonlinearity of a dynamical system. In mathematical terms, burstiness is associated with heavy-tailed probability distributions of stochastic processes describing the dynamics of the system. The sequence of stochastic cooperativity events allows for transition from continuous deterministic dynamics expressed in terms of ordinary differential equations (ODE) to discrete stochastic dynamics expressed in terms of Langevin and Fokker-Plank equations. We demonstrate also that high-dimensional nonlinear systems, even in the absence of explicit mechanisms for suppressing inherent instability, may nevertheless reside in a state of stationary pseudo-random fluctuations which for all practical purposes may be regarded as stochastic process. This type of stochastic behavior is an inherent property of such systems and requires neither an external random force, nor highly specialized conditions of bistability.",Biology
"In the simplest view of transcriptional regulation, the expression of a gene is turned on or off by changes in the concentration of a transcription factor (TF). We use recent data on noise levels in gene expression to show that it should be possible to transmit much more than just one regulatory bit. Realizing this optimal information capacity would require that the dynamic range of TF concentrations used by the cell, the input/output relation of the regulatory module, and the noise levels of binding and transcription satisfy certain matching relations. This parameter-free prediction is in good agreement with recent experiments on the Bicoid/Hunchback system in the early Drosophila embryo, and this system achieves ~90% of its theoretical maximum information transmission.",Biology
"We consider a system of differential equations the behavior of which solutions possesses several properties characteristic of the blood pressure distribution. The system can be used for a compartmental modeling of the cardiovascular system. It admits a unique bounded solution such that all coordinates of the solution are separated from zero by positive numbers, and which is periodic, eventually periodic or almost periodic depending on the moments of heart contraction. Appropriate numerical simulations are provided.",Biology
"This work is concerned with the development of a well-founded, theoretically justified, and least complicated metric for the classification of proteins with reference to enzymes. As the signature of an enzyme family, a catalytic domain is easily fingerprinted. Given that the classification problem has so far seemed intractable, a classification schema derived from the catalytic domain would be satisfying. Here I show that there exists a natural ab initio if nonobvious basis to theorize that the catalytic domain of an enzyme is uniquely informative about its regulation. This annotates its function. Based on this hypothesis, a method that correctly classifies potassium ion channels into their respective subfamilies is described. To put the principle on firmer ground, extra validation was sought and obtained through co-evolutionary analyses. The co-evolutionary analyses reveal a departure from the notion that potassium ion channel proteins are functionally modular. This finding is discussed in light of the prevailing notion of domain. These studies establish that significant co-evolution of the catalytic domain of a gene with its conjoint domain is a specialized, necessary process following fusion and swapping events in evolution. Instances of this discovery are likely to be found pervasive in protein science.",Biology
"We have used the Penna ageing model to analyze how the differences in evolution of sex chromosomes depend on the strategy of reproduction. In panmictic populations, when females (XX) can freely choose the male partner (XY) for reproduction from the whole population, the Y chromosome accumulates defects and eventually the only information it brings is a male sex determination. As a result of shrinking Y chromosome the males become hemizygous in respect to the X chromosome content and are characterized by higher mortality, observed also in the human populations. If it is assumed in the model that the presence of the male is indispensable at least during the pregnancy of his female partner and he cannot be seduced by another female at least during the one reproduction cycle - the Y chromosome preserves its content, does not shrink and the lifespan of females and males is the same. Thus, Y chromosome shrinks not because of existing in one copy, without the possibility of recombination, but because it stays under weaker selection pressure; in panmictic populations without the necessity of being faithful, a considerable fraction of males is dispensable and they can be eliminated from the population without reducing its reproduction potential.",Biology
"A model is proposed to minimize the total volume of the main distribution networks of fluids in relation to the organ form. The minimization analysis shows that the overall exterior form of distribution networks is a modified ellipsoid, a geometric form that is a good approximation to the external anatomy of the kidney and lung. The variational procedure implementing this minimization is similar to the traditional isoperimetric theorems of geometry.   A revised version of this preprint that expands Section 4 will be published in the Journal of Biological Systems, World Scientific Publishing.",Biology
"Background : The carnivorous plants of the genus Nepenthes, widely distributed in the Asian tropics, rely mostly on nutrients derived from arthropods trapped in their pitcher-shaped leaves and digested by their enzymatic fluid. The genus exhibits a great diversity of prey and pitcher forms and its mechanism of trapping has long intrigued scientists. The slippery inner surfaces of the pitchers, which can be waxy or highly wettable, have so far been considered as the key trapping devices. However, the occurrence of species lacking such epidermal specializations but still effective at trapping insects suggests the possible implication of other mechanisms. Methodology/Principal Findings : Using a combination of insect bioassays, high-speed video and rheological measurements, we show that the digestive fluid of Nepenthes rafflesiana is highly viscoelastic and that this physical property is crucial for the retention of insects in its traps. Trapping efficiency is shown to remain strong even when the fluid is highly diluted by water, as long as the elastic relaxation time of the fluid is higher than the typical time scale of insect movements. Conclusions/Significance : This finding challenges the common classification of Nepenthes pitchers as simple passive traps and is of great adaptive significance for these tropical plants, which are often submitted to high rainfalls and variations in fluid concentration. The viscoelastic trap constitutes a cryptic but potentially widespread adaptation of Nepenthes species and could be a homologous trait shared through common ancestry with the sundew (Drosera) flypaper plants. Such large production of a highly viscoelastic biopolymer fluid in permanent pools is nevertheless unique in the plant kingdom and suggests novel applications for pest control.",Biology
"Medvedev and Melott (2007) have suggested that periodicity in fossil biodiversity may be induced by cosmic rays which vary as the Solar System oscillates normal to the galactic disk. We re-examine the evidence for a 62 million year (Myr) periodicity in biodiversity throughout the Phanerozoic history of animal life reported by Rohde & Mueller (2005), as well as related questions of periodicity in origination and extinction. We find that the signal is robust against variations in methods of analysis, and is based on fluctuations in the Paleozoic and a substantial part of the Mesozoic. Examination of origination and extinction is somewhat ambiguous, with results depending upon procedure. Origination and extinction intensity as defined by RM may be affected by an artifact at 27 Myr in the duration of stratigraphic intervals. Nevertheless, when a procedure free of this artifact is implemented, the 27 Myr periodicity appears in origination, suggesting that the artifact may ultimately be based on a signal in the data. A 62 Myr feature appears in extinction, when this same procedure is used. We conclude that evidence for a periodicity at 62 Myr is robust, and evidence for periodicity at approximately 27 Myr is also present, albeit more ambiguous.",Biology
"Surface modified amorphous nanoporous silica molecules with hydrophobic as well as hydrophilic character can be effectively used as therapeutic drug for combating chicken malaria in poultry industry. The amorphous nanosilica was developed by top-down approach using volcanic soil derived silica as source material. Amorphous silica has long been used as feed additive for poultry industry and considered to be safe for human consumption by WHO and USDA. The basic mechanism of action of these nanosilica molecules is mediated by the physical absorption of VLDL, serum triglycerides and other serum cholesterol components in the lipophilic nanopores of nanosilica. This reduces the supply of the host derived cholesterol, thus limiting the growth of the malarial parasite in vivo.",Biology
"Previously, we have identified the cytoplasmic zinc metalloprotease insulin-degrading enzyme(IDE) in human tissues by an immunohistochemical method involving no antigen retrieval (AR) by pressure cooking to avoid artifacts by endogenous biotin exposure and a detection kit based on the labeled streptavidin biotin (LSAB) method. Thereby, we also employed 3% hydrogen peroxide(H2O2) for the inhibition of endogenous peroxidase activity and incubated the tissue sections with the biotinylated secondary antibody at room temperature (RT). We now add the immunohistochemical details that had led us to this optimized procedure as they also bear a more general relevance when demonstrating intracellular tissue antigens. Our most important result is that endogenous peroxidase inhibition by 0.3% H2O2 coincided with an apparently positive IDE staining in an investigated breast cancer specimen whereas combining a block by 3% H2O2 with an incubation of the biotinylated secondary antibody at RT, yet not at 37 degrees Celsius, revealed this specimen as almost entirely IDE-negative. Our present data caution against three different immunohistochemical pitfalls that might cause falsely positive results and artifacts when using an LSAB- and peroxidase-based detection method: pressure cooking for AR, insufficient quenching of endogenous peroxidases and heating of tissue sections while incubating with biotinylated secondary antibodies.",Biology
"In this article, we study the kinetics of reversible ligand binding to receptors on a spherical cell surface using a self-consistent stochastic theory. Binding, dissociation, diffusion and rebinding of ligands are incorporated into the theory in a systematic manner. We derive explicitly the time evolution of the ligand-bound receptor fraction p(t) in various regimes . Contrary to the commonly accepted view, we find that the well-known Berg-Purcell scaling for the association rate is modified as a function of time. Specifically, the effective on-rate changes non-monotonically as a function of time and equals the intrinsic rate at very early as well as late times, while being approximately equal to the Berg-Purcell value at intermediate times. The effective dissociation rate, as it appears in the binding curve or measured in a dissociation experiment, is strongly modified by rebinding events and assumes the Berg-Purcell value except at very late times, where the decay is algebraic and not exponential. In equilibrium, the ligand concentration everywhere in the solution is the same and equals its spatial mean, thus ensuring that there is no depletion in the vicinity of the cell. Implications of our results for binding experiments and numerical simulations of ligand-receptor systems are also discussed.",Biology
"Transforming growth factor (TGF) $\beta$ is known to have properties of both a tumor suppressor and a tumor promoter. While it inhibits cell proliferation, it also increases cell motility and decreases cell--cell adhesion. Coupling mathematical modeling and experiments, we investigate the growth and motility of oncogene--expressing human mammary epithelial cells under exposure to TGF--$\beta$. We use a version of the well--known Fisher--Kolmogorov equation, and prescribe a procedure for its parametrization. We quantify the simultaneous effects of TGF--$\beta$ to increase the tendency of individual cells and cell clusters to move randomly and to decrease overall population growth. We demonstrate that in experiments with TGF--$\beta$ treated cells \textit{in vitro}, TGF--$\beta$ increases cell motility by a factor of 2 and decreases cell proliferation by a factor of 1/2 in comparison with untreated cells.",Biology
"In this paper I show that, for a class of reaction networks, the discrete stochastic nature of the reacting species and reactions results in qualitative and quantitative differences between the mean of exact stochastic simulations and the prediction of the corresponding deterministic system. The differences are independent of the number of molecules of each species in the system under consideration. These reaction networks are open systems of chemical reactions with no zero-order reaction rates systems. They are characterized by at least two stationary points, one of which is a nonzero stable point, and one unstable trivial solution (stability based on a linear stability analysis of the deterministic system). Starting from a nonzero initial condition, the deterministic system never reaches the zero stationary point due to its unstable nature. In contrast, the result presented here proves that this zero-state is the only stable stationary state for the discrete stochastic system. This result generalizes previous theoretical studies and simulations of specific systems and provides a theoretical basis for analyzing a class of systems that exhibit such inconsistent behavior. This result has implications in the simulation of infection, apoptosis, and population kinetics, as it can be shown that for certain models the stochastic simulations will always yield different predictions for the mean behavior than the deterministic simulations.",Biology
"Malaria and other parasites, including virus often induce an increase in host lipids which the invaders use to their own advantage. We obtained encouraging results in our investigations on bird malaria with a new approach namely the use of nanosilica to mop up excess host lipids. While this project is continuing we have investigated another, simpler system namely silkworms which suffer from a deadly baculovirus, BmNPV. This virus decimates the infected population within 24 hours or so and no known antibiotic antidote or genetically resistant strain of silkworm3 exists. We report here a partial success, which is worth following up. Our rationale, we believe, has a broad and interdisciplinary appeal, for, this nanosilica treatment might be used together with other arsenals on all sorts of virus which take advantage of enhanced host lipids. It has not escaped our notice that Ebola and HIV also belong to this category. Nanoparticles are being preferentially harnessed, because they offer a greater surface area, circulate more easily and in lepidopteran system4 they are removed within 24 hours from the body. Lawry surmised, on cogent theoretical grounds that particles significantly smaller than micron order would be less harmful in the hemocoele. Furthermore, Hui-peng et al. pointed out that lipase treatment, the only viable option for controlling BmNPV interferes in hormonal balance and cannot be applied to pre molting stage.",Biology
"Biological networks have evolved to be highly functional within uncertain environments while remaining extremely adaptable. One of the main contributors to the robustness and evolvability of biological networks is believed to be their modularity of function, with modules defined as sets of genes that are strongly interconnected but whose function is separable from those of other modules. Here, we investigate the in silico evolution of modularity and robustness in complex artificial metabolic networks that encode an increasing amount of information about their environment while acquiring ubiquitous features of biological, social, and engineering networks, such as scale-free edge distribution, small-world property, and fault-tolerance. These networks evolve in environments that differ in their predictability, and allow us to study modularity from topological, information-theoretic, and gene-epistatic points of view using new tools that do not depend on any preconceived notion of modularity. We find that for our evolved complex networks as well as for the yeast protein-protein interaction network, synthetic lethal pairs consist mostly of redundant genes that lie close to each other and therefore within modules, while knockdown suppressor pairs are farther apart and often straddle modules, suggesting that knockdown rescue is mediated by alternative pathways or modules. The combination of network modularity tools together with genetic interaction data constitutes a powerful approach to study and dissect the role of modularity in the evolution and function of biological networks.",Biology
"Miniaturization is a hallmark of modern technologies. Notably, this feature has not spared molecular biology and its potential applications. Towards developing more effective therapeutics against cancer, studies began to explore more than a decade ago how natural tumor suppression could be translated into antineoplastic drugs. To this end, investigators focused on major constituents of a central pathway that protects cells against neoplastic transformation: the nuclear retinoblastoma protein (RB) pathway. As such, peptide mimetics of RB, p16 and p21 were developed. Likewise, the p53 and von Hippel-Lindau gene products which affect indirectly the RB pathway provided additional templates for the development of anti-proliferative peptides. Each of the peptides derived from these distinct tumor suppressors was made cell-permeable by its ligation to an amino acid sequence conferring cellular internalization. Details reviewed here reveal that through the application of such anti-cancer peptide therapeutics alone or in conjunction whenever synergy is to expect, the dark era of chemotherapy will likely be overcome, at last.",Biology
"Various types of surface functionalized nanosilica (50-60 nm size with 3-10 nm inner pore size range) have been used to kill insect pests by sucking up cuticular lipids and breaking the water barrier. We have also utilized nanosilica for mopping up host lipids induced by the malarial parasite, P. gallinaceum in poultry birds; VLDL cholesterol and serum triglycerides are brought back to the normal level with a concomitant check in parasite growth. While this work continues, we have explored another more convenient system, silkworm (Bombyx mori) that is frequently decimated by a baculovirus, NPV for which no antidote is known so far. Here, too, viral infection enhances host lipids. Eight different types of nanosilica were injected in the virus infected silkworm (batches of 10 worms) after ensuring 100% survival up to cocoon formation in control larvae (injected with the same volume of ethanol, the medium of nanosilica). Of these 8, AL60102 and AL60106, have the most marked effect on infected silkworm, both as prophylactic and pharmaceutical agents. Normal larvae injected with these nanosilica survive up to cocoon formation.",Biology
"In this paper we enumerate $k$-noncrossing RNA pseudoknot structures with given minimum arc- and stack-length. That is, we study the numbers of RNA pseudoknot structures with arc-length $\ge 3$, stack-length $\ge \sigma$ and in which there are at most $k-1$ mutually crossing bonds, denoted by ${\sf T}_{k,\sigma}^{[3]}(n)$. In particular we prove that the numbers of 3, 4 and 5-noncrossing RNA structures with arc-length $\ge 3$ and stack-length $\ge 2$ satisfy ${\sf T}_{3,2}^{[3]}(n)^{}\sim K_3 n^{-5} 2.5723^n$, ${\sf T}^{[3]}_{4,2}(n)\sim K_4 n^{-{21/2}} 3.0306^n$, and ${\sf T}^{[3]}_{5,2}(n)\sim K_5 n^{-18} 3.4092^n$, respectively, where $K_3,K_4,K_5$ are constants. Our results are of importance for prediction algorithms for RNA pseudoknot structures.",Biology
"Functional Magnetic Resonance Imaging (fMRI) provides dynamical access into the complex functioning of the human brain, detailing the hemodynamic activity of thousands of voxels during hundreds of sequential time points. One approach towards illuminating the connection between fMRI and cognitive function is through decoding; how do the time series of voxel activities combine to provide information about internal and external experience? Here we seek models of fMRI decoding which are balanced between the simplicity of their interpretation and the effectiveness of their prediction. We use signals from a subject immersed in virtual reality to compare global and local methods of prediction applying both linear and nonlinear techniques of dimensionality reduction. We find that the prediction of complex stimuli is remarkably low-dimensional, saturating with less than 100 features. In particular, we build effective models based on the decorrelated components of cognitive activity in the classically-defined Brodmann areas. For some of the stimuli, the top predictive areas were surprisingly transparent, including Wernicke's area for verbal instructions, visual cortex for facial and body features, and visual-temporal regions for velocity. Direct sensory experience resulted in the most robust predictions, with the highest correlation ($c \sim 0.8$) between the predicted and experienced time series of verbal instructions. Techniques based on non-linear dimensionality reduction (Laplacian eigenmaps) performed similarly. The interpretability and relative simplicity of our approach provides a conceptual basis upon which to build more sophisticated techniques for fMRI decoding and offers a window into cognitive function during dynamic, natural experience.",Biology
"In this short note we sketch the statistical physics framework of the replica exchange technique when applied to molecular dynamics simulations. In particular, we draw attention to generalized move sets that allow a variety of optimizations as well as new applications of the method.",Biology
"Structural fluctuations in the thermal equilibrium of the kinesin motor domain are studied using a lattice protein model with Go interactions. By means of the multi-self-overlap ensemble (MSOE) Monte Carlo method and the principal component analysis (PCA), the free-energy landscape is obtained. It is shown that kinesins have two subdomains that exhibit partial folding/unfolding at functionally important regions: one is located around the nucleotide binding site and the other includes the main microtubule binding site. These subdomains are consistent with structural variability that was reported recently based on experimentally-obtained structures. On the other hand, such large structural fluctuations have not been captured by B-factor or normal mode analyses. Thus, they are beyond the elastic regime, and it is essential to take into account chain connectivity for studying the function of kinesins.",Biology
"Both short interfering RNAs (siRNAs) and microRNAs (miRNAs) mediate the repression of specific sequences of mRNA through the RNA interference pathway. In the last years several experiments have supported the hypothesis that siRNAs and miRNAs may be functionally interchangeable, at least in cultured cells. In this work we verify that this hypothesis is also supported by a computational evidence. We show that a method specifically trained to predict the activity of the exogenous siRNAs assigns a high silencing level to experimentally determined human miRNAs. This result not only supports the idea of siRNAs and miRNAs equivalence but indicates that it is possible to use computational tools developed using synthetic small interference RNAs to investigate endogenous miRNAs.",Biology
"This report describes technical adaptations of a traumatic brain injury (TBI) model-largely inspired by Marmarou-in order to monitor microdialysis data and PtiO2 (brain tissue oxygen) before, during and after injury. We particularly focalize on our model requirements which allows us to re-create some drastic pathological characteristics experienced by severely head-injured patients: impact on a closed skull, no ventilation immediately after impact, presence of diffuse axonal injuries and secondary brain insults from systemic origin...We notably give priority to minimize anaesthesia duration in order to tend to banish any neuroprotection. Our new model will henceforth allow a better understanding of neurochemical and biochemical alterations resulting from traumatic brain injury, using microdialysis and PtiO2 techniques already monitored in our Intensive Care Unit. Studies on efficiency and therapeutic window of neuroprotective pharmacological molecules are now conceivable to ameliorate severe head-injury treatment.",Biology
"By means of the diffusion entropy approach, we detect the scale-invariance characteristics embedded in the 4737 human promoter sequences. The exponent for the scale-invariance is in a wide range of $[ {0.3,0.9} ]$, which centered at $\delta_c = 0.66$. The distribution of the exponent can be separated into left and right branches with respect to the maximum. The left and right branches are asymmetric and can be fitted exactly with Gaussian form with different widths, respectively.",Biology
"A comparison is made between conventional Michaelis-Menten kinetics and two models that take into account the duration of the conformational changes that take place at the molecular level during the catalytic cycle of a monomer. The models consider the time that elapses from the moment an enzyme-substrate complex forms until the moment a product molecule is released, as well as the recovery time needed to reset the conformational change that took place. In the first model the dynamics is described by a set of delayed differential equations, instead of the ordinary differential equations associated to Michaelis-Menten kinetics. In the second model the delay, the discretization inherent to enzyme reactions and the stochastic binding of substrates to enzimes at the molecular level is considered. All three models agree at equilibrium, as expected; however, out-of-equilibrium dynamics can differ substantially. In particular, both delayed models show oscillations at low values of the Michaelis constant which are not reproduced by the Michaelis-Menten model. Additionally, in certain cases, the dynamics shown by the continuous delayed model differs from the dynamics of the discrete delayed model when some reactant become scarce.",Biology
"To establish the relationship between locomotory behavior and dynamics of neural circuits in the nematode C. elegans we combined molecular and theoretical approaches. In particular, we quantitatively analyzed the motion of C. elegans with defective synaptic GABA and acetylcholine transmission, defective muscle calcium signaling, and defective muscles and cuticle structures, and compared the data with our systems level circuit model. The major experimental findings are: (i) anterior-to-posterior gradients of body bending flex for almost all strains both for forward and backward motion, and for neuronal mutants, also analogous weak gradients of undulatory frequency, (ii) existence of some form of neuromuscular (stretch receptor) feedback, (iii) invariance of neuromuscular wavelength, (iv) biphasic dependence of frequency on synaptic signaling, and (v) decrease of frequency with increase of the muscle time constant. Based on (i) we hypothesize that the Central Pattern Generator (CPG) is located in the head both for forward and backward motion. Points (i) and (ii) are the starting assumptions for our theoretical model, whose dynamical patterns are qualitatively insensitive to the details of the CPG design if stretch receptor feedback is sufficiently strong and slow. The model reveals that stretch receptor coupling in the body wall is critical for generation of the neuromuscular wave. Our model agrees with our behavioral data(iii), (iv), and (v), and with other pertinent published data, e.g., that frequency is an increasing function of muscle gap-junction coupling.",Biology
"The critical properties of the Frank model of spontaneous chiral synthesis are discussed by applying results from the field theoretic renormalization group (RG). The long time and long wavelength features of this microscopic reaction scheme belong to the same universality class as multi-colored directed percolation processes. Thus, the following RG fixed points (FP) govern the critical dynamics of the Frank model for d<4: one unstable FP that corresponds to complete decoupling between the two enantiomers, a saddle-point that corresponds to symmetric interspecies coupling, and two stable FPs that individually correspond to unidirectional couplings between the two chiral molecules. These latter two FPs are associated with the breakdown of mirror or chiral symmetry. In this simplified model of molecular synthesis, homochirality is a natural consequence of the intrinsic reaction noise in the critical regime, which corresponds to extremely dilute chemical systems.",Biology
"Many complex biological, social, and economical networks show topologies drastically differing from random graphs. But, what is a complex network, i.e.\ how can one quantify the complexity of a graph? Here the Offdiagonal Complexity (OdC), a new, and computationally cheap, measure of complexity is defined, based on the node-node link cross-distribution, whose nondiagonal elements characterize the graph structure beyond link distribution, cluster coefficient and average path length. The OdC apporach is applied to the {\sl Helicobacter pylori} protein interaction network and randomly rewired surrogates thereof. In addition, OdC is used to characterize the spatial complexity of cell aggregates. We investigate the earliest embryo development states of Caenorhabditis elegans. The development states of the premorphogenetic phase are represented by symmetric binary-valued cell connection matrices with dimension growing from 4 to 385. These matrices can be interpreted as adjacency matrix of an undirected graph, or network. The OdC approach allows to describe quantitatively the complexity of the cell aggregate geometry.",Biology
"Consensus methods provide a useful strategy for combining information from a collection of gene trees. An important application of consensus methods is to combine gene trees to estimate a species tree. To investigate the theoretical properties of consensus trees that would be obtained from large numbers of loci evolving according to a basic evolutionary model, we construct consensus trees from independent gene trees that occur in proportion to gene tree probabilities derived from coalescent theory. We consider majority-rule, rooted triple (R*), and greedy consensus trees constructed from known gene trees, both in the asymptotic case as numbers of gene trees approach infinity and for finite numbers of genes. Our results show that for some combinations of species tree branch lengths, increasing the number of independent loci can make the majority-rule consensus tree more likely to be at least partially unresolved and the greedy consensus tree less likely to match the species tree. However, the probability that the R* consensus tree has the species tree topology approaches 1 as the number of gene trees approaches infinity. Although the greedy consensus algorithm can be the quickest to converge on the correct species tree when increasing the number of gene trees, it can also be positively misleading. The majority-rule consensus tree is not a misleading estimator of the species tree topology, and the R* consensus tree is a statistically consistent estimator of the species tree topology. Our results therefore suggest a method for using multiple loci to infer the species tree topology, even when it is discordant with the most likely gene tree.",Biology
"From the spectral plot of the (normalized) graph Laplacian, the essential qualitative properties of a network can be simultaneously deduced. Given a class of empirical networks, reconstruction schemes for elucidating the evolutionary dynamics leading to those particular data can then be developed. This method is exemplified for protein-protein interaction networks. Traces of their evolutionary history of duplication and divergence processes are identified. In particular, we can identify typical specific features that robustly distinguish protein-protein interaction networks from other classes of networks, in spite of possible statistical fluctuations of the underlying data.",Biology
"Computational analyses of, e.g., genomic, proteomic, or metabolomic data, commonly result in one or more sets of candidate genes, proteins, or enzymes. These sets are often the outcome of clustering algorithms. Subsequently, it has to be tested if, e.g., the candidate gene-products are members of known metabolic processes. With OrfMapper we provide a powerful but easy-to-use, web-based database application, that supports such analyses. All services provided by OrfMapper are freely available at http://www.orfmapper.com",Biology
". Genechip oligonucleotide microarrays have been used widely for transcriptional profiling of a large number of genes in a given paradigm. Gene expression estimation precedes biological inference and is given as a complex combination of atomic entities on the array called probes. These probe intensities are further classified into perfect-match (PM) and mis-match (MM) probes. While former is a measure of specific binding, the lat-ter is a measure of non-specific binding. The behavior of the MM probes has especially proven to be elusive. The present study investigates qualita-tive similarities in the distributional signatures and local correlation struc-tures/patchiness between the PM and MM probe intensities. These qualita-tive similarities are established on publicly available microarrays generated across laboratories investigating the same paradigm. Persistence of these similarities across raw as well as background subtracted probe intensities is also investigated. The results presented raise fundamental concerns in inter-preting Genechip oligonucleotide microarray data.",Biology
"For cellular biochemical reaction systems where the numbers of molecules is small, significant noise is associated with chemical reaction events. This molecular noise can give rise to behavior that is very different from the predictions of deterministic rate equation models. Unfortunately, there are few analytic methods for examining the qualitative behavior of stochastic systems. Here we describe such a method that extends deterministic analysis to include leading-order corrections due to the molecular noise. The method allows the steady-state behavior of the stochastic model to be easily computed, facilitates the mapping of stability phase diagrams that include stochastic effects and reveals how model parameters affect noise susceptibility, in a manner not accessible to numerical simulation. By way of illustration we consider two genetic circuits: a bistable positive-feedback loop and a negative-feedback oscillator. We find in the positive feedback circuit that translational activation leads to a far more stable system than transcriptional control. Conversely, in a negative-feedback loop triggered by a positive-feedback switch, the stochasticity of transcriptional control is harnessed to generate reproducible oscillations.",Biology
"We study a continuous-time dynamical system that models the evolving distribution of genotypes in an infinite population where genomes may have infinitely many or even a continuum of loci, mutations accumulate along lineages without back-mutation, added mutations reduce fitness, and recombination occurs on a faster time scale than mutation and selection. Some features of the model, such as existence and uniqueness of solutions and convergence to the dynamical system of an approximating sequence of discrete time models, were presented in earlier work by Evans, Steinsaltz, and Wachter for quite general selective costs. Here we study a special case where the selective cost of a genotype with a given accumulation of ancestral mutations from a wild type ancestor is a sum of costs attributable to each individual mutation plus successive interaction contributions from each $k$-tuple of mutations for $k$ up to some finite ``degree''. Using ideas from complex chemical reaction networks and a novel Lyapunov function, we establish that the phenomenon of mutation-selection balance occurs for such selection costs under mild conditions. That is, we show that the dynamical system has a unique equilibrium and that it converges to this equilibrium from all initial conditions.",Biology
"We study the response properties of d-dimensional hypercubic excitable networks to a stochastic stimulus. Each site, modelled either by a three-state stochastic susceptible-infected-recovered-susceptible system or by the probabilistic Greenberg-Hastings cellular automaton, is continuously and independently stimulated by an external Poisson rate h. The response function (mean density of active sites rho versus h) is obtained via simulations (for d=1, 2, 3, 4) and mean field approximations at the single-site and pair levels (for all d). In any dimension, the dynamic range of the response function is maximized precisely at the nonequilibrium phase transition to self-sustained activity, in agreement with a reasoning recently proposed. Moreover, the maximum dynamic range attained at a given dimension d is a decreasing function of d.",Biology
"Protein detection on SDS gels or on 2-D gels must combine several features, such as sensitivity, homogeneity from one protein to another, speed, low cost, and user-friendliness. For some applications, it is also interesting to have a nonfixing stain, so that proteins can be mobilized from the gel for further use (electroelution, blotting). We show here that coelectrophoretic staining by fluorophores of the oxacarbocyanine family, and especially diheptyloxacarbocyanine, offers several positive features. The sensitivity is intermediate between the one of colloidal CBB and the one of fluroescent ruthenium complexes. Detection is achieved within 1 h after the end of the electrophoretic process and does not use any fixing or toxic agent. The fluorescent SDS-carbocyanine-protein complexes can be detected either with a laser scanner with an excitation wavelength of 488 nm or with a UV table operating at 302 nm. Excellent sequence coverage in subsequent MS analysis of proteolytic peptides is also achieved with this detection method.",Biology
"Simple nonlinear dynamical systems with multiple stable stationary states are often taken as models for switchlike biological systems. This paper considers the interaction of multiple such simple multistable systems when they are embedded together into a larger dynamical ""supersystem."" Attention is focused on the network structure of the resulting set of coupled differential equations, and the consequences of this structure on the propensity of the embedded switches to act independently versus cooperatively. Specifically, it is argued that both larger average and larger variance of the node degree distribution lead to increased switch independence. Given the frequency of empirical observations of high variance degree distributions (e.g., power-law) in biological networks, it is suggested that the results presented here may aid in identifying switch-integrating subnetworks as comparatively homogenous, low-degree, substructures. Potential applications to ecological problems such as the relationship of stability and complexity are also briefly discussed.",Biology
"In a recent paper, Marr, Muller-Linow and Hutt [Phys. Rev. E 75, 041917 (2007)] investigate an artificial dynamic system on metabolic networks. They find a less complex time evolution of this dynamic system in real networks, compared to networks of reference models. The authors argue that this suggests that metabolic network structure is a major factor behind the stability of biochemical steady states. We reanalyze the same kind of data using a dynamic system modeling actual reaction kinetics. The conclusions about stability, from our analysis, are inconsistent with those of Marr et al. We argue that this issue calls for a more detailed type of modeling.",Biology
"Analyzing nonlinear conformational relaxation dynamics in elastic networks corresponding to two classical motor proteins, we find that they respond by well-defined internal mechanical motions to various initial deformations and that these motions are robust against external perturbations. We show that this behavior is not characteristic for random elastic networks. However, special network architectures with such properties can be designed by evolutionary optimization methods. Using them, an example of an artificial elastic network, operating as a cyclic machine powered by ligand binding, is constructed.",Biology
"Recently, several studies have investigated the transcription process associated to specific genetic regulatory networks. In this work, we present a stochastic approach for analyzing the dynamics and effect of negative feedback loops (FBL) on the transcriptional noise. First, our analysis allows us to identify a bimodal activity depending of the strength of self-repression coupling D. In the strong coupling region D>>1, the variance of the transcriptional noise is found to be reduced a 28 % more than described earlier. Secondly, the contribution of the noise effect to the abundance of regulating protein becomes manifest when the coefficient of variation is computed. In the strong coupling region, this coefficient is found to be independent of all parameters and in fair agreement with the experimentally observed values. Finally, our analysis reveals that the regulating protein is significantly induced by the intrinsic and external noise in the strong coupling region. In short, it indicates that the existence of inherent noise in FBL makes it possible to produce a basal amount of proteins even though the repression level D is very strong.",Biology
"Phylogenetic invariants are certain polynomials in the joint probability distribution of a Markov model on a phylogenetic tree. Such polynomials are of theoretical interest in the field of algebraic statistics and they are also of practical interest--they can be used to construct phylogenetic trees. This paper is a self-contained introduction to the algebraic, statistical, and computational challenges involved in the practical use of phylogenetic invariants. We survey the relevant literature and provide some partial answers and many open problems.",Biology
"Proteins are known to locate their specific targets on DNA up to two orders of magnitude faster than predicted by the Smoluchowski three-dimensional diffusion rate. One of the mechanisms proposed to resolve this discrepancy is termed ""intersegment transfer"". Many proteins have two DNA binding sites and can transfer from one DNA segment to another without dissociation to water. We calculate the target search rate for such proteins in a dense globular DNA, taking into account intersegment transfer working in conjunction with DNA motion and protein sliding along DNA. We show that intersegment transfer plays a very important role in cases where the protein spends most of its time adsorbed on DNA.",Biology
"Comment on ""Classification Scheme for Phenomenological Universalities in Growth Problems in Physics and Other Sciences"" by P. Castorina, P. P. Delsanto and C. Guiot, Phys. Rev. Lett. {\bf 96}, 188701 (2006) is presented. It has been proved that the West-like function of growth derived by the authors is incorrect and the approach does not take into account the growth of the biological systems undergoing atrophy or demographic and economic systems undergoing involution or regression. A simple extension of the model, which permits derivation of the so far unknown involuted Gompertz function of growth is proposed.",Biology
"The p53 protein is well-known for its tumour suppressor function. The p53-MDM2 negative feedback loop constitutes the core module of a network of regulatory interactions activated under cellular stress. In normal cells, the level of p53 proteins is kept low by MDM2, i.e. MDM2 negatively regulates the activity of p53. In the case of DNA damage,the p53-mediated pathways are activated leading to cell cycle arrest and repair of the DNA. If repair is not possible due to excessive damage, the p53-mediated apoptotic pathway is activated bringing about cell death. In this paper, we give an overview of our studies on the p53-MDM2 module and the associated pathways from a systems biology perspective. We discuss a number of key predictions, related to some specific aspects of cell cycle arrest and cell death, which could be tested in experiments.",Biology
"We find that discrete noise of inhibiting (signal) molecules can greatly delay the extinction of plasmids in a plasmid replication system: a prototypical biochemical regulatory network. We calculate the probability distribution of the metastable state of the plasmids and show on this example that the reaction rate equations may fail in predicting the average number of regulated molecules even when this number is large, and the time is much shorter than the mean extinction time.",Biology
"Species coexistence is one of the central themes in modern ecology. Coexistence is a prerequisite of biological diversity. However, the question arises how biodiversity can be reconciled with the statement of competition theory, which asserts that competing species cannot coexist. To solve this problem natural selection theory is rejected because it contradicts kinetic models of interacting populations. Biological evolution is presented as a process equivalent to a chemical reaction. The main point is that interactions occur between self-replicating units. Under these assumptions biodiversity is possible if and only if species are identical with respect to the patterns of energy flow in which individuals are involved.",Biology
"We investigate the cycles in the transcription network of S. cerevisiae. Unlike a similar network of E. coli, it contains many cycles. We characterize properties of these cycles and their place in the regulatory mechanism of the cell. Almost all cycles in the transcription network of S. cerevisiae are contained in a single strongly connected component, which we call LSCC (L for ``largest''), except for a single cycle of two transcription factors. Among different physiological conditions, cell cycle has the most significant relationship with LSCC, as the set of 64 transcription interactions that are active in all phases of the cell cycle has overlap of 27 with the interactions of LSCC (of which there are 49). Conversely, if we remove the interactions that are active in all phases of the cell cycle (fewer than 1% of the total), the LSCC would have only three nodes and 5 edges, 4 of which are active only in the stress response subnetwork. LSCC has a special place in the topology of the network and it can be used to define a natural hierarchy in the network; in every physiological subnetwork LSCC plays a pivotal role. Apart from those well-defined conditions, the transcription network of S. cerevisiae is devoid of cycles. It was observed that two conditions that were studied and that have no cycles of their own are exogenous: diauxic shift and DNA repair, while cell cycle, sporulation are endogenous.",Biology
"The growth rate of organisms depends both on external conditions and on internal states, such as the expression levels of various genes. We show that to achieve a criterion mean growth rate over an ensemble of conditions, the internal variables must carry a minimum number of bits of information about those conditions. Evolutionary competition thus can select for cellular mechanisms that are more efficient in an abstract, information theoretic sense. Estimates based on recent experiments suggest that the minimum information required for reasonable growth rates is close to the maximum information that can be conveyed through biologically realistic regulatory mechanisms. These ideas are applicable most directly to unicellular organisms, but there are analogies to problems in higher organisms, and we suggest new experiments for both cases.",Biology
"A basic question of protein structural studies is to which extent mutations affect the stability. This question may be addressed starting from sequence and/or from structure. In proteomics and genomics studies prediction of protein stability free energy change (DDG) upon single point mutation may also help the annotation process. The experimental SSG values are affected by uncertainty as measured by standard deviations. Most of the DDG values are nearly zero (about 32% of the DDG data set ranges from -0.5 to 0.5 Kcal/mol) and both the value and sign of DDG may be either positive or negative for the same mutation blurring the relationship among mutations and expected DDG value. In order to overcome this problem we describe a new predictor that discriminates between 3 mutation classes: destabilizing mutations (DDG<-0.5 Kcal/mol), stabilizing mutations (DDG>0.5 Kcal/mol) and neutral mutations (-0.5<=DDG<=0.5 Kcal/mol). In this paper a support vector machine starting from the protein sequence or structure discriminates between stabilizing, destabilizing and neutral mutations. We rank all the possible substitutions according to a three state classification system and show that the overall accuracy of our predictor is as high as 52% when performed starting from sequence information and 58% when the protein structure is available, with a mean value correlation coefficient of 0.30 and 0.39, respectively. These values are about 20 points per cent higher than those of a random predictor.",Biology
"The neuronal mechanisms that serve to distinguish between light-emitting and light reflecting objects are largely unknown. It has been suggested that luminosity perception implements a separate pathway in the visual system, such that luminosity constitutes an independent perceptual feature. Recently, a psychophysical study was conducted to address the question whether luminosity has a feature status or not. However, the results of this study lend support to the hypothesis that luminance gradients are instead a perceptual feature. Here, I show how the perception of luminosity can emerge from a previously proposed neuronal architecture for generating representations of luminance gradients.",Biology
"Background: Duplication of genes is important for evolution of molecular networks. Many authors have therefore considered gene duplication as a driving force in shaping the topology of molecular networks. In particular it has been noted that growth via duplication would act as an implicit way of preferential attachment, and thereby provide the observed broad degree distributions of molecular networks.   Results: We extend current models of gene duplication and rewiring by including directions and the fact that molecular networks are not a result of unidirectional growth. We introduce upstream sites and downstream shapes to quantify potential links during duplication and rewiring. We find that this in itself generates the observed scaling of transcription factors for genome sites in procaryotes. The dynamical model can generate a scale-free degree distribution, p(k)&prop; 1/k^&gamma;, with exponent &gamma;=1 in the non-growing case, and with &gamma;>1 when the network is growing.   Conclusions: We find that duplication of genes followed by substantial recombination of upstream regions could generate main features of genetic regulatory networks. Our steady state degree distribution is however to broad to be consistent with data, thereby suggesting that selective pruning acts as a main additional constraint on duplicated genes. Our analysis shows that gene duplication can only be a main cause for the observed broad degree distributions, if there is also substantial recombinations between upstream regions of genes.",Biology
"An essential requirement for the representation of functional patterns in complex neural networks, such as the mammalian cerebral cortex, is the existence of stable network activations within a limited critical range. In this range, the activity of neural populations in the network persists between the extremes of quickly dying out, or activating the whole network. The nerve fiber network of the mammalian cerebral cortex possesses a modular organization extending across several levels of organization. Using a basic spreading model without inhibition, we investigated how functional activations of nodes propagate through such a hierarchically clustered network. The simulations demonstrated that persistent and scalable activation could be produced in clustered networks, but not in random networks of the same size. Moreover, the parameter range yielding critical activations was substantially larger in hierarchical cluster networks than in small-world networks of the same size. These findings indicate that a hierarchical cluster architecture may provide the structural basis for the stable and diverse functional patterns observed in cortical networks.",Biology
"Background: The computation of the statistical properties of motif occurrences has an obviously relevant practical application: for example, patterns that are significantly over- or under-represented in the genome are interesting candidates for biological roles. However, the problem is computationally hard; as a result, virtually all the existing pipelines use fast but approximate scoring functions, in spite of the fact that they have been shown to systematically produce incorrect results. A few interesting exact approaches are known, but they are very slow and hence not practical in the case of realistic sequences. Results: We give an exact solution, solely based on deterministic finite-state automata (DFAs), to the problem of finding not only the p-value, but the whole relevant part of the Markovian probability distribution function of a motif in a biological sequence. In particular, the time complexity of the algorithm in the most interesting regimes is far better than that of Nuel (2006), which was the fastest similar exact algorithm known to date; in many cases, even approximate methods are outperformed. Conclusions: DFAs are a standard tool of computer science for the study of patterns, but so far they have been sparingly used in the study of biological motifs. Previous works do propose algorithms involving automata, but there they are used respectively as a first step to build a Finite Markov Chain Imbedding (FMCI), or to write a generating function: whereas we only rely on the concept of DFA to perform the calculations. This innovative approach can realistically be used for exact statistical studies of very long genomes and protein sequences, as we illustrate with some examples on the scale of the human genome.",Biology
"In the peripheral nervous system, utrophin and the short dystrophin isoform (Dp116) are co-localized at the outermost layer of the myelin sheath of nerve fibers; together with the dystroglycan complex. In peripheral nerve, matrix metalloproteinase (MMP) creates a 30 kDa fragment of beta-dystroglycan, leading to a disruption of the link between the extracellular matrix and the cell membrane. Here we asked if the processing of the beta-dystroglycan could influence the anchorage of Dp116 or/and utrophin in normal and mdx Schwann cell membrane. We showed that MMP-9 was more activated in mdx nerve than in wild-type one. This activation leads to an accumulation of the 30 kDa beta-dystroglycan isoform and have an impact on the anchorage of Dp116 and utrophin isoforms in mdx Schwann cells membrane. Our results showed that Dp116 had greater affinity to the full length form of beta-dystroglycan than the 30 kDa form. Moreover, we showed for the first time that the short isoform of utrophin (Up71) was over-expressed in mdx Schwann cells compared to wild-type. In addition, this utrophin isoform (Up71) seems to have greater affinity to the 30 kDa beta-dystroglycan which could explain a more stabilization of this 30 kDa at the membrane compartment. Our results highlight the potential participation of the short utrophin isoform and the cleaved form of beta-dystroglycan in mdx Schwann cell membrane architecture.",Biology
"The concept of (auto)catalytic systems has become a cornerstone in understanding evolutionary processes in various fields. The common ground is the observation that for the production of new species/goods/ideas/elements etc. the pre-existence of specific other elements is a necessary condition. In previous work some of us showed that the dynamics of the catalytic network equation can be understood in terms of topological recurrence relations paving a path towards the analytic tractability of notoriously high dimensional evolution equations. We apply this philosophy to studies in socio-physics, bio-diversity and massive events of creation and destruction in technological and biological networks. Cascading events, triggered by small exogenous fluctuations, lead to dynamics strongly resembling the qualitative picture of Schumpeterian economic evolution. Further we show that this new methodology allows to mathematically treat a variant of the threshold voter-model of opinion formation on networks. For fixed topology we find distinct phases of mixed opinions and consensus.",Biology
"This review deals with computer simulation of biological ageing, particularly with the Penna model of 1995.",Biology
"Is it possible to understand cancer? Or more specifically, is it possible to understand cancer from genetic side? There already many answers in literature. The most optimistic one has claimed that it is mission-possible. Duesberg and his colleagues reviewed the impressive amount of research results on cancer accumulated over 100 years. It confirms the a general opinion that considering all available experimental results and clinical observations there is no cancer theory without major difficulties, including the prevailing gene-based cancer theories. They have then listed 9 ""absolute discrepancies"" for such cancer theory. In this letter the quantitative evidence against one of their major reasons for dismissing mutation cancer theory, by both in vivo experiment and a first principle computation, is explicitly pointed out.",Biology
"In the present study, we show that ascorbic acid dose-dependently inhibited interleukin-1beta (IL-1beta)-mediated PGE2 synthesis in the human neuronal cell line, SK-N-SH. Furthermore, in combination with aspirin, ascorbic acid augmented the inhibitory effect of aspirin on PGE2 synthesis. However, ascorbic acid had no synergistic effect along with other COX inhibitors (SC-58125 and indomethacin). The inhibition of IL-1beta-mediated PGE2 synthesis by ascorbic acid was not due to the inhibition of the expression of COX-2 or microsomal prostaglandin E synthase (mPGES-1). Rather, ascorbic acid dose-dependently (0.1-100 microM) produced a significant reduction in IL-1beta-mediated production of 8-iso-prostaglandin F2alpha (8-iso-PGF2alpha), a reliable indicator of free radical formation, suggesting that the effects of ascorbic acid on COX-2-mediated PGE2 biosynthesis may be the result of the maintenance of the neuronal redox status since COX activity is known to be enhanced by oxidative stress. Our results provide in vitro evidence that the neuroprotective effects of ascorbic acid may depend, at least in part, on its ability to reduce neuronal COX-2 activity and PGE2 synthesis, owing to its antioxidant properties. Further, these experiments suggest that a combination of aspirin with ascorbic acid constitutes a novel approach to render COX-2 more sensitive to inhibition by aspirin, allowing an anti-inflammatory therapy with lower doses of aspirin, thereby avoiding the side effects of the usually high dose aspirin treatment.",Biology
"By explicitly representing the reaction times of discrete chemical systems as the firing times of independent, unit rate Poisson processes, we develop a new adaptive tau-leaping procedure. The procedure developed is novel in that accuracy is guaranteed by performing postleap checks. Because the representation we use separates the randomness of the model from the state of the system, we are able to perform the postleap checks in such a way that the statistics of the sample paths generated will not be biased by the rejections of leaps. Further, since any leap condition is ensured with a probability of one, the simulation method naturally avoids negative population values",Biology
"The spatial structure of populations is a key element in the understanding of the large scale spreading of epidemics. Motivated by the recent empirical evidence on the heterogeneous properties of transportation and commuting patterns among urban areas, we present a thorough analysis of the behavior of infectious diseases in metapopulation models characterized by heterogeneous connectivity and mobility patterns. We derive the basic reaction-diffusion equation describing the metapopulation system at the mechanistic level and derive an early stage dynamics approximation for the subpopulation invasion dynamics. The analytical description uses degree block variables that allows us to take into account arbitrary degree distribution of the metapopulation network. We show that along with the usual single population epidemic threshold the metapopulation network exhibits a global threshold for the subpopulation invasion. We find an explicit analytic expression for the invasion threshold that determines the minimum number of individuals traveling among subpopulations in order to have the infection of a macroscopic number of subpopulations. The invasion threshold is a function of factors such as the basic reproductive number, the infectious period and the mobility process and it is found to decrease for increasing network heterogeneity. We provide extensive mechanistic numerical Monte Carlo simulations that recover the analytical finding in a wide range of metapopulation network connectivity patterns. The results can be useful in the understanding of recent data driven computational approaches to disease spreading in large transportation networks and the effect of containment measures such as travel restrictions.",Biology
"The fold recognition methods are promissing tools for capturing the structure of a protein by its amino acid residues sequence but their use is still restricted by the needs of huge computational resources and suitable efficient algorithms as well. In the recent version of FROST (Fold Recognition Oriented Search Tool) package the most efficient algorithm for solving the Protein Threading Problem (PTP) is implemented due to the strong collaboration between the SYMBIOSE group in IRISA and MIG in Jouy-en-Josas. In this paper, we present the diverse components of FROST, emphasizing on the recent advances in formulating and solving new versions of the PTP and on the way of solving on a computer cluster a million of instances in a easonable time.",Biology
"We analyzed folding routes predicted by a variational model in terms of a generalized formalism of the capillarity scaling theory for 28 two-state proteins. The scaling exponent ranged from 0.2 to 0.45 with an average of 0.33. This average value corresponds to packing of rigid objects.That is, on average the folded core of the nucleus is found to be relatively diffuse. We also studied the growth of the folding nucleus and interface along the folding route in terms of the density or packing fraction. The evolution of the folded core and interface regions can be classified into three patterns of growth depending on how the growth of the folded core is balanced by changes in density of the interface. Finally, we quantified the diffuse versus polarized structure of the critical nucleus through direct calculation of the packing fraction of the folded core and interface regions. Our results support the general picture of describing protein folding as the capillarity-like growth of folding nuclei.",Biology
"Biodiversity is essential to the viability of ecological systems. Species diversity in ecosystems is promoted by cyclic, non-hierarchical interactions among competing populations. Such non-transitive relations lead to an evolution with central features represented by the `rock-paper-scissors' game, where rock crushes scissors, scissors cut paper, and paper wraps rock. In combination with spatial dispersal of static populations, this type of competition results in the stable coexistence of all species and the long-term maintenance of biodiversity. However, population mobility is a central feature of real ecosystems: animals migrate, bacteria run and tumble. Here, we observe a critical influence of mobility on species diversity. When mobility exceeds a certain value, biodiversity is jeopardized and lost. In contrast, below this critical threshold all subpopulations coexist and an entanglement of travelling spiral waves forms in the course of temporal evolution. We establish that this phenomenon is robust, it does not depend on the details of cyclic competition or spatial environment. These findings have important implications for maintenance and evolution of ecological systems and are relevant for the formation and propagation of patterns in excitable media, such as chemical kinetics or epidemic outbreaks.",Biology
"Codon usage bias measure is defined through the mutual entropy calculation of real codon frequency distribution against the quasi-equilibrium one. This latter is defined in three manners: (1) the frequency of synonymous codons is supposed to be equal (i.e., the arithmetic mean of their frequencies); (2) it coincides to the frequency distribution of triplets; and, finally, (3) the quasi-equilibrium frequency distribution is defined as the expected frequency of codons derived from the dinucleotide frequency distribution. The measure of bias in codon usage is calculated for 125 bacterial genomes.",Biology
"We investigate the mechanisms of histone sliding and detachment with a stochastic model that couples thermally-induced, passive histone sliding with active motor-driven histone unwrapping. Analysis of a passive loop or twist defect-mediated histone sliding mechanism shows that diffusional sliding is enhanced as larger portions of the DNA is peeled off the histone. The mean times to histone detachment and the mean distance traveled by the motor complex prior to histone detachment are computed as functions of the intrinsic speed of the motor. Fast motors preferentially induce detachment over sliding. However, for a fixed motor speed, increasing the histone-DNA affinity (and thereby decreasing the passive sliding rate) increases the mean distance traveled by the motor.",Biology
"The entropy production rate of cancer cell is always higher than healthy cell under the case of no external field applied. Different entropy production between two kinds of cells determines the direction of entropy flow among cells. The entropy flow is the carrier of information flow. The entropy flow from cancer to healthy cell takes along the harmful information of cancerous cell, propagating its toxic action to healthy tissues. We demonstrate that a low-frequency and low-intensity electromagnetic field or ultrasound irradiation may increase the entropy production rate of a cell in normal tissue than that in cancer, consequently reverse the direction of entropy current between two kinds of cells. The modification of PH value of cells may also cause the reversal of the direction of entropy flow between healthy and cancerous cells. So, the biological tissue under the irradiation of electromagnetic field or ultrasound or under the appropriate change of cell acidity can avoid the propagation of harmful information from cancer cells. We suggest that this entropy mechanism possibly provides a basis for a novel approach to anticancer therapy.",Biology
"Strong experimental and theoretical evidence shows that transcription factors and other specific DNA-binding proteins find their sites using a two-mode search: alternating between 3D diffusion through the cell and 1D sliding along the DNA. We consider the role spatial effects in the mechanism on two different scales. First, we reconcile recent experimental findings by showing that the 3D diffusion of the transcription factor is often local, i.e. the transcription factor lands quite near its dissociation site. Second, we discriminate between two types of searches: global searches and local searches. We show that these searches differ significantly in average search time and the variability of search time. Using experimentally measured parameter values, we also show that 1D and 3D search is not optimally balanced, leading to much larger estimates of search time. Together, these results lead to a number of biological implications including suggestions of how prokaryotes and eukaryotes achieve rapid gene regulation and the relationship between the search mechanism and noise in gene expression.",Biology
"The occurrence of a critical period of plasticity in the visual cortex has long been established, yet its function in normal development is not fully understood. Here we show that as the late phase of the critical period unfolds, different areas of cat visual cortex develop in a coordinated manner. Orientation columns in areas V1 and V2 become matched in size in regions that are mutually connected. The same age trend is found for such regions in the left and right brain hemisphere. Our results indicate that a function of critical period plasticity is to progressively coordinate the functional architectures of different cortical areas - even across hemispheres.",Biology
"Bacterial chemotaxis in Escherichia coli is a canonical system for the study of signal transduction. A remarkable feature of this system is the coexistence of precise adaptation in population with large fluctuating cellular behavior in single cells (Korobkova et al. 2004, Nature, 428, 574). Using a stochastic model, we found that the large behavioral variability experimentally observed in non-stimulated cells is a direct consequence of the architecture of this adaptive system. Reversible covalent modification cycles, in which methylation and demethylation reactions antagonistically regulate the activity of receptor-kinase complexes, operate outside the region of first-order kinetics. As a result, the receptor-kinase that governs cellular behavior exhibits a sigmoidal activation curve. This curve simultaneously amplifies the inherent stochastic fluctuations in the system and lengthens the relaxation time in response to stimulus. Because stochastic fluctuations cause large behavioral variability and the relaxation time governs the average duration of runs in response to small stimuli, cells with the greatest fluctuating behavior also display the largest chemotactic response. Finally, Large-scale simulations of digital bacteria suggest that the chemotaxis network is tuned to simultaneously optimize the random spread of cells in absence of nutrients and the cellular response to gradients of attractant.",Biology
"A model for epidemics on an adaptive network is considered. Nodes follow an SIRS (susceptible-infective-recovered-susceptible) pattern. Connections are rewired to break links from non-infected nodes to infected nodes and are reformed to connect to other non-infected nodes, as the nodes that are not infected try to avoid the infection. Monte Carlo simulation and numerical solution of a mean field model are employed. The introduction of rewiring affects both the network structure and the epidemic dynamics. Degree distributions are altered, and the average distance from a node to the nearest infective increases. The rewiring leads to regions of bistability where either an endemic or a disease-free steady state can exist. Fluctuations around the endemic state and the lifetime of the endemic state are considered. The fluctuations are found to exhibit power law behavior.",Biology
"How can a microorganism adapt to a variety of environmental conditions despite there exists a limited number of signal transduction machineries? We show that for any growing cells whose gene expression is under stochastic fluctuations, adaptive cellular state is inevitably selected by noise, even without specific signal transduction network for it. In general, changes in protein concentration in a cell are given by its synthesis minus dilution and degradation, both of which are proportional to the rate of cell growth. In an adaptive state with a higher growth speed, both terms are large and balanced. Under the presence of noise in gene expression, the adaptive state is less affected by stochasticity since both the synthesis and dilution terms are large, while for a non-adaptive state both the terms are smaller so that cells are easily kicked out of the original state by noise. Hence, escape time from a cellular state and the cellular growth rate are negatively correlated. This leads to a selection of adaptive states with higher growth rates, and model simulations confirm this selection to take place in general. The results suggest a general form of adaptation that has never been brought to light - a process that requires no specific machineries for sensory adaptation. The present scheme may help explain a wide range of cellular adaptive responses including the metabolic flux optimization for maximal cell growth.",Biology
"Human language and its governing rules present a number of analogies with the organization and structure of communication and information management in living organisms. This chapter will provide a short general introduction about grammar, as well as a brief explanation on how linguistic approaches effectively contaminate scientific practice, and, finally, how they can also provide systems biology with further tools and paradigms to analyse emergent behaviours and interactions among the components of a biological system.",Biology
"We prove that Nakhleh's latest dissimilarity measure for phylogenetic networks separates distinguishable phylogenetic networks, and that a slight modification of it provides a true distance on the class of all phylogenetic networks.",Biology
"In recent years, several authors have used probabilistic graphical models to learn expression modules and their regulatory programs from gene expression data. Here, we demonstrate the use of the synthetic data generator SynTReN for the purpose of testing and comparing module network learning algorithms. We introduce a software package for learning module networks, called LeMoNe, which incorporates a novel strategy for learning regulatory programs. Novelties include the use of a bottom-up Bayesian hierarchical clustering to construct the regulatory programs, and the use of a conditional entropy measure to assign regulators to the regulation program nodes. Using SynTReN data, we test the performance of LeMoNe in a completely controlled situation and assess the effect of the methodological changes we made with respect to an existing software package, namely Genomica. Additionally, we assess the effect of various parameters, such as the size of the data set and the amount of noise, on the inference performance. Overall, application of Genomica and LeMoNe to simulated data sets gave comparable results. However, LeMoNe offers some advantages, one of them being that the learning process is considerably faster for larger data sets. Additionally, we show that the location of the regulators in the LeMoNe regulation programs and their conditional entropy may be used to prioritize regulators for functional validation, and that the combination of the bottom-up clustering strategy with the conditional entropy-based assignment of regulators improves the handling of missing or hidden regulators.",Biology
"Metabolism of arachidonic acid by cyclooxygenase is one of the primary sources of reactive oxygen species in the ischemic brain. Neuronal overexpression of cyclooxygenase-2 has recently been shown to contribute to neurodegeneration following ischemic injury. In the present study, we examined the possibility that the neuroprotective effects of the cyclooxygenase-2 inhibitor nimesulide would depend upon reduction of oxidative stress following cerebral ischemia. Gerbils were subjected to 5 min of transient global cerebral ischemia followed by 48 h of reperfusion and markers of oxidative stress were measured in hippocampus of gerbils receiving vehicle or nimesulide treatment at three different clinically relevant doses (3, 6 or 12 mg/kg). Compared with vehicle, nimesulide significantly (P<0.05) reduced hippocampal glutathione depletion and lipid peroxidation, as assessed by the levels of malondialdehyde (MDA), 4-hydroxy-alkenals (4-HDA) and lipid hydroperoxides levels, even when the treatment was delayed until 6 h after ischemia. Biochemical evidences of nimesulide neuroprotection were supported by histofluorescence findings using the novel marker of neuronal degeneration Fluoro-Jade B. Few Fluoro-Jade B positive cells were seen in CA1 region of hippocampus in ischemic animals treated with nimesulide compared with vehicle. These results suggest that nimesulide may protect neurons by attenuating oxidative stress and reperfusion injury following the ischemic insult with a wide therapeutic window of protection.",Biology
"Persistent activity is postulated to drive neural network plasticity and learning. To investigate its underlying cellular mechanisms, we developed a biophysically tractable model that explains the emergence, sustenance, and eventual termination of short-term persistent activity. Using the model, we reproduced the features of reverberating activity that were observed in small (50-100 cells) networks of cultured hippocampal neurons, such as the appearance of polysynaptic current clusters, the typical inter-cluster intervals, the typical duration of reverberation, and the response to changes in extra-cellular ionic composition. The model relies on action potential-triggered residual presynaptic calcium, which we suggest plays an important role in sustaining reverberations. We show that reverberatory activity is maintained by enhanced asynchronous transmitter release from pre-synaptic terminals, which in itself depends on the dynamics of residual presynaptic calcium. Hence, asynchronous release, rather than being a ""synaptic noise"", can play an important role in network dynamics. Additionally, we found that a fast timescale synaptic depression is responsible for oscillatory network activation during reverberations, whereas the onset of a slow timescale depression leads to the termination of reverberation. The simplicity of our model enabled a number of predictions that were confirmed by additional analyses of experimental manipulations.",Biology
"The flexibility in gap cost enjoyed by Hidden Markov Models (HMMs) is expected to afford them better retrieval accuracy than position-specific scoring matrices (PSSMs). We attempt to quantify the effect of more general gap parameters by separately examining the influence of position- and composition-specific gap scores, as well as by comparing the retrieval accuracy of the PSSMs constructed using an iterative procedure to that of the HMMs provided by Pfam and SUPERFAMILY, curated ensembles of multiple alignments.   We found that position-specific gap penalties have an advantage over uniform gap costs. We did not explore optimizing distinct uniform gap costs for each query. For Pfam, PSSMs iteratively constructed from seeds based on HMM consensus sequences perform equivalently to HMMs that were adjusted to have constant gap transition probabilities, albeit with much greater variance. We observed no effect of composition-specific gap costs on retrieval performance.",Biology
"Specific binding of proteins to DNA is one of the most common ways in which gene expression is controlled. Although general rules for the DNA-protein recognition can be derived, the ambiguous and complex nature of this mechanism precludes a simple recognition code, therefore the prediction of DNA target sequences is not straightforward. DNA-protein interactions can be studied using computational methods which can complement the current experimental methods and offer some advantages. In the present work we use physical effective potentials to evaluate the DNA-protein binding affinities for the lambda repressor-DNA complex for which structural and thermodynamic experimental data are available. The effect of conformational sampling by Molecular Dynamics simulations on the computed binding energy is assessed; results show that this effect is in general negative and the reproducibility of the experimental values decreases with the increase of simulation time considered. The free energy of binding for non-specific complexes agrees with earlier theoretical suggestions. Moreover, as a results of these analyses, we propose a protocol for the prediction of DNA-binding target sequences. The possibility of searching regulatory elements within the bacteriophage-lambda genome using this protocol is explored. Our analysis shows good prediction capabilities, even in the absence of any thermodynamic data and information on the naturally recognized sequence. This study supports the conclusion that physics-based methods can offer a completely complementary methodology to sequence-based methods for the identification of DNA-binding protein target sequences.",Biology
A discrete time model that is capable of replicating the basic features of cardiac cell action potentials is suggested. The paper shows how the map-based approaches can be used to design highly efficient computational models (algorithms) that enable large-scale simulations and analysis of discrete network models of cardiac activity.,Biology
"Protein-DNA complexes with loops play a fundamental role in a wide variety of cellular processes, ranging from the regulation of DNA transcription to telomere maintenance. As ubiquitous as they are, their precise in vivo properties and their integration into the cellular function still remain largely unexplored. Here, we present a multilevel approach that efficiently connects in both directions molecular properties with cell physiology and use it to characterize the molecular properties of the looped DNA-lac repressor complex while functioning in vivo. The properties we uncover include the presence of two representative conformations of the complex, the stabilization of one conformation by DNA architectural proteins, and precise values of the underlying twisting elastic constants and bending free energies. Incorporation of all this molecular information into gene-regulation models reveals an unprecedented versatility of looped DNA-protein complexes at shaping the properties of gene expression.",Biology
"The multiple worlds of genetically manipulated laboratory organisms such as transgenic mice or worms with certain gene mutations are somewhat reminiscent of parallel worlds in quantum mechanics. So are various models of aging tested in such organisms. In this context, the tumor suppressor p53 has been found to either accelerate or delay aging, the latter, for instance, in conjunction with ARF, another tumor suppressor, as shown very recently. To more easily determine which of these artificial settings comes closest to real life, I discuss here their features in the light of my protein structure-based insights that have led me to propose a physiological anti-aging role for the retinoblastoma tumor suppressor protein (RB) over the past four years.",Biology
"Background The epidermal growth factor receptor (EGFR) is frequently overexpressed in many cancers, including non-small cell lung cancer (NSCLC). In silcio modeling is considered to be an increasingly promising tool to add useful insights into the dynamics of the EGFR signal transduction pathway. However, most of the previous modeling work focused on the molecular or the cellular level only, neglecting the crucial feedback between these scales as well as the interaction with the heterogeneous biochemical microenvironment.   Results We developed a multiscale model for investigating expansion dynamics of NSCLC within a two-dimensional in silico microenvironment. At the molecular level, a specific EGFR-ERK intracellular signal transduction pathway was implemented. Dynamical alterations of these molecules were used to trigger phenotypic changes at the cellular level. Examining the relationship between extrinsic ligand concentrations, intrinsic molecular profiles and microscopic patterns, the results confirmed that increasing the amount of available growth factor leads to a spatially more aggressive cancer system. Moreover, for the cell closest to nutrient abundance, a phase-transition emerges where a minimal increase in extrinsic ligand abolishes the proliferative phenotype altogether.   Conclusions Our in silico results indicate that, in NSCLC, in the presence of a strong extrinsic chemotactic stimulus, and depending on the cell's location, downstream EGFR-ERK signaling may be processed more efficiently, thereby yielding a migration-dominant cell phenotype and overall, an accelerated spatio-temporal expansion rate.",Biology
"We present the results of our numerical analysis of a ""composite"" model of DNA which generalizes a well-known elementary torsional model of Yakushevich by allowing bases to move independently from the backbone. The model shares with the Yakushevich model many features and results but it represents an improvement from both the conceptual and the phenomenological point of view. It provides a more realistic description of DNA and possibly a justification for the use of models which consider the DNA chain as uniform. It shows that the existence of solitons is a generic feature of the underlying nonlinear dynamics and is to a large extent independent of the detailed modelling of DNA. As opposite to the Yakushevich model, where it is needed to use an unphysical value for the torsion in order to induce the correct velocity of sound, the model we consider supports solitonic solutions, qualitatively and quantitatively very similar to the Yakushevich solitons, in a fully realistic range of all the physical parameters characterizing the DNA.",Biology
"The present paper is devoted to foundations of p-adic modelling in genomics. Considering nucleotides, codons, DNA and RNA sequences, amino acids, and proteins as information systems, we have formulated the corresponding p-adic formalisms for their investigations. Each of these systems has its characteristic prime number used for construction of the related information space. Relevance of this approach is illustrated by some examples. In particular, it is shown that degeneration of the genetic code is a p-adic phenomenon. We have also put forward a hypothesis on evolution of the genetic code assuming that primitive code was based on single nucleotides and chronologically first four amino acids. This formalism of p-adic genomic information systems can be implemented in computer programs and applied to various concrete cases.",Biology
"There are many processes in biology in which mechanical forces are generated. Force-bearing networks can transduce locally developed mechanical signals very extensively over different parts of the cell or tissues. In this article we conduct an overview of this kind of mechanical transduction, focusing in particular on the multiple layers of complexity displayed by the mechanisms that control and trigger the conversion of a mechanical signal into a biochemical function. Single molecule methodologies, through their capability to introduce the force in studies of biological processes in which mechanical stresses are developed, are unveiling subtle intertwining mechanisms between chemistry and mechanics and in particular are revealing how chemistry can control mechanics. The possibility that chemistry interplays with mechanics should be always considered in biochemical studies.",Biology
"In many stochastic simulations of biochemical reaction networks, it is desirable to ``coarse-grain'' the reaction set, removing fast reactions while retaining the correct system dynamics. Various coarse-graining methods have been proposed, but it remains unclear which methods are reliable and which reactions can safely be eliminated. We address these issues for a model gene regulatory network that is particularly sensitive to dynamical fluctuations: a bistable genetic switch. We remove protein-DNA and/or protein-protein association-dissociation reactions from the reaction set, using various coarse-graining strategies. We determine the effects on the steady-state probability distribution function and on the rate of fluctuation-driven switch flipping transitions. We find that protein-protein interactions may be safely eliminated from the reaction set, but protein-DNA interactions may not. We also find that it is important to use the chemical master equation rather than macroscopic rate equations to compute effective propensity functions for the coarse-grained reactions.",Biology
"As in many other areas of science, systems biology makes extensive use of statistical association and significance estimates in contingency tables, a type of categorical data analysis known in this field as enrichment (also over-representation or enhancement) analysis. In spite of efforts to create probabilistic annotations, especially in the Gene Ontology context, or to deal with uncertainty in high throughput-based datasets, current enrichment methods largely ignore this probabilistic information since they are mainly based on variants of the Fisher Exact Test. We developed an open-source R package to deal with probabilistic categorical data analysis, ProbCD, that does not require a static contingency table. The contingency table for the enrichment problem is built using the expectation of a Bernoulli Scheme stochastic process given the categorization probabilities. An on-line interface was created to allow usage by non-programmers and is available at: http://xerad.systemsbiology.net/ProbCD/ . We present an analysis framework and software tools to address the issue of uncertainty in categorical data analysis. In particular, concerning the enrichment analysis, ProbCD can accommodate: (i) the stochastic nature of the high-throughput experimental techniques and (ii) probabilistic gene annotation.",Biology
"A synfire chain is a simple neural network model which can propagate stable synchronous spikes called a pulse packet and widely researched. However how synfire chains coexist in one network remains to be elucidated. We have studied the activity of a layered associative network of Leaky Integrate-and-Fire neurons in which connection we embed memory patterns by the Hebbian Learning. We analyzed their activity by the Fokker-Planck method. In our previous report, when a half of neurons belongs to each memory pattern (memory pattern rate $F=0.5$), the temporal profiles of the network activity is split into temporally clustered groups called sublattices under certain input conditions. In this study, we show that when the network is sparsely connected ($F<0.5$), synchronous firings of the memory pattern are promoted. On the contrary, the densely connected network ($F>0.5$) inhibit synchronous firings. The sparseness and denseness also effect the basin of attraction and the storage capacity of the embedded memory patterns. We show that the sparsely(densely) connected networks enlarge(shrink) the basion of attraction and increase(decrease) the storage capacity.",Biology
"Virus trafficking is fundamental for infection success and plasmid cytosolic trafficking is a key step of gene delivery. Based on the main physical properties of the cellular transport machinery such as microtubules, motor proteins, our goal here is to derive a mathematical model to study cytoplasmic trafficking. Because experimental results reveal that both active and passive movement are necessary for a virus to reach the cell nucleus, by taking into account the complex interactions of the virus with the microtubules, we derive here an estimate of the mean time a virus reaches the nucleus. In particular, we present a mathematical procedure in which the complex viral movement, oscillating between pure diffusion and a deterministic movement along microtubules, can be approximated by a steady state stochastic equation with a constant effective drift. An explicit expression for the drift amplitude is given as a function of the real drift, the density of microtubules and other physical parameters. The present approach can be used to model viral trafficking inside the cytoplasm, which is a fundamental step of viral infection, leading to viral replication and in some cases to cell damage.",Biology
"We investigate the effects of risk perception in a simple model of epidemic spreading. We assume that the perception of the risk of being infected depends on the fraction of neighbors that are ill. The effect of this factor is to decrease the infectivity, that therefore becomes a dynamical component of the model. We study the problem in the mean-field approximation and by numerical simulations for regular, random and scale-free networks.   We show that for homogeneous and random networks, there is always a value of perception that stops the epidemics. In the ``worst-case'' scenario of a scale-free network with diverging input connectivity, a linear perception cannot stop the epidemics; however we show that a non-linear increase of the perception risk may lead to the extinction of the disease. This transition is discontinuous, and is not predicted by the mean-field analysis.",Biology
Hot spots in tumors are regions of high vascular density in the center of the tumor and their analysis is an important diagnostic tool in cancer treatment. We present a model for vascular remodeling in tumors predicting that the formation of hot spots correlates with local inhomogeneities of the original arterio-venous vasculature of the healthy tissue. Probable locations for hot spots in the late stages of the tumor are locations of increased blood pressure gradients. The developing tumor vasculature is non-hierarchical but still complex displaying algebraically decaying density distributions.,Biology
"In a recent article, Desai and Fisher (2007) proposed that the speed of adaptation in an asexual population is determined by the dynamics of the stochastic edge of the population, that is, by the emergence and subsequent establishment of rare mutants that exceed the fitness of all sequences currently present in the population. Desai and Fisher perform an elaborate stochastic calculation of the mean time $\tau$ until a new class of mutants has been established, and interpret $1/\tau$ as the speed of adaptation. As they note, however, their calculations are valid only for moderate speeds. This limitation arises from their method to determine $\tau$: Desai and Fisher back-extrapolate the value of $\tau$ from the best-fit class' exponential growth at infinite time. This approach is not valid when the population adapts rapidly, because in this case the best-fit class grows non-exponentially during the relevant time interval. Here, we substantially extend Desai and Fisher's analysis of the stochastic edge. We show that we can apply Desai and Fisher's method to high speeds by either exponentially back-extrapolating from finite time or using a non-exponential back-extrapolation. Our results are compatible with predictions made using a different analytical approach (Rouzine et al. 2003, 2007), and agree well with numerical simulations.",Biology
"The distribution of fitness effects of adaptive mutations remains poorly understood, both empirically and theoretically. We study this distribution using a version of Fisher's geometrical model without pleiotropy, such that each mutation affects only a single trait. We are motivated by the notion of an organism's chemotype, the set of biochemical reaction constants that govern its molecular constituents. From physical considerations, we expect the chemotype to be of high dimension and to exhibit very little pleiotropy. Our model generically predicts striking cusps in the distribution of the fitness effects of arising and fixed mutations. It further predicts that a single element of the chemotype should comprise all mutations at the high-fitness ends of these distributions. Using extreme value theory, we show that the two cusps with the highest fitnesses are typically well-separated, even when the chemotype possesses thousands of elements; this suggests a means to observe these cusps experimentally. More broadly, our work demonstrates that new insights into evolution can arise from the chemotype perspective, a perspective between the genotype and the phenotype.",Biology
"Initial reaction rate data for lactic dehydrogenase / pyruvate, lactic dehydrogenase / lactate and malic dehydrogenase / malate enzyme reactions were analyzed to obtain activation free energy changes of -329, -195 and -221 cal/mole, respectively, for rate increases associated with time-specific irradiation of the crystalline substrates prior to dissolution and incorporation in the reaction solutions. These energies, presumably, correspond to conformational or vibrational changes in the reactants or the activated complex. For the lactic dehydrogenase / pyruvate reaction, it is estimated that on the order of 10% of the irradiation energy (546 nm, 400 footcandles for 5 seconds) would be required to produce the observed reaction rate increase if a presumed photoproduct is consumed stoichiometrically with the pyruvate substrate. These findings are consistent with the proposition that the observed reaction rate enhancement involves photoproducts derived from oscillatory atmospheric gas reactions at the crystalline enzyme substrate surfaces rather than photo-excitations of the substrate molecules, per se.",Biology
We consider a probabilistic cellular automaton to analyze the stochastic dynamics of a predator-prey system. The local rules are Markovian and are based in the Lotka-Volterra model. The individuals of each species reside on the sites of a lattice and interact with an unsymmetrical neighborhood. We look for the effect of the space anisotropy in the characterization of the oscillations of the species population densities. Our study of the probabilistic cellular automaton is based on simple and pair mean-field approximations and explicitly takes into account spatial anisotropy.,Biology
"We discuss the task of reconstructing the topological map of an environment based on the sequences of locations visited by a mobile agent -- this occurs in systems neuroscience, where one runs into the task of reconstructing the global topological map of the environment based on activation patterns of the place coding cells in hippocampus area of the brain. A similar task appears in the context of establishing wifi connectivity maps.",Biology
"Over the brief time intervals available for processing retinal output, roughly 50 to 300 msec, the number of extra spikes generated by individual ganglion cells can be quite variable. Here, computer-generated spike trains were used to investigate how signal/noise might be improved by utilizing spatiotemporal correlations among retinal neurons responding to large, contiguous stimuli. Realistic correlations were produced by modulating the instantaneous firing probabilities of all stimulated neurons by a common oscillatory input whose amplitude and temporal structure were consistent with experimentally measured field potentials and correlograms. Whereas previous studies have typically measured synergy between pairs of ganglion cells examined one at a time, or alternatively have employed optimized linear filters to decode activity across larger populations, the present study investigated a distributed, non-linear encoding strategy by using Principal Components Analysis (PCA) to reconstruct simple visual stimuli from up to one million oscillatory pairwise correlations extracted on single trials from massively-parallel spike trains as short as 25 msec in duration. By integrating signals across retinal neighborhoods commensurate in size to classical antagonistic surrounds, the first principal component of the pairwise correlation matrix yielded dramatic improvements in signal/noise without sacrificing fine spatial detail. These results demonstrate how local intensity information can distributed across hundreds of neurons linked by a common, stimulus-dependent oscillatory modulation, a strategy that might have evolved to minimize the number of spikes required to support rapid image reconstruction.",Biology
"Genomes evolve as modules. In prokaryotes (and some eukaryotes), genetic material can be transferred between species and integrated into the genome via homologous or illegitimate recombination. There is little reason to imagine that the units of transfer correspond to entire genes; however, such units have not been rigorously characterized. We examined fragmentary genetic transfers in single-copy gene families from 144 prokaryotic genomes and found that breakpoints are located significantly closer to the boundaries of genomic regions that encode annotated structural domains of proteins than expected by chance, particularly when recombining sequences are more divergent. This correlation results from recombination events themselves and not from differential nucleotide substitution. We report the first systematic study relating genetic recombination to structural features at the protein level.",Biology
"The popular neighbor-joining (NJ) algorithm used in phylogenetics is a greedy algorithm for finding the balanced minimum evolution (BME) tree associated to a dissimilarity map. From this point of view, NJ is ``optimal'' when the algorithm outputs the tree which minimizes the balanced minimum evolution criterion. We use the fact that the NJ tree topology and the BME tree topology are determined by polyhedral subdivisions of the spaces of dissimilarity maps ${\R}_{+}^{n \choose 2}$ to study the optimality of the neighbor-joining algorithm. In particular, we investigate and compare the polyhedral subdivisions for $n \leq 8$. A key requirement is the measurement of volumes of spherical polytopes in high dimension, which we obtain using a combination of Monte Carlo methods and polyhedral algorithms. We show that highly unrelated trees can be co-optimal in BME reconstruction, and that NJ regions are not convex. We obtain the $l_2$ radius for neighbor-joining for $n=5$ and we conjecture that the ability of the neighbor-joining algorithm to recover the BME tree depends on the diameter of the BME tree.",Biology
"Bubbles in ion channel proteins have been proposed to be the bistable gates that control current flow. Gating currents associated with channel gating would then be an electrical signature of bubble breaking and formation, arising from the change in dielectric coefficient as the bubble breaks or forms. A bubble would have a dielectric coefficient of 1. A filled bubble would have a dielectric coefficient (say) between 30 and 80. Transporters, pumps, and channels would be expected to have gating currents.",Biology
"Single molecule data made of on and off events are ubiquitous. Famous examples include enzyme turnover, probed via fluorescence, and opening and closing of ion-channel, probed via the flux of ions. The data reflects the dynamics in the underlying multi-substate on-off kinetic scheme (KS) of the process, but the determination of the underlying KS is difficult, and sometimes even impossible, due to the loss of information in the mapping of the mutli-dimensional KS onto two dimensions. A way to deal with this problem considers canonical (unique) forms. (Unique canonical form is constructed from an infinitely long trajectory, but many KSs.) Here we introduce canonical forms of reduced dimensions that can handle any KS (i.e. also KSs with symmetry and irreversible transitions). We give the mapping of KSs into reduced dimensions forms, which is based on topology of KSs, and the tools for extracting the reduced dimensions form from finite data. The canonical forms of reduced dimensions constitute a powerful tool in discriminating between KSs.",Biology
"A primordial genetic code is proposed, having only four codons assigned, GGC meaning glycine, GAC meaning aspartate/glutamate, GCC meaning alanine-like and GUC meaning valine-like. Pathways of ambiguity reduction enlarged the codon repertoire with CUC meaning leucine, AUC meaning isoleucine, ACC meaning threonine-like and GAG meaning glutamate. Introduction of UNN anticodons, in a next episode of code evolution in which nonsense elimination was the leading theme, introduced a family box structure superposed on the original mirror structure. Finally, growth rate was the leading theme during the remaining repertoire expansion, explaining the ordered phylogenetic pattern of aminoacyl-tRNA synthetases. The special role of natural aptamers in the process is high-lighted, and the error robustness characteristics of the code are shown to have evolved by way of a stepwise, restricted enlargement of the tRNA repertoire, instead of by an exhaustive selection process testing myriads of codes.",Biology
"The genetic repressilator circuit consists of three transcription factors, or repressors, which negatively regulate each other in a cyclic manner. This circuit was synthetically constructed on plasmids in {\it Escherichia coli} and was found to exhibit oscillations in the concentrations of the three repressors. Since the repressors and their binding sites often appear in low copy numbers, the oscillations are noisy and irregular. Therefore, the repressilator circuit cannot be fully analyzed using deterministic methods such as rate-equations. Here we perform stochastic analysis of the repressilator circuit using the master equation and Monte Carlo simulations. It is found that fluctuations modify the range of conditions in which oscillations appear as well as their amplitude and period, compared to the deterministic equations. The deterministic and stochastic approaches coincide only in the limit in which all the relevant components, including free proteins, plasmids and bound proteins, appear in high copy numbers. We also find that subtle features such as cooperative binding and bound-repressor degradation strongly affect the existence and properties of the oscillations.",Biology
"Sensitivity analysis is an effective tool for systematically identifying specific perturbations in parameters that have significant effects on the behavior of a given biosystem, at the scale investigated. In this work, using a two-dimensional, multiscale non-small cell lung cancer (NSCLC) model, we examine the effects of perturbations in system parameters which span both molecular and cellular levels, i.e. across scales of interest. This is achieved by first linking molecular and cellular activities and then assessing the influence of parameters at the molecular level on the tumor's spatio-temporal expansion rate, which serves as the output behavior at the cellular level. Overall, the algorithm operated reliably over relatively large variations of most parameters, hence confirming the robustness of the model. However, three pathway components (proteins PKC, MEK, and ERK) and eleven reaction steps were determined to be of critical importance by employing a sensitivity coefficient as an evaluation index. Each of these sensitive parameters exhibited a similar changing pattern in that a relatively larger increase or decrease in its value resulted in a lesser influence on the system's cellular performance. This study provides a novel cross-scaled approach to analyzing sensitivities of computational model parameters and proposes its application to interdisciplinary biomarker studies.",Biology
Long range charge transfer experiments in DNA oligomers and the subsequently measured -- and very diverse -- transport response of DNA wires in solid state experiments exemplifies the need for a thorough theoretical understanding of charge migration in DNA-based natural and artificial materials. Here we present a review of tight-binding models for DNA conduction which have the intrinsic merit of containing more structural information than plain rate-equation models while still retaining sufficient detail of the electronic properties. This allows for simulations of transport properties to be more manageable with respect to density functional theory methods or correlated first principle algorithms.,Biology
"A mutator is an allele that increases the mutation rate throughout the genome by disrupting some aspect of DNA replication or repair. Mutators that increase the mutation rate by the order of 100 fold have been observed to spontaneously emerge and achieve high frequencies in natural populations and in long-term laboratory evolution experiments with \textit{E. coli}. In principle, the fixation of mutator alleles is limited by (i) competition with mutations in wild-type backgrounds, (ii) additional deleterious mutational load, and (iii) random genetic drift. Using a multiple locus model and employing both simulation and analytic methods, we investigate the effects of these three factors on the fixation probability $P_{fix}$ of an initially rare mutator as a function of population size $N$, beneficial and deleterious mutation rates, and the strength of mutations $s$. Our diffusion based approximation for $P_{fix}$ successfully captures effects (ii) and (iii) when selection is fast compared to mutation ($\mu/s \ll 1$). This enables us to predict the conditions under which mutators will be evolutionarily favored. Surprisingly, our simulations show that effect (i) is typically small for strong-effect mutators. Our results agree semi-quantitatively with existing laboratory evolution experiments and suggest future experimental directions.",Biology
"We demonstrate a new algorithm for finding protein conformations that minimize a non-bonded energy function. The new algorithm, called the difference map, seeks to find an atomic configuration that is simultaneously in two constraint spaces. The first constraint space is the space of atomic configurations that have a valid peptide geometry, while the second is the space of configurations that have a non-bonded energy below a given target. These two constraint spaces are used to define a deterministic dynamical system, whose fixed points produce atomic configurations in the intersection of the two constraint spaces. The rate at which the difference map produces low energy protein conformations is compared with that of a contemporary search algorithm, parallel tempering. The results indicate the difference map finds low energy protein conformations at a significantly higher rate then parallel tempering.",Biology
"The transfer of genetic materials across species (lateral genetic transfer, LGT) contributes to genomic and physiological innovation in prokaryotes. The extent of LGT in prokaryotes has been examined in a number of studies, but the unit of transfer has not been studied in a rigorous manner. Using a rigorous phylogenetic approach, we analysed the units of LGT within families of single-copy genes obtained from 144 fully sequenced prokaryote genomes. A total of 30.3% of these gene families show evidence of LGT. We found that the transfer of gene fragments has been more frequent than the transfer of entire genes, suggesting the extent of LGT has been underestimated. We found little functional bias between within-gene (fragmentary) and whole-gene (non-fragmentary) genetic transfer, but non-fragmentary transfer has been more frequent into pathogens than into non-pathogens. As gene families that contain probable paralogs were excluded from the current study, our results may still underestimate the extent of LGT; nonetheless this is the most-comprehensive study to date of the unit of LGT among prokaryote genomes.",Biology
"If predictions for species extinctions hold, then the `tree of life' today may be quite different to that in (say) 100 years. We describe a technique to quantify how much each species is likely to contribute to future biodiversity, as measured by its expected contribution to phylogenetic diversity. Our approach considers all possible scenarios for the set of species that will be extant at some future time, and weights them according to their likelihood under an independent (but not identical) distribution on species extinctions. Although the number of extinction scenarios can typically be very large, we show that there is a simple algorithm that will quickly compute this index. The method is implemented and applied to the prosimian primates as a test case, and the associated species ranking is compared to a related measure (the `Shapley index'). We describe indices for rooted and unrooted trees, and a modification that also includes the focal taxon's probability of extinction, making it directly comparable to some new conservation metrics.",Biology
"Kainate induces a marked expression of cyclooxygenase-2 after its systemic administration. Because cyclooxygenase-2 activity is associated to the production of reactive oxygen species, we investigated the effects of nimesulide, a selective cyclooxygenase-2 inhibitor, on kainate-induced in vivo oxidative damage in the rat hippocampus. A clinically relevant dose of nimesulide (6 mg/kg, i.p.) was administered three times following kainate application (9 mg/kg, i.p.). After 24 h of kainate administration, the drastic decrease in hippocampal glutathione content and the significant increase in lipid peroxidation were attenuated in nimesulide-treated rats, suggesting that the induction of cyclooxygenase-2 is involved in kainate-mediated free radicals formation.",Biology
"This Letter studies the quasispecies dynamics of a population capable of genetic repair evolving on a time-dependent fitness landscape. We develop a model that considers an asexual population of single-stranded, conservatively replicating genomes, whose only source of genetic variation is due to copying errors during replication. We consider a time-dependent, single-fitness-peak landscape where the master sequence changes by a single point mutation every time $ \tau $. We are able to analytically solve for the evolutionary dynamics of the population in the point-mutation limit. In particular, our model provides an analytical expression for the fraction of mutators in the dynamic fitness landscape that agrees well with results from stochastic simulations.",Biology
"We present a top-down approach to the study of the dynamics of icosahedral virus capsids, in which each protein is approximated by a point mass. Although this represents a rather crude coarse-graining, we argue that it highlights several generic features of vibrational spectra which have been overlooked so far. We furthermore discuss the consequences of approximate inversion symmetry as well as the role played by Viral Tiling Theory in the study of virus capsid vibrations.",Biology
"Hormonal processes along with enzymatic processing similar to that found in vertebrates occur in annelids. Amino acid sequence determination of annelids precursor gene products reveals the presence of the respective peptides that exhibit high sequence identity to their mammalian counterparts. Furthermore, these neuropeptides exert similar physiological function in annelids than the ones found in vertebrates. In this respect, the high conservation in course of evolution of these molecules families reflects their importance. Nevertheless, some specific neuropeptides to annelids or invertebrates have also been in these animals.",Biology
"The total conformational energy is assumed to consist of pairwise interaction energies between atoms or residues, each of which is expressed as a product of a conformation-dependent function (an element of a contact matrix, C-matrix) and a sequence-dependent energy parameter (an element of a contact energy matrix, E-matrix). Such pairwise interactions in proteins force native C-matrices to be in a relationship as if the interactions are a Go-like potential [N. Go, Annu. Rev. Biophys. Bioeng. 12. 183 (1983)] for the native C-matrix, because the lowest bound of the total energy function is equal to the total energy of the native conformation interacting in a Go-like pairwise potential. This relationship between C- and E-matrices corresponds to (a) a parallel relationship between the eigenvectors of the C- and E-matrices and a linear relationship between their eigenvalues, and (b) a parallel relationship between a contact number vector and the principal eigenvectors of the C- and E-matrices; the E-matrix is expanded in a series of eigenspaces with an additional constant term, which corresponds to a threshold of contact energy that approximately separates native contacts from non-native ones. These relationships are confirmed in 182 representatives from each family of the SCOP database by examining inner products between the principal eigenvector of the C-matrix, that of the E-matrix evaluated with a statistical contact potential, and a contact number vector. In addition, the spectral representation of C- and E-matrices reveals that pairwise residue-residue interactions, which depends only on the types of interacting amino acids but not on other residues in a protein, are insufficient and other interactions including residue connectivities and steric hindrance are needed to make native structures the unique lowest energy conformations.",Biology
"This paper investigates the effect of drug treatment on the standard within-host HIV model, assuming that therapy occurs periodically. It is shown that eradication is possible under these periodic regimes, and we quantitatively characterize successful drugs or drug combinations, both theoretically and numerically. We also consider certain optimization problems, motivated for instance, by the fact that eradication should be achieved at acceptable toxicity levels to the patient. It turns out that these optimization problems can be simplified considerably, and this makes calculations of the optima a fairly straightforward task. All our results will be illustrated by means of numerical examples based on up-to-date knowledge of parameter values in the model.",Biology
"Cells are known to utilize biochemical noise to probabilistically switch between distinct gene expression states. We demonstrate that such noise-driven switching is dominated by tails of probability distributions and is therefore exponentially sensitive to changes in physiological parameters such as transcription and translation rates. However, provided mRNA lifetimes are short, switching can still be accurately simulated using protein-only models of gene expression. Exponential sensitivity limits the robustness of noise-driven switching, suggesting cells may use other mechanisms in order to switch reliably.",Biology
"We argue that immune system is an adaptive complex system. It is shown that it has emergent properties. Its network structure is of the small world network type. The network is of the threshold type, which helps in avoiding autoimmunity. It has the property that every antigen (e.g.virus or bacteria) is typically attacked by more than one effector. This stabilizes the equilibrium state. Modelling complex systems is discussed. Cellular automata (CA) type models are successful but there are much less analytic results about CA than about other less successful models e.g. partial differential equations (PDE). A compromise is proposed",Biology
"A model is presented to describe the nucleotide and repeat addition processivity by the telomerase. In the model, the processive nucleotide addition is implemented on the basis of two requirements: One is that stem IV loop stimulates the chemical reaction of nucleotide incorporation, and the other one is the existence of an ssRNA-binding site adjacent to the polymerase site that has a high affinity for the unpaired base of the template. The unpairing of DNA:RNA hybrid after the incorporation of the nucleotide paired with the last base on the template, which is the prerequisite for repeat addition processivity, is caused by a force acting on the primer. The force is resulted from the unfolding of stem III pseudoknot that is induced by the swinging of stem IV loop towards the nucleotide-bound polymerase site. Based on the model, the dynamics of processive nucleotide and repeat additions by Tetrahymena telomerase are quantitatively studied, which give good explanations to the previous experimental results. Moreover, some predictions are presented. In particular, it is predicted that the repeat addition processivity is mainly determined by the difference between the free energy required to disrupt the DNA:RNA hybrid and that required to unfold the stem III pseudoknot, with the large difference corresponding to a low repeat addition processivity while the small one corresponding to a high repeat addition processivity.",Biology
"Intracellular pathogens such as Listeria monocytogenes and Rickettsia rickettsii move within a host cell by polymerizing a comet-tail of actin fibers that ultimately pushes the cell forward. This dense network of cross-linked actin polymers typically exhibits a striking curvature that causes bacteria to move in gently looping paths. Theoretically, tail curvature has been linked to details of motility by considering force and torque balances from a finite number of polymerizing filaments. Here we track beads coated with a prokaryotic activator of actin polymerization in three dimensions to directly quantify the curvature and torsion of bead motility paths. We find that bead paths are more likely to have low rather than high curvature at any given time. Furthermore, path curvature changes very slowly in time, with an autocorrelation decay time of 200 seconds. Paths with a small radius of curvature, therefore, remain so for an extended period resulting in loops when confined to two dimensions. When allowed to explore a 3D space, path loops are less evident. Finally, we quantify the torsion in the bead paths and show that beads do not exhibit a significant left- or right-handed bias to their motion in 3D. These results suggest that paths of actin-propelled objects may be attributed to slow changes in curvature rather than a fixed torque.",Biology
"This paper develops simplified mathematical models describing the mutation-selection balance for the asexual and sexual replication pathways in {\it Saccharomyces cerevisiae}. We assume diploid genomes consisting of two chromosomes, and we assume that each chromosome is functional if and only if its base sequence is identical to some master sequence. The growth and replication of the yeast cells is modeled as a first-order process, with first-order growth rate constants that are determined by whether a given genome consists of zero, one, or two functional chromosomes. In the asexual pathway, we assume that a given diploid cell divides into two diploids. In the sexual pathway, we assume that a given diploid cell divides into two diploids, each of which then divide into two haploids. The resulting four haploids enter a haploid pool, where they grow and replicate until they meet another haploid with which to fuse. When the cost for sex is low, we find that the selective mating strategy leads to the highest mean fitness of the population, when compared to all of the other strategies. We also show that, at low to intermediate replication fidelities, sexual replication with random mating has a higher mean fitness than asexual replication, as long as the cost for sex is low. This is consistent with previous work suggesting that sexual replication is advantageous at high population densities, low replication rates, and intermediate replication fidelities. The results of this paper also suggest that {\it S. cerevisiae} switches from asexual to sexual replication when stressed, because stressful growth conditions provide an opportunity for the yeast to clear out deleterious mutations from their genomes.",Biology
"Background: It is of biological interest to make genome-wide predictions of the locations of DNA melting bubbles using statistical mechanics models. Computationally, this poses the challenge that a generic search through all combinations of bubble starts and ends is quadratic.   Results: An efficient algorithm is described, which shows that the time complexity of the task is O(NlogN) rather than quadratic. The algorithm exploits that bubble lengths may be limited, but without a prior assumption of a maximal bubble length. No approximations, such as windowing, have been introduced to reduce the time complexity. More than just finding the bubbles, the algorithm produces a stitch profile, which is a probabilistic graphical model of bubbles and helical regions. The algorithm applies a probability peak finding method based on a hierarchical analysis of the energy barriers in the Poland-Scheraga model.   Conclusions: Exact and fast computation of genomic stitch profiles is thus feasible. Sequences of several megabases have been computed, only limited by computer memory. Possible applications are the genome-wide comparisons of bubbles with promotors, TSS, viral integration sites, and other melting-related regions.",Biology
"A composite, exponential relaxation function, modulated by a periodic component, was used to fit to an experimental time series of blood glucose levels. The 11 parameters function that allows for the detection of a possible rhythm transition was fitted to the experimental time series using a genetic algorithm. It has been found that the relaxation from a hyperglycemic condition following a change in the anti-diabetic treatment, can be characterized by a change from an initial 12 hours ultradian rhythm to a near-24 hours circadian rhythm.",Biology
"The conformational dynamics of a single protein molecule in a shear flow is investigated using Brownian dynamics simulations. A structure-based coarse grained model of a protein is used. We consider two proteins, ubiquitin and integrin, and find that at moderate shear rates they unfold through a sequence of metastable states - a pattern which is distinct from a smooth unraveling found in homopolymers. Full unfolding occurs only at very large shear rates. Furthermore, the hydrodynamic interactions between the amino acids are shown to hinder the shear flow unfolding. The characteristics of the unfolding process depend on whether a protein is anchored or not, and if it is, on the choice of an anchoring point.",Biology
"We consider a simple-model population, whose individuals react with a certain delay to temporal variations of their habitat. We investigate the impact of such a delayed-answer on the survival chances of the population, both in a periodically changing environment, and in the case of an abrupt change of it. It is found that for population with low degree of mutation-induced variability, being ""slow-reacting"" decreases the extinction risk face to environmental changes. On the contrary, for populations with high mutation amplitude, the delayed reaction reduces the survival chances.",Biology
"The concept of robustness of regulatory networks has been closely related to the nature of the interactions among genes, and the capability of pattern maintenance or reproducibility. Defining this robustness property is a challenging task, but mathematical models have often associated it to the volume of the space of admissible parameters. Not only the volume of the space but also its topology and geometry contain information on essential aspects of the network, including feasible pathways, switching between two parallel pathways or distinct/disconnected active regions of parameters. A general method is presented here to characterize the space of admissible parameters, by writing it as a semi-algebraic set, and then theoretically analyzing its topology and geometry, as well as volume. This method provides a more objective and complete measure of the robustness of a developmental module. As an illustration, the segment polarity gene network is analyzed.",Biology
"Based upon the membrane currents generated by an action potential in a biologically realistic model of a pyramidal, hippocampal cell within rat CA1, we perform a moment expansion of the extracellular field potential. We decompose the potential into both inverse and classical moments and show that this method is a rapid and efficient way to calculate the extracellular field both near and far from the cell body. The action potential gives rise to a large quadrupole moment that contributes to the extracellular field up to distances of almost 1 cm. This method will serve as a starting point in connecting the microscopic generation of electric fields at the level of neurons to macroscopic observables such as the local field potential.",Biology
"BACKGROUND: One of the most evident achievements of bioinformatics is the development of methods that transfer biological knowledge from characterised proteins to uncharacterised sequences. This mode of protein function assignment is mostly based on the detection of sequence similarity and the premise that functional properties are conserved during evolution. Most automatic approaches developed to date rely on the identification of clusters of homologous proteins and the mapping of new proteins onto these clusters, which are expected to share functional characteristics. RESULTS: Here, we inverse the logic of this process, by considering the mapping of sequences directly to a functional classification instead of mapping functions to a sequence clustering. In this mode, the starting point is a database of labelled proteins according to a functional classification scheme, and the subsequent use of sequence similarity allows defining the membership of new proteins to these functional classes. In this framework, we define the Correspondence Indicators as measures of relationship between sequence and function and further formulate two Bayesian approaches to estimate the probability for a sequence of unknown function to belong to a functional class. This approach allows the parametrisation of different sequence search strategies and provides a direct measure of annotation error rates. We validate this approach with a database of enzymes labelled by their corresponding four-digit EC numbers and analyse specific cases. CONCLUSION: The performance of this method is significantly higher than the simple strategy consisting in transferring the annotation from the highest scoring BLAST match and is expected to find applications in automated functional annotation pipelines.",Biology
"Mortality, birth rates and retirement play a major role in demographic changes. In most cases, mortality rates decreased in the past century without noticeable decrease in fertility rates, this leads to a significant increase in population growth. In many poor countries like Palestinian territories the number of births has fallen and the life expectancy increased.   In this article we concentrate on measuring, analyzing and extrapolating the age structure in Palestine a few decades ago into future. A Fortran program has been designed and used for the simulation and analysis of our statistical data. This study of demographic change in Palestine has shown that Palestinians will have in future problems as the strongest age cohorts are the above-60-year olds. We therefore recommend the increase of both the retirement age and women employment.",Biology
"The persistent pods of the tree, Acacia caven, that do not fall from the tree provide opportunities for the appearance of a diverse group of insects the following season. Such pods collected during the spring of 1999 in Chile were indehiscent with highly sclerified pod walls. In contrast, persistent pods collected in Uruguay after a wet winter and spring (2002) were partially dehiscent, inducing the deterioration of the woody pods, and consequently exposing the seeds. These persistent pods are a natural refuge for insect species, namely two bruchid beetles (Pseudopachymeria spinipes, Stator furcatus), one scolytidae (Dendroctonus sp), lepidopterous larvae, ant colonies (Camponotus sp),one species of oophagous parasitoid (Uscana espinae group senex), the gregarious larval-pupae parasitoid Monoksa dorsiplana (Pteromalidae) and two species of Horismenus spp. (Eulophidae). The patriline of M. dorsiplana is frequently formed by 1 son +7 daughters.",Biology
"Assuming the deleterious mutations in the Penna ageing model to affect mainly the young ages, we get an enhanced mortality at very young age, followed by a minimum of the mortality, and then the usual exponential increase of mortality with age.",Biology
"We use traveling-wave theory to derive expressions for the rate of accumulation of deleterious mutations under Muller's ratchet and the speed of adaptation under positive selection in asexual populations. Traveling-wave theory is a semi-deterministic description of an evolving population, where the bulk of the population is modeled using deterministic equations, but the class of the highest-fitness genotypes, whose evolution over time determines loss or gain of fitness in the population, is given proper stochastic treatment. We derive improved methods to model the highest-fitness class (the stochastic edge) for both Muller's ratchet and adaptive evolution, and calculate analytic correction terms that compensate for inaccuracies which arise when treating discrete fitness classes as a continuum. We show that traveling wave theory makes excellent predictions for the rate of mutation accumulation in the case of Muller's ratchet, and makes good predictions for the speed of adaptation in a very broad parameter range. We predict the adaptation rate to grow logarithmically in the population size until the population size is extremely large.",Biology
"Annealed importance sampling is a means to assign equilibrium weights to a nonequilibrium sample that was generated by a simulated annealing protocol. The weights may then be used to calculate equilibrium averages, and also serve as an ``adiabatic signature'' of the chosen cooling schedule. In this paper we demonstrate the method on the 50-atom dileucine peptide, showing that equilibrium distributions are attained for manageable cooling schedules. For this system, as naively implemented here, the method is modestly more efficient than constant temperature simulation. However, the method is worth considering whenever any simulated heating or cooling is performed (as is often done at the beginning of a simulation project, or during an NMR structure calculation), as it is simple to implement and requires minimal additional CPU expense. Furthermore, the naive implementation presented here can be improved.",Biology
"Theoretical analysis of own and literature investigations of sexual motivation with the use of the partition test [Kudryavtseva, 1987, 1994] in male mice was carried out. It has been shown that appearance of a receptive female in the neighboring compartment of common cage separated by perforated transparent partition produces the enhancement of testosterone level in blood and stimulates the behavioral activity near partition as a reaction to the receptive female in naive males. In many studies this behavioral activity is considered as sexual motivation, arising in this experimental context in male mice. The lack of correlation between behavioral parameters and gonad reaction of males on receptive female, uninterconnected changes of these two parameters as well as the lack of sexual behavior between naive male and female when partition is removed cast doubt on this data interpretation. It has been supposed that in naive males behavioral reaction to a receptive female is induced by positive incentive - odor of the female associated with nursing and warmth from mother and other females which look after posterity. Short-term increase of the level of testosterone (possessing rewarding properties) is innate stimulus-response reaction which stimulates and prolongs behavioral interest of male to receptive female. It has been supposed that after sexual experience female odor is associated in experienced males with sexual behavior directed to the sexual partner and resulted in the formation of sexual motivation. The data are considered also in the light of the theory of motivated behavior including ""liking"", ""wanting"" and ""learning"" [Robinson and Berridge, 1993, 2000].",Biology
"Phylogenetic networks are a generalization of phylogenetic trees that allow for the representation of evolutionary events acting at the population level, like recombination between genes, hybridization between lineages, and lateral gene transfer. While most phylogenetics tools implement a wide range of algorithms on phylogenetic trees, there exist only a few applications to work with phylogenetic networks, and there are no open-source libraries either.   In order to improve this situation, we have developed a Perl package that relies on the BioPerl bundle and implements many algorithms on phylogenetic networks. We have also developed a Java applet that makes use of the aforementioned Perl package and allows the user to make simple experiments with phylogenetic networks without having to develop a program or Perl script by herself.   The Perl package has been accepted as part of the BioPerl bundle. It can be downloaded from http://dmi.uib.es/~gcardona/BioInfo/Bio-PhyloNetwork.tgz. The web-based application is available at http://dmi.uib.es/~gcardona/BioInfo/. The Perl package includes full documentation of all its features.",Biology
In this paper we address a general parameter estimation methodology for an extended biokinetic degradation model [1] for poorly degradable micropollutants. In particular we concentrate on parameter estimation of the micropollutant degradation sub-model by specialised microorganisms. In this case we focus on the case when only substrate degradation data are available and prove the structural identifiability of the model. Further we consider the problem of practical identifiability and propose experimental and related numerical methods for unambiguous parameter estimation based on multiple substrate degradation curves with different initial concentrations. Finally by means of simulated pseudo-experiments we have found convincing indications that the proposed algorithm is stable and yields appropriate parameter estimates even in unfavourable regimes.,Biology
"Temporally and spatially resolved measurements of protein transport inside cells provide important clues to the functional architecture and dynamics of biological systems. Fluorescence Recovery After Photobleaching (FRAP) technique has been used over the past three decades to measure the mobility of macromolecules and protein transport and interaction with immobile structures inside the cell nucleus. A theoretical model is presented that aims to describe protein transport inside the nucleus, a process which is influenced by the presence of a boundary (i.e. membrane). A set of reaction-diffusion equations is employed to model both the diffusion of proteins and their interaction with immobile binding sites. The proposed model has been designed to be applied to biological samples with a Confocal Laser Scanning Microscope (CLSM) equipped with the feature to bleach regions characterised by a scanning beam that has a radially Gaussian distributed profile. The proposed model leads to FRAP curves that depend on the on- and off-rates. Semi-analytical expressions are used to define the boundaries of on- (off-) rate parameter space in simplified cases when molecules move within a bounded domain. The theoretical model can be used in conjunction to experimental data acquired by CLSM to investigate the biophysical properties of proteins in living cells.",Biology
"Genetic recombination can produce heterogeneous phylogenetic histories within a set of homologous genes. Delineating recombination events is important in the study of molecular evolution, as inference of such events provides a clearer picture of the phylogenetic relationships among different gene sequences or genomes. Nevertheless, detecting recombination events can be a daunting task, as the performance of different recombinationdetecting approaches can vary, depending on evolutionary events that take place after recombination. We recently evaluated the effects of postrecombination events on the prediction accuracy of recombination-detecting approaches using simulated nucleotide sequence data. The main conclusion, supported by other studies, is that one should not depend on a single method when searching for recombination events. In this paper, we introduce a two-phase strategy, applying three statistical measures to detect the occurrence of recombination events, and a Bayesian phylogenetic approach in delineating breakpoints of such events in nucleotide sequences. We evaluate the performance of these approaches using simulated data, and demonstrate the applicability of this strategy to empirical data. The two-phase strategy proves to be time-efficient when applied to large datasets, and yields high-confidence results.",Biology
"The architecture of biological networks has been reported to exhibit high level of modularity, and to some extent, topological modules of networks overlap with known functional modules. However, how the modular topology of the molecular network affects the evolution of its member proteins remains unclear. In this work, the functional and evolutionary modularity of Homo sapiens (H. sapiens) metabolic network were investigated from a topological point of view. Network decomposition shows that the metabolic network is organized in a highly modular core-periphery way, in which the core modules are tightly linked together and perform basic metabolism functions, whereas the periphery modules only interact with few modules and accomplish relatively independent and specialized functions. Moreover, over half of the modules exhibit co-evolutionary feature and belong to specific evolutionary ages. Peripheral modules tend to evolve more cohesively and faster than core modules do. The correlation between functional, evolutionary and topological modularity suggests that the evolutionary history and functional requirements of metabolic systems have been imprinted in the architecture of metabolic networks. Such systems level analysis could demonstrate how the evolution of genes may be placed in a genome-scale network context, giving a novel perspective on molecular evolution.",Biology
"Phylogenetic networks are a generalization of phylogenetic trees that allow for the representation of non-treelike evolutionary events, like recombination, hybridization, or lateral gene transfer. In this paper, we present and study a new class of phylogenetic networks, called tree-child phylogenetic networks, where every non-extant species has some descendant through mutation. We provide an injective representation of these networks as multisets of vectors of natural numbers, their path multiplicity vectors, and we use this representation to define a distance on this class and to give an alignment method for pairs of these networks. To the best of our knowledge, they are respectively the first true distance and the first alignment method defined on a meaningful class of phylogenetic networks strictly extending the class of phylogenetic trees. Simple, polynomial algorithms for reconstructing a tree-child phylogenetic network from its path multiplicity vectors, for computing the distance between two tree-child phylogenetic networks, and for aligning a pair of tree-child phylogenetic networks, are provided, and they have been implemented as a Perl package and a Java applet, and they are available at http://bioinfo.uib.es/~recerca/phylonetworks/mudistance",Biology
"As I compress on the canvas of a few pages here major results of my research on the retinoblastoma tumor suppressor protein (RB) spreading over the past 15 years, an exciting picture emerges on this unique host molecule which surpasses in its complexity even that of the most capable viral proteins known to date. Accordingly, RB has the potential to bind not only growth-promoting proteins such as insulin, but also to attach itself to calcium and oxygen, as well as to be secreted into the extracellular environment. Moreover, RB may exert proteolytic, antimicrobial and anti-aging activities. These condensed structure-based insights on RB are the substance of a scientific revolution I have initiated a long time ago, yet likely to gain even further speed in the years to come, thus expanding both our understanding of life at the molecular level and the possibilities for pharmacological modulation of fundamental biological phenomena, particularly in oncology and gerontology.",Biology
"Jansson and Sung showed that, given a dense set of input triplets T (representing hypotheses about the local evolutionary relationships of triplets of species), it is possible to determine in polynomial time whether there exists a level-1 network consistent with T, and if so to construct such a network. They also showed that, unlike in the case of trees (i.e. level-0 networks), the problem becomes NP-hard when the input is non-dense. Here we further extend this work by showing that, when the set of input triplets is dense, the problem is even polynomial-time solvable for the construction of level-2 networks. This shows that, assuming density, it is tractable to construct plausible evolutionary histories from input triplets even when such histories are heavily non-tree like. This further strengthens the case for the use of triplet-based methods in the construction of phylogenetic networks. We also show that, in the non-dense case, the level-2 problem remains NP-hard.",Biology
"Position determination in biological systems is often achieved through protein concentration gradients. Measuring the local concentration of such a protein with a spatially-varying distribution allows the measurement of position within the system. In order for these systems to work effectively, position determination must be robust to noise. Here, we calculate fundamental limits to the precision of position determination by concentration gradients due to unavoidable biochemical noise perturbing the gradients. We focus on gradient proteins with first order reaction kinetics. Systems of this type have been experimentally characterised in both developmental and cell biology settings. For a single gradient we show that, through time-averaging, great precision can potentially be achieved even with very low protein copy numbers. As a second example, we investigate the ability of a system with oppositely directed gradients to find its centre. With this mechanism, positional precision close to the centre improves more slowly with increasing averaging time, and so longer averaging times or higher copy numbers are required for high precision. For both single and double gradients, we demonstrate the existence of optimal length scales for the gradients, where precision is maximized, as well as analyzing how precision depends on the size of the concentration measuring apparatus. Our results provide fundamental constraints on the positional precision supplied by concentration gradients in various contexts, including both in developmental biology and also within a single cell.",Biology
"The organization of the connectivity between mammalian cortical areas has become a major subject of study, because of its important role in scaffolding the macroscopic aspects of animal behavior and intelligence. In this study we present a computational reconstruction approach to the problem of network organization, by considering the topological and spatial features of each area in the primate cerebral cortex as subsidy for the reconstruction of the global cortical network connectivity. Starting with all areas being disconnected, pairs of areas with similar sets of features are linked together, in an attempt to recover the original network structure. Inferring primate cortical connectivity from the properties of the nodes, remarkably good reconstructions of the global network organization could be obtained, with the topological features allowing slightly superior accuracy to the spatial ones. Analogous reconstruction attempts for the C. elegans neuronal network resulted in substantially poorer recovery, indicating that cortical area interconnections are relatively stronger related to the considered topological and spatial properties than neuronal projections in the nematode. The close relationship between area-based features and global connectivity may hint on developmental rules and constraints for cortical networks. Particularly, differences between the predictions from topological and spatial properties, together with the poorer recovery resulting from spatial properties, indicate that the organization of cortical networks is not entirely determined by spatial constraints.",Biology
"Contact patterns in populations fundamentally influence the spread of infectious diseases. Current mathematical methods for epidemiological forecasting on networks largely assume that contacts between individuals are fixed, at least for the duration of an outbreak. In reality, contact patterns may be quite fluid, with individuals frequently making and breaking social or sexual relationships. Here we develop a mathematical approach to predicting disease transmission on dynamic networks in which each individual has a characteristic behavior (typical contact number), but the identities of their contacts change in time. We show that dynamic contact patterns shape epidemiological dynamics in ways that cannot be adequately captured in static network models or mass-action models. Our new model interpolates smoothly between static network models and mass-action models using a mixing parameter, thereby providing a bridge between disparate classes of epidemiological models. Using epidemiological and sexual contact data from an Atlanta high school, we then demonstrate the utility of this method for forecasting and controlling sexually transmitted disease outbreaks.",Biology
"We introduce a simple algorithm for reconstructing phylogenies from multiple gene trees in the presence of incomplete lineage sorting, that is, when the topology of the gene trees may differ from that of the species tree. We show that our technique is statistically consistent under standard stochastic assumptions, that is, it returns the correct tree given sufficiently many unlinked loci. We also show that it can tolerate moderate estimation errors.",Biology
"Despite the spontaneity of some in vitro protein folding reactions, native folding in vivo often requires the participation of barrel-shaped multimeric complexes known as chaperonins. Although it has long been known that chaperonin substrates fold upon sequestration inside the chaperonin barrel, the precise mechanism by which confinement within this space facilitates folding remains unknown. In this study, we examine the possibility that the chaperonin mediates a favorable reorganization of the solvent for the folding reaction. We begin by discussing the effect of electrostatic charge on solvent-mediated hydrophobic forces in an aqueous environment. Based on these initial physical arguments, we construct a simple, phenomenological theory for the thermodynamics of density and hydrogen bond order fluctuations in liquid water. Within the framework of this model, we investigate the effect of confinement within a chaperonin-like cavity on the configurational free energy of water by calculating solvent free energies for cavities corresponding to the different conformational states in the ATP- driven catalytic cycle of the prokaryotic chaperonin GroEL. Our findings suggest that one function of chaperonins may be to trap unfolded proteins and subsequently expose them to a micro-environment in which the hydrophobic effect, a crucial thermodynamic driving force for folding, is enhanced.",Biology
"We study a model ecosystem by means of dynamical techniques from disordered systems theory. The model describes a set of species subject to competitive interactions through a background of resources, which they feed upon. Additionally direct competitive or co-operative interaction between species may occur through a random coupling matrix. We compute the order parameters of the system in a fixed point regime, and identify the onset of instability and compute the phase diagram. We focus on the effects of variability of resources, direct interaction between species, co-operation pressure and dilution on the stability and the diversity of the ecosystem. It is shown that resources can be exploited optimally only in absence of co-operation pressure or direct interaction between species.",Biology
The holographic bound in physics constrains the complexity of life. The finite storage capability of information in the observable universe requires the protein linguistics in the evolution of life. We find that the evolution of genetic code determines the variance of amino acid frequencies and genomic GC content among species. The elegant linguistic mechanism is confirmed by the experimental observations based on all known entire proteomes.,Biology
"Evolution of the spatial arrangement of cells in a primary culture of cardiac tissue derived from newborn rats was studied experimentally over extended period. It was found that cells attract each other spontaneously to form a clustered structure over the timescale of several days. These clusters exhibit spontaneous rhythmic contraction and have been confirmed to consist of cardiac muscle cells. Addition of a contraction inhibitor (2,3-butanedione-2-monoxime) to the culture medium resulted in the inhibition of both the spontaneous contractions exhibited by the cells as well as the formation of clusters. Furthermore, the formation of clusters is suppressed when high concentrations of collagen are used for coating the substratum to which the cells adhere. From these experimental observations, it was deduced that the cells are mechanically stressed by the tension associated with repeated contractions and that this results in the cells becoming compact and attracting each other, finally resulting in the formation of clusters. This process can be interpreted as modulation of a cellular network by the activity associated with contraction, which could be employed to control cellular networks by modifying the dynamics associated with the contractions in cardiac tissue culture.",Biology
"We present a comprehensive computational study of some 900 possible ""lambda-lac"" mutants of the lysogeny maintenance switch in phage lambda, of which up to date 19 have been studied experimentally (Atsumi & Little, PNAS 103: 4558-4563, (2006)). We clarify that these mutants realise regulatory schemes quite different from wild-type lambda, and can therefore be expected to behave differently, within the conventional mechanistic setting in which this problem has often been framed. We verify that indeed, within this framework, across this wide selection of mutants the lambda-lac mutants for the most part either have no stable lytic states, or should only be inducible with difficulty. In particular, the computational results contradicts the experimental finding that four lambda-lac mutants both show stable lysogeny and are inducible. This work hence suggests either that the four out of 900 mutants are special, or that lambda lysogeny and inducibility are holistic effects involving other molecular players or other mechanisms, or both. The approach illustrates the power and versatility of computational systems biology to systematically and quickly test a wide variety of examples and alternative hypotheses for future closer experimental studies.",Biology
"In this work it is shown that 20 canonical amino acids (AAs) within genetic code appear to be a whole system with strict distinction in Genetic Code Table (GCT) into some different quantums: 20, 23, 61 amino acid molecules. These molecules distinction is followed by specific balanced atom number and/or nucleon number distinctions within those molecules. In this second version two appendices are added; also a new version of Periodic system of numbers, whose first verson is given in arXiv:1107.1998 [q-bio.OT].",Biology
"Magnetic tweezers are used to study the mechanical response under torsion of single nucleosome arrays reconstituted on tandem repeats of 5S positioning sequences. Regular arrays are extremely resilient and can reversibly accommodate a large amount of supercoiling without much change in length. This behavior is quantitatively described by a molecular model of the chromatin 3-D architecture. In this model, we assume the existence of a dynamic equilibrium between three conformations of the nucleosome, which are determined by the crossing status of the entry/exit DNAs (positive, null or negative). Torsional strain, in displacing that equilibrium, extensively reorganizes the fiber architecture. The model explains a number of long-standing topological questions regarding DNA in chromatin, and may provide the ground to better understand the dynamic binding of most chromatin-associated proteins.",Biology
"We present a theoretical study of the folding of small proteins inside confining potentials. Proteins are described in the framework of an effective potential model which contains the Ramachandran angles as degrees of freedom and does not need any {\it a priori} information about the native state. Hydrogen bonds, dipole-dipole- and hydrophobic interactions are taken explicitly into account. An interesting feature displayed by this potential is the presence of some intermediates between the unfolded and native states. We consider different types of confining potentials in order to study the structural properties of proteins folding inside cages with repulsive or attractive walls. Using the Wang-Landau algorithm we determine the density of states (DOS) and analyze in detail the thermodynamical properties of the confined proteins for different sizes of the cages. We show that confinement dramatically reduces the phase space available to the protein and that the presence of intermediate states can be controlled by varying the properties of the confining potential. Cages with strongly attractive walls lead to the disappearance of the intermediate states and to a two-state folding into a less stable configuration. However, cages with slightly attractive walls make the native structure more stable than in the case of pure repulsive potentials, and the folding process occurs through intermediate configurations. In order to test the metastable states we analyze the free energy landscapes as a function of the configurational energy and of the end-to-end distance as an order parameter.",Biology
"We discovered a dynamic phase transition induced by sexual reproduction. The dynamics is a pure Darwinian rule with both fundamental ingredients to drive evolution: 1) random mutations and crossings which act in the sense of increasing the entropy (or diversity); and 2) selection which acts in the opposite sense by limiting the entropy explosion. Selection wins this competition if mutations performed at birth are few enough. By slowly increasing the average number m of mutations, however, the population suddenly undergoes a mutational degradation precisely at a transition point mc. Above this point, the ""bad"" alleles spread over the genetic pool of the population, overcoming the selection pressure. Individuals become selectively alike, and evolution stops. Only below this point, m < mc, evolutionary life is possible.   The finite-size-scaling behaviour of this transition is exhibited for large enough ""chromosome"" lengths L. One important and surprising observation is the L-independence of the transition curves, for large L. They are also independent on the population size. Another is that mc is near unity, i.e. life cannot be stable with much more than one mutation per diploid genome, independent of the chromosome length, in agreement with reality. One possible consequence is that an eventual evolutionary jump towards larger L enabling the storage of more genetic information would demand an improved DNA copying machinery in order to keep the same total number of mutations per offspring.",Biology
"Robustness to mutations and noise has been shown to evolve through stabilizing selection for optimal phenotypes in model gene regulatory networks. The ability to evolve robust mutants is known to depend on the network architecture. How do the dynamical properties and state-space structures of networks with high and low robustness differ? Does selection operate on the global dynamical behavior of the networks? What kind of state-space structures are favored by selection? We provide damage propagation analysis and an extensive statistical analysis of state spaces of these model networks to show that the change in their dynamical properties due to stabilizing selection for optimal phenotypes is minor. Most notably, the networks that are most robust to both mutations and noise are highly chaotic. Certain properties of chaotic networks, such as being able to produce large attractor basins, can be useful for maintaining a stable gene-expression pattern. Our findings indicate that conventional measures of stability, such as the damage-propagation rate, do not provide much information about robustness to mutations or noise in model gene regulatory networks.",Biology
"The coevolutionary dynamics in finite populations currently is investigated in a wide range of disciplines, as chemical catalysis, biological evolution, social and economic systems. The dynamics of those systems can be formulated within the unifying framework of evolutionary game theory. However it is not a priori clear which mathematical description is appropriate when populations are not infinitely large. Whereas the replicator equation approach describes the infinite population size limit by deterministic differential equations, in finite populations the dynamics is inherently stochastic which can lead to new effects. Recently, an explicit mean-field description in the form of a Fokker-Planck equation was derived for frequency-dependent selection in finite populations based on microscopic processes. In asymmetric conflicts between two populations with a cyclic dominance, a finite-size dependent drift reversal was demonstrated, depending on the underlying microscopic process of the evolutionary update. Cyclic dynamics appears widely in biological coevolution, be it within a homogeneous population, or be it between disjunct populations as female and male. Here explicit analytic address is given and the average drift is calculated for the frequency-dependent Moran process and for different pairwise comparison processes. It is explicitely shown that the drift reversal cannot occur if the process relies on payoff differences between pairs of individuals. Further, also a linear comparison with the average payoff does not lead to a drift towards the internal fixed point. Hence the nonlinear comparison function of the frequency-dependent Moran process, together with its usage of nonlocal information via the average payoff, is the essential part of the mechanism.",Biology
"In Chile and Uruguay,the gregarious Pteromalidae (Monoksa dorsiplana) has been discovered emerging from seeds of the persistent pods of Acacia caven attacked by the univoltin bruchid Pseudopachymeria spinipes. We investigated the potential for mass rearing of this gregarious ectoparasitoid on an alternative bruchid host, Callosobruchus maculatus, to use it against the bruchidae of native and cultured species of Leguminosea seeds in South America. The mass rearing of M.dorsiplana was carried out in a population cage where the density of egg-laying females per infested seed was increased from 1:1 on the first day to 5:1 on the last (fifth) day. Under these experimental conditions egg-clutch size per host increased, and at the same time the mortality of eggs laid also increased. The density of egg-laying females influenced the sex ratio which tended towards a balance of sons and daughters,in contrast to the sex ratio of a single egg-laying female per host (1 son to 7 daughters). The mean weight of adults emerging from a parasitized host was negatively correlated with the egg-clutch size, i.e., as egg-clutch size increased, adult weight decreased. All these results show that mass rearing of the gregarious ectoparasitoid M.dorsiplana was possible under laboratory conditions on an alternative bruchid host C.maculatus. As M.dorsiplana is a natural enemy of larval and pupal stages of bruchidae, the next step was to investigate whether the biological control of bruchid C.maculatus was possible in an experimental structure of stored beans.",Biology
"The genetic code markup is the assignment of stop codons. The standard genetic code markup ensures the maximum possible stability of genetic information with respect to two fault classes: frameshift and nonsense mutations. There are only 528 (about 1,3% of total number) optimal markups in the set of markups having 3 stop codons. Among the sets of markups with 1,2,...,8 stop codons, the standard case having 3 stop codons has maximum absolute number of optimal markups.",Biology
"The Battle of the Sexes describes asymmetric conflicts in mating behavior of males and females. Males can be philanderer or faithful, while females are either fast or coy, leading to a cyclic dynamics. The adjusted replicator equation predicts stable coexistence of all four strategies. In this situation, we consider the effects of fluctuations stemming from a finite population size. We show that they unavoidably lead to extinction of two strategies in the population. However, the typical time until extinction occurs strongly prolongs with increasing system size. In the meantime, a quasi-stationary probability distribution forms that is anomalously flat in the vicinity of the coexistence state. This behavior originates in a vanishing linear deterministic drift near the fixed point. We provide numerical data as well as an analytical approach to the mean extinction time and the quasi-stationary probability distribution.",Biology
"It has been claimed that different types of causes must be considered in biological systems, including top-down as well as same-level and bottom-up causation, thus enabling the top levels to be causally efficacious in their own right. To clarify this issue, important distinctions between information and signs are introduced here and the concepts of information control and functional equivalence classes in those systems are rigorously defined and used to characterise when top down causation by feedback control happens, in a way that is testable. The causally significant elements we consider are equivalence classes of lower level processes, realised in biological systems through different operations having the same outcome within the context of information control and networks.",Biology
"It has been shown that differences in fecundity variance can influence the probability of invasion of a genotype in a population, i.e. a genotype with lower variance in offspring number can be favored in finite populations even if it has a somewhat lower mean fitness than a competitor. In this paper, Gillespie's results are extended to population genetic systems with explicit age structure, where the demographic variance (variance in growth rate) calculated in the work of Engen and colleagues is used as a generalization of ""variance in offspring number"" to predict the interaction between deterministic and random forces driving change in allele frequency. By calculating the variance from the life history parameters, it is shown that selection against variance in the growth rate will favor a genotypes with lower stochasticity in age specific survival and fertility rates. A diffusion approximation for selection and drift in a population with two genotypes with different life history matrices (and therefore, different growth rates and demographic variances) is derived and shown to be consistent with individual based simulations. It is also argued that for finite populations, perturbation analyses of both the growth rate and demographic variances may be necessary to determine the sensitivity of ""fitness"" (broadly defined) to changes in the life history parameters.",Biology
"Phylogenetic mixtures model the inhomogeneous molecular evolution commonly observed in data. The performance of phylogenetic reconstruction methods where the underlying data is generated by a mixture model has stimulated considerable recent debate. Much of the controversy stems from simulations of mixture model data on a given tree topology for which reconstruction algorithms output a tree of a different topology; these findings were held up to show the shortcomings of particular tree reconstruction methods. In so doing, the underlying assumption was that mixture model data on one topology can be distinguished from data evolved on an unmixed tree of another topology given enough data and the ``correct'' method. Here we show that this assumption can be false. For biologists our results imply that, for example, the combined data from two genes whose phylogenetic trees differ only in terms of branch lengths can perfectly fit a tree of a different topology.",Biology
"Gene regulation is a complex process involving the role of several genomic elements which work in concert to drive spatio-temporal expression. The experimental characterization of gene regulatory elements is a very complex and resource-intensive process. One of the major goals in computational biology is the \textit{in-silico} annotation of previously uncharacterized elements using results from the subset of known, previously annotated, regulatory elements.   The recent results of the ENCODE project (\emph{http://encode.nih.gov}) presented in-depth analysis of such functional (regulatory) non-coding elements for 1% of the human genome. It is hoped that the results obtained on this subset can be scaled to the rest of the genome. This is an extremely important effort which will enable faster dissection of other functional elements in key biological processes such as disease progression and organ development (\cite{Kleinjan2005},\cite{Lieb2006}. The computational annotation of these hitherto uncharacterized regions would require an identification of features that have good predictive value.   In this work, we study transcriptional regulation as a problem in heterogeneous data integration, across sequence, expression and interactome level attributes. Using the example of the \textit{Gata2} gene and its recently discovered urogenital enhancers \cite{Khandekar2004} as a case study, we examine the predictive value of various high throughput functional genomic assays (from projects like ENCODE and SymAtlas) in characterizing these enhancers and their regulatory role. Observing results from the application of modern statistical learning methodologies for each of these data modalities, we propose a set of features that are most discriminatory to find these enhancers.",Biology
"Previous research has shown a strong correlation of protein folding rates to the native state geometry, yet a complete explanation for this dependence is still lacking. Here we study the rate-geometry relationship with a simple statistical physics model, and focus on two classes of model geometries, representing ideal parallel and antiparallel structures. We find that the logarithm of the rate shows an almost perfect linear correlation with the ""absolute contact order"", but the slope depends on the particular class considered. We discuss these findings in the light of experimental results.",Biology
"Questions of understanding and quantifying the representation and amount of information in organisms have become a central part of biological research, as they potentially hold the key to fundamental advances. In this paper, we demonstrate the use of information-theoretic tools for the task of identifying segments of biomolecules (DNA or RNA) that are statistically correlated. We develop a precise and reliable methodology, based on the notion of mutual information, for finding and extracting statistical as well as structural dependencies. A simple threshold function is defined, and its use in quantifying the level of significance of dependencies between biological segments is explored. These tools are used in two specific applications. First, for the identification of correlations between different parts of the maize zmSRp32 gene. There, we find significant dependencies between the 5' untranslated region in zmSRp32 and its alternatively spliced exons. This observation may indicate the presence of as-yet unknown alternative splicing mechanisms or structural scaffolds. Second, using data from the FBI's Combined DNA Index System (CODIS), we demonstrate that our approach is particularly well suited for the problem of discovering short tandem repeats, an application of importance in genetic profiling.",Biology
"We examine the effects of stochastic input currents on the firing behavior of two excitable neurons coupled with fast excitatory synapses. In such cells (models), typified by the quadratic integrate and fire model, mutual synaptic coupling can cause sustained firing or oscillatory behavior which is necessarily antiphase. Additive Gaussian white noise can transiently terminate the oscillations, hence destroying the stable limit cycle. Further application of the noise may return the system to spiking activity. In a particular noise range, the transition times between the oscillating and the resting state are strongly asymmetric. We numerically investigate an approximate basin of attraction, A, of the periodic orbit and use Markov process theory to explain the firing behavior in terms of the probability of escape of trajectories from A",Biology
"Bird flocking is a striking example of collective animal behaviour. A vivid illustration of this phenomenon is provided by the aerial display of vast flocks of starlings gathering at dusk over the roost and swirling with extraordinary spatial coherence. Both the evolutionary justification and the mechanistic laws of flocking are poorly understood, arguably because of a lack of data on large flocks. Here, we report a quantitative study of aerial display. We measured the individual three-dimensional positions in compact flocks of up to 2700 birds. We investigated the main features of the flock as a whole - shape, movement, density and structure - and discuss these as emergent attributes of the grouping phenomenon. We find that flocks are relatively thin, with variable sizes, but constant proportions. They tend to slide parallel to the ground and, during turns, their orientation changes with respect to the direction of motion. Individual birds keep a minimum distance from each other that is comparable to their wingspan. The density within the aggregations is non-homogeneous, as birds are packed more tightly at the border compared to the centre of the flock. These results constitute the first set of large-scale data on three-dimensional animal aggregations. Current models and theories of collective animal behaviour can now be tested against these results.",Biology
"Considering a basic enzyme-catalysed reaction, in which the rate of input of the substrate varies periodically in time, we give a necessary and sufficient condition for the existence of a periodic solution of the reaction equations. The proof employs the Leray-Schauder degree, applied to an appropriately constructed homotopy.",Biology
"Schizophrenia is a severe, currently incurable, relatively common mental condition. Its symptoms are complex and widespread. It structurally and functionally affects cortical and subcortical regions involved in cognitive, emotional and motivational aspects of behavior. Its cause is unknown, its diagnosis is based on statistical behavior and its treatment is elusive.   Our paradigm addresses the complexity of schizophrenic symptoms. Building upon recent neural vulnerability and limbic dysregulation hypotheses, it offers a mathematical model for the evolution of the limbic system under perturbation. Dependence on parameters and the concept of ""bifurcation"" could be the key to understanding the threshold between ""normality"" and ""disease"".",Biology
"Vibrational energy transfer of the amide I mode of N-methylacetamide (NMA) is studied theoretically using the vibrational configuration interaction method. A quartic force field of NMA is constructed at the B3LYP/6-31G+(d) level of theory and its accuarcy is checked by comparing the resulting anharmonic frequencies with available theoretical and experimental values. Quantum dynamics calculations for the amide I mode excitation clarify the dominant energy transfer pathways, which sensitively depend on the anharmonic couplings among vibrational modes. A ratio of the anharmonic coupling to the frequency mismatch is employed to predict and interpret the dominant energy flow pathways.",Biology
"In this paper, we focus on a spatial Holling-type IV predator-prey model which contains some important factors, such as diffusion, noise (random fluctuations) and external periodic forcing. By a brief stability and bifurcation analysis, we arrive at the Hopf and Turing bifurcation surface and derive the symbolic conditions for Hopf and Turing bifurcation in the spatial domain. Based on the stability and bifurcation analysis, we obtain spiral pattern formation via numerical simulation. Additionally, we study the model with colored noise and external periodic forcing. From the numerical results, we know that noise or external periodic forcing can induce instability and enhance the oscillation of the species, and resonant response. Our results show that modeling by reaction-diffusion equations is an appropriate tool for investigating fundamental mechanisms of complex spatiotemporal dynamics.",Biology
"Recently, structural analysis of the human transferrin and growth hormone (GH) amino acid sequences has unravelled that they harbor a motif identical to a pattern found in viral oncoproteins known to bind the primarily nuclear tumor suppressor retinoblastoma protein (RB). Since related signatures had previously been identified also in insulin and the two insulin-like growth factors (IGFs), the aim of the current study has been to investigate whether further hints substantiating these reported homologies can be found in silico. Here, additional similarities are presented supporting the notion of an insulin superfamily of growth-promoting proteins with dual localization in the extracellular environment and the intracellular space, particularly in the nucleus, as well as characterized by a tropism for RB.",Biology
"Constraint-based modeling has been widely used on metabolic networks analysis, such as biosynthetic prediction and flux optimization. The linear constraints, like mass conservation constraint, reversibility constraint, biological capacity constraint, can be imposed on linear algorithms. However, recently a non-linear constraint based on the second thermodynamic law, known as ""loop law"", has emerged and challenged the existing algorithms. Proven to be unfeasible with linear solutions, this non-linear constraint has been successfully imposed on the sampling process. In this place, Monte - Carlo sampling with Metropolis criterion and Simulated Annealing has been introduced to optimize the Biomass synthesis of genome scale metabolic network of Helicobacter pylori (iIT341 GSM / GPR) under mass conservation constraint, biological capacity constraint, and thermodynamic constraints including reversibility and ""loop law"". The sampling method has also been employed to optimize a non-linear objective function, the Biomass synthetic rate, which is unified by the total income number of reducible electrons. To verify whether a sample contains internal loops, an automatic solution has been developed based on solving a set of inequalities. In addition, a new type of pathway has been proposed here, the Futile Pathway, which has three properties: 1) its mass flow could be self-balanced; 2) it has exchange reactions; 3) it is independent to the biomass synthesis. To eliminate the fluxes of the Futile Pathways in the sampling results, a linear programming based method has been suggested and the results have showed improved correlations among the reaction fluxes in the pathways related to Biomass synthesis.",Biology
"Wild animals, pets, zoo animals and mammals of veterinary importance heavily suffer from trypanosomiasis. Drugs with serious side effects are currently mainstay of therapies used by veterinarians. Trypanosomiasis is caused by Trypanosoma sp. leading to sleeping sickness in humans. Surface modified (hydrophobic and lipophilic) amorphous nanoporous silica molecules could be effectively used as therapeutic drug for combating trypanosomiasis. The amorphous nanosilica was developed by top-down approach using volcanic soil derived silica (Advasan; 50- 60 nm size with 3-10 nm inner pore size range) and diatomaceous earth (FS; 60-80 nm size with 3-5 nm inner pore size range) as source materials. According to WHO and USDA standards amorphous silica has long been used as feed additives for several veterinary industries and considered to be safe for human consumption. The basic mechanism of action of these nanosilica molecules is mediated by the physical absorption of HDL components in the lipophilic nanopores of nanosilica. This reduces the supply of the host derived cholesterol, thus limiting the growth of the Trypanosoma sp. in vivo.",Biology
"A coarse-grained computational procedure based on the Finite Element Method is proposed to calculate the normal modes and mechanical response of proteins and their supramolecular assemblies. Motivated by the elastic network model, proteins are modeled as homogeneous isotropic elastic solids with volume defined by their solvent-excluded surface. The discretized Finite Element representation is obtained using a surface simplification algorithm that facilitates the generation of models of arbitrary prescribed spatial resolution. The procedure is applied to compute the normal modes of a mutant of T4 phage lysozyme and of filamentous actin, as well as the critical Euler buckling load of the latter when subject to axial compression. Results compare favorably with all-atom normal mode analysis, the Rotation Translation Blocks procedure, and experiment. The proposed methodology establishes a computational framework for the calculation of protein mechanical response that facilitates the incorporation of specific atomic-level interactions into the model, including aqueous-electrolyte-mediated electrostatic effects. The procedure is equally applicable to proteins with known atomic coordinates as it is to electron density maps of proteins, protein complexes, and supramolecular assemblies of unknown atomic structure.",Biology
It is proposed that using both self-non-self and danger theories give a better understanding of how the immune system works. It is proposed that comparing immune system to police force is useful in this case since police responds both to danger or damage signals and to foreign or suspicious behavior even if no danger signals existed. We also propose that due to low zone tolerance immunotherapy needs to be combined with another treatment method for cancer e.g. chemotherapy or/and radiotherapy to get a sufficient eradication of tumors. Finally we propose that fractional order differential equations are more suitable than the familiar integer order differential equations. A fractional order example of two immune effectors attacking an antigen is given.,Biology
"In the study of the basic properties observed in the immune system and, in a broader view, in biological systems, several concepts have already been mathematically formulated or treated in an analytical perspective, such as degeneracy, robustness, noise, and bow tie architecture. These properties, among others, seem to rule many aspects of the system functioning, and share among themselvesseveral characteristics, intersecting each other, and often becoming one the indivisible part of the other. According to Kitano, systems biology needs solid theoretical and methodological foundation of principles and properties, able to lead towards a unified perspective. An effort in unifying the formalization and analysis of these principles can be now timely attempted.",Biology
"The identification of genes essential for survival is important for the understanding of the minimal requirements for cellular life and for drug design. As experimental studies with the purpose of building a catalog of essential genes for a given organism are time-consuming and laborious, a computational approach which could predict gene essentiality with high accuracy would be of great value. We present here a novel computational approach, called NTPGE (Network Topology-based Prediction of Gene Essentiality), that relies on network topology features of a gene to estimate its essentiality. The first step of NTPGE is to construct the integrated molecular network for a given organism comprising protein physical, metabolic and transcriptional regulation interactions. The second step consists in training a decision tree-based machine learning algorithm on known essential and non-essential genes of the organism of interest, considering as learning attributes the network topology information for each of these genes. Finally, the decision tree classifier generated is applied to the set of genes of this organism to estimate essentiality for each gene. We applied the NTPGE approach for discovering essential genes in Escherichia coli and then assessed its performance.",Biology
"We study the on-line minimum weighted bipartite matching problem in arbitrary metric spaces. Here, $n$ not necessary disjoint points of a metric space $M$ are given, and are to be matched on-line with $n$ points of $M$ revealed one by one. The cost of a matching is the sum of the distances of the matched points, and the goal is to find or approximate its minimum. The competitive ratio of the deterministic problem is known to be $\Theta(n)$. It was conjectured that a randomized algorithm may perform better against an oblivious adversary, namely with an expected competitive ratio $\Theta(\log n)$. We prove a slightly weaker result by showing a $o(\log^3 n)$ upper bound on the expected competitive ratio. As an application the same upper bound holds for the notoriously hard fire station problem, where $M$ is the real line.",Computer Science
We investigate raytracing performance that can be achieved on a class of Blue Gene supercomputers. We measure a 822 times speedup over a Pentium IV on a 6144 processor Blue Gene/L. We measure the computational performance as a function of number of processors and problem size to determine the scaling performance of the raytracing calculation on the Blue Gene. We find nontrivial scaling behavior at large number of processors. We discuss applications of this technology to scientific visualization with advanced lighting and high resolution. We utilize three racks of a Blue Gene/L in our calculations which is less than three percent of the the capacity of the worlds largest Blue Gene computer.,Computer Science
"The problem of publishing personal data without giving up privacy is becoming increasingly important. An interesting formalization recently proposed is the k-anonymity. This approach requires that the rows in a table are clustered in sets of size at least k and that all the rows in a cluster become the same tuple, after the suppression of some records. The natural optimization problem, where the goal is to minimize the number of suppressed entries, is known to be NP-hard when the values are over a ternary alphabet, k = 3 and the rows length is unbounded. In this paper we give a lower bound on the approximation factor that any polynomial-time algorithm can achive on two restrictions of the problem,namely (i) when the records values are over a binary alphabet and k = 3, and (ii) when the records have length at most 8 and k = 4, showing that these restrictions of the problem are APX-hard.",Computer Science
"Wireless Sensor Networks research and demand are now in full expansion, since people came to understand these are the key to a large number of issues in industry, commerce, home automation, healthcare, agriculture and environment, monitoring, public safety etc. One of the most challenging research problems in sensor networks research is power awareness and power-saving techniques. In this master's thesis, we have studied one particular power-saving technique, i.e. frequency scaling. In particular, we analysed the close relationship between clock frequencies in a microcontroller and several types of constraints imposed on these frequencies, e.g. by other components of the microcontroller, by protocol specifications, by external factors etc. Among these constraints, we were especially interested in the ones imposed by the timer service and by the serial ports' transmission rates. Our efforts resulted in a microcontroller configuration management tool which aims at assisting application programmers in choosing microcontroller configurations, in function of the particular needs and constraints of their application.",Computer Science
"The capacity region of the two-user Gaussian Interference Channel (IC) is studied. Three classes of channels are considered: weak, one-sided, and mixed Gaussian IC. For the weak Gaussian IC, a new outer bound on the capacity region is obtained that outperforms previously known outer bounds. The sum capacity for a certain range of channel parameters is derived. For this range, it is proved that using Gaussian codebooks and treating interference as noise is optimal. It is shown that when Gaussian codebooks are used, the full Han-Kobayashi achievable rate region can be obtained by using the naive Han-Kobayashi achievable scheme over three frequency bands (equivalently, three subspaces). For the one-sided Gaussian IC, an alternative proof for the Sato's outer bound is presented. We derive the full Han-Kobayashi achievable rate region when Gaussian codebooks are utilized. For the mixed Gaussian IC, a new outer bound is obtained that outperforms previously known outer bounds. For this case, the sum capacity for the entire range of channel parameters is derived. It is proved that the full Han-Kobayashi achievable rate region using Gaussian codebooks is equivalent to that of the one-sided Gaussian IC for a particular range of channel parameters.",Computer Science
"A fundamental problem in artificial intelligence is that nobody really knows what intelligence is. The problem is especially acute when we need to consider artificial systems which are significantly different to humans. In this paper we approach this problem in the following way: We take a number of well known informal definitions of human intelligence that have been given by experts, and extract their essential features. These are then mathematically formalised to produce a general measure of intelligence for arbitrary machines. We believe that this equation formally captures the concept of machine intelligence in the broadest reasonable sense. We then show how this formal definition is related to the theory of universal optimal learning agents. Finally, we survey the many other tests and definitions of intelligence that have been proposed for machines.",Computer Science
"Overheating has been acknowledged as a major issue in testing complex SOCs. Several power constrained system-level DFT solutions (power constrained test scheduling) have recently been proposed to tackle this problem. However, as it will be shown in this paper, imposing a chip-level maximum power constraint doesn't necessarily avoid local overheating due to the non-uniform distribution of power across the chip. This paper proposes a new approach for dealing with overheating during test, by embedding thermal awareness into test scheduling. The proposed approach facilitates rapid generation of thermal-safer test schedules without requiring time-consuming thermal simulations. This is achieved by employing a low-complexity test session thermal model used to guide the test schedule generation algorithm. This approach reduces the chances of a design re-spin due to potential overheating during test.",Computer Science
"Recently, great efforts have been dedicated to researches on the management of large scale graph based data such as WWW, social networks, biological networks. In the study of graph based data management, node disjoint subgraph homeomorphism relation between graphs is more suitable than (sub)graph isomorphism in many cases, especially in those cases that node skipping and node mismatching are allowed. However, no efficient node disjoint subgraph homeomorphism determination (ndSHD) algorithms have been available. In this paper, we propose two computationally efficient ndSHD algorithms based on state spaces searching with backtracking, which employ many heuristics to prune the search spaces. Experimental results on synthetic data sets show that the proposed algorithms are efficient, require relative little time in most of the testing cases, can scale to large or dense graphs, and can accommodate to more complex fuzzy matching cases.",Computer Science
"Collaborative tagging has recently attracted the attention of both industry and academia due to the popularity of content-sharing systems such as CiteULike, del.icio.us, and Flickr. These systems give users the opportunity to add data items and to attach their own metadata (or tags) to stored data. The result is an effective content management tool for individual users. Recent studies, however, suggest that, as tagging communities grow, the added content and the metadata become harder to manage due to an ease in content diversity. Thus, mechanisms that cope with increase of diversity are fundamental to improve the scalability and usability of collaborative tagging systems. This paper analyzes whether usage patterns can be harnessed to improve navigability in a growing knowledge space. To this end, it presents a characterization of two collaborative tagging communities that target scientific literature: CiteULike and Bibsonomy. We explore three main directions: First, we analyze the tagging activity distribution across the user population. Second, we define new metrics for similarity in user interest and use these metrics to uncover the structure of the tagging communities we study. The structure we uncover suggests a clear segmentation of interests into a large number of individuals with unique preferences and a core set of users with interspersed interests. Finally, we offer preliminary results that demonstrate that the interest-based structure of the tagging community can be used to facilitate content usage as communities scale.",Computer Science
"We consider a backhaul-constrained coordinated cellular network. That is, a single-frequency network with $N+1$ multi-antenna base stations (BSs) that cooperate in order to decode the users' data, and that are linked by means of a common lossless backhaul, of limited capacity $\mathrm{R}$. To implement receive cooperation, we propose distributed compression: $N$ BSs, upon receiving their signals, compress them using a multi-source lossy compression code. Then, they send the compressed vectors to a central BS, which performs users' decoding. Distributed Wyner-Ziv coding is proposed to be used, and is optimally designed in this work. The first part of the paper is devoted to a network with a unique multi-antenna user, that transmits a predefined Gaussian space-time codeword. For such a scenario, the compression codebooks at the BSs are optimized, considering the user's achievable rate as the performance metric. In particular, for $N = 1$ the optimum codebook distribution is derived in closed form, while for $N>1$ an iterative algorithm is devised. The second part of the contribution focusses on the multi-user scenario. For it, the achievable rate region is obtained by means of the optimum compression codebooks for sum-rate and weighted sum-rate, respectively.",Computer Science
"This paper presents a fault classification method which makes use of a Takagi-Sugeno neuro-fuzzy model and Pseudomodal energies calculated from the vibration signals of cylindrical shells. The calculation of Pseudomodal Energies, for the purposes of condition monitoring, has previously been found to be an accurate method of extracting features from vibration signals. This calculation is therefore used to extract features from vibration signals obtained from a diverse population of cylindrical shells. Some of the cylinders in the population have faults in different substructures. The pseudomodal energies calculated from the vibration signals are then used as inputs to a neuro-fuzzy model. A leave-one-out cross-validation process is used to test the performance of the model. It is found that the neuro-fuzzy model is able to classify faults with an accuracy of 91.62%, which is higher than the previously used multilayer perceptron.",Computer Science
"Spectrum sensing is an essential functionality that enables cognitive radios to detect spectral holes and opportunistically use under-utilized frequency bands without causing harmful interference to primary networks. Since individual cognitive radios might not be able to reliably detect weak primary signals due to channel fading/shadowing, this paper proposes a cooperative wideband spectrum sensing scheme, referred to as spatial-spectral joint detection, which is based on a linear combination of the local statistics from spatially distributed multiple cognitive radios. The cooperative sensing problem is formulated into an optimization problem, for which suboptimal but efficient solutions can be obtained through mathematical transformation under practical conditions.",Computer Science
"It is widely acknowledged that good object clustering is critical to the performance of object-oriented databases. However, object clustering always involves some kind of overhead for the system. The aim of this paper is to propose a modelling methodology in order to evaluate the performances of different clustering policies. This methodology has been used to compare the performances of three clustering algorithms found in the literature (Cactis, CK and ORION) that we considered representative of the current research in the field of object clustering. The actual performance evaluation was performed using simulation. Simulation experiments we performed showed that the Cactis algorithm is better than the ORION algorithm and that the CK algorithm totally outperforms both other algorithms in terms of response time and clustering overhead.",Computer Science
"OBJECTIVE: The TER system is a robot-based tele-echography system allowing remote ultrasound examination. The specialist moves a mock-up of the ultrasound probe at the master site, and the robot reproduces the movements of the real probe, which sends back ultrasound images and force feedback. This tool could be used to perform ultrasound examinations in small health care centers or from isolated sites. The objective of this study was to prove, under real conditions, the feasibility and reliability of the TER system in detecting abdominal aortic and iliac aneurysms. METHODS: Fifty-eight patients were included in 2 centers in Brest and Grenoble, France. The remote examination was compared with the reference standard, the bedside examination, for aorta and iliac artery diameter measurement, detection and description of aneurysms, detection of atheromatosis, the duration of the examination, and acceptability. RESULTS: All aneurysms (8) were detected by both techniques as intramural thrombosis and extension to the iliac arteries. The interobserver correlation coefficient was 0.982 (P < .0001) for aortic diameters. The rate of concordance between 2 operators in evaluating atheromatosis was 84% +/- 11% (95% confidence interval). CONCLUSIONS: Our study on 58 patients suggests that the TER system could be a reliable, acceptable, and effective robot-based system for performing remote abdominal aortic ultrasound examinations. Research is continuing to improve the equipment for general abdominal use.",Computer Science
This paper discusses why P and NP are likely to be different. It analyses the essence of the concepts and points out that P and NP might be diverse by sheer definition. It also speculates that P and NP may be unequal due to natural laws.,Computer Science
"Traditional parallel schedulers running on cluster supercomputers support only static scheduling, where the number of processors allocated to an application remains fixed throughout the execution of the job. This results in under-utilization of idle system resources thereby decreasing overall system throughput. In our research, we have developed a prototype framework called ReSHAPE, which supports dynamic resizing of parallel MPI applications executing on distributed memory platforms. The resizing library in ReSHAPE includes support for releasing and acquiring processors and efficiently redistributing application state to a new set of processors. In this paper, we derive an algorithm for redistributing two-dimensional block-cyclic arrays from $P$ to $Q$ processors, organized as 2-D processor grids. The algorithm ensures a contention-free communication schedule for data redistribution if $P_r \leq Q_r$ and $P_c \leq Q_c$. In other cases, the algorithm implements circular row and column shifts on the communication schedule to minimize node contention.",Computer Science
"In this paper, a transmission protocol is studied for a two relay wireless network in which simple repetition coding is applied at the relays. Information-theoretic achievable rates for this transmission scheme are given, and a space-time V-BLAST signalling and detection method that can approach them is developed. It is shown through the diversity multiplexing tradeoff analysis that this transmission scheme can recover the multiplexing loss of the half-duplex relay network, while retaining some diversity gain. This scheme is also compared with conventional transmission protocols that exploit only the diversity of the network at the cost of a multiplexing loss. It is shown that the new transmission protocol offers significant performance advantages over conventional protocols, especially when the interference between the two relays is sufficiently strong.",Computer Science
"The unit cost model is both convenient and largely realistic for describing integer decision algorithms over (+,*). Additional operations like division with remainder or bitwise conjunction, although equally supported by computing hardware, may lead to a considerable drop in complexity. We show a variety of concrete problems to benefit from such NON-arithmetic primitives by presenting and analyzing corresponding fast algorithms.",Computer Science
"We prove that any finite collection of polygons of equal area has a common hinged dissection. That is, for any such collection of polygons there exists a chain of polygons hinged at vertices that can be folded in the plane continuously without self-intersection to form any polygon in the collection. This result settles the open problem about the existence of hinged dissections between pairs of polygons that goes back implicitly to 1864 and has been studied extensively in the past ten years. Our result generalizes and indeed builds upon the result from 1814 that polygons have common dissections (without hinges). We also extend our common dissection result to edge-hinged dissections of solid 3D polyhedra that have a common (unhinged) dissection, as determined by Dehn's 1900 solution to Hilbert's Third Problem. Our proofs are constructive, giving explicit algorithms in all cases. For a constant number of planar polygons, both the number of pieces and running time required by our construction are pseudopolynomial. This bound is the best possible, even for unhinged dissections. Hinged dissections have possible applications to reconfigurable robotics, programmable matter, and nanomanufacturing.",Computer Science
"A unified analytical framework for optimum power allocation in the unordered V-BLAST algorithm and its comparative performance analysis are presented. Compact closed-form approximations for the optimum power allocation are derived, based on average total and block error rates. The choice of the criterion has little impact on the power allocation and, overall, the optimum strategy is to allocate more power to lower step transmitters and less to higher ones. High-SNR approximations for optimized average block and total error rates are given. The SNR gain of optimization is rigorously defined and studied using analytical tools, including lower and upper bounds, high and low SNR approximations. The gain is upper bounded by the number of transmitters, for any modulation format and type of fading channel. While the average optimization is less complex than the instantaneous one, its performance is almost as good at high SNR. A measure of robustness of the optimized algorithm is introduced and evaluated. The optimized algorithm is shown to be robust to perturbations in individual and total transmit powers. Based on the algorithm robustness, a pre-set power allocation is suggested as a low-complexity alternative to the other optimization strategies, which exhibits only a minor loss in performance over the practical SNR range.",Computer Science
"We demonstrate a polynomial approach to express the decision version of the directed Hamiltonian Cycle Problem (HCP), which is NP-Complete, as the Solvability of a Polynomial Equation with a constant number of variables, within a bounded real space. We first introduce four new Theorems for a set of periodic Functions with irrational periods, based on which we then use a trigonometric substitution, to show how the HCP can be expressed as the Solvability of a single polynomial Equation with a constant number of variables. The feasible solution of each of these variables is bounded within two real numbers. We point out what future work is necessary to prove that P=NP.",Computer Science
"For a graph G, consider the pairs of edge-disjoint matchings whose union consists of as many edges as possible. Let H be the largest matching among such pairs. Let M be a maximum matching of G. We show that 5/4 is a tight upper bound for |M|/|H|.",Computer Science
"Design, implementation, and machine learning issues associated with developing a control system for a serpentine robotic manipulator are explored. The controller developed provides autonomous control of the serpentine robotic manipulatorduring operation of the manipulator within an enclosed environment such as an underground storage tank. The controller algorithms make use of both low-level joint angle control employing force/position feedback constraints, and high-level coordinated control of end-effector positioning. This approach has resulted in both high-level full robotic control and low-level telerobotic control modes, and provides a high level of dexterity for the operator.",Computer Science
"The author reviews the computer and robotic tools available to urologists to help in diagnosis and technical procedures. The first part concerns the contribution of robotics and presents several systems at various stages of development (laboratory prototypes, systems under validation or marketed systems). The second part describes image fusion tools and navigation systems currently under development or evaluation. Several studies on computerized simulation of urological procedures are also presented.",Computer Science
"The need to visualize large social networks is growing as hardware capabilities make analyzing large networks feasible and many new data sets become available. Unfortunately, the visualizations in existing systems do not satisfactorily answer the basic dilemma of being readable both for the global structure of the network and also for detailed analysis of local communities. To address this problem, we present NodeTrix, a hybrid representation for networks that combines the advantages of two traditional representations: node-link diagrams are used to show the global structure of a network, while arbitrary portions of the network can be shown as adjacency matrices to better support the analysis of communities. A key contribution is a set of interaction techniques. These allow analysts to create a NodeTrix visualization by dragging selections from either a node-link or a matrix, flexibly manipulate the NodeTrix representation to explore the dataset, and create meaningful summary visualizations of their findings. Finally, we present a case study applying NodeTrix to the analysis of the InfoVis 2004 coauthorship dataset to illustrate the capabilities of NodeTrix as both an exploration tool and an effective means of communicating results.",Computer Science
"In this contribution, the performance of a multi-user system is analyzed in the context of frequency selective fading channels. Using game theoretic tools, a useful framework is provided in order to determine the optimal power allocation when users know only their own channel (while perfect channel state information is assumed at the base station). We consider the realistic case of frequency selective channels for uplink CDMA. This scenario illustrates the case of decentralized schemes, where limited information on the network is available at the terminal. Various receivers are considered, namely the Matched filter, the MMSE filter and the optimum filter. The goal of this paper is to derive simple expressions for the non-cooperative Nash equilibrium as the number of mobiles becomes large and the spreading length increases. To that end two asymptotic methodologies are combined. The first is asymptotic random matrix theory which allows us to obtain explicit expressions of the impact of all other mobiles on any given tagged mobile. The second is the theory of non-atomic games which computes good approximations of the Nash equilibrium as the number of mobiles grows.",Computer Science
"Spreadsheets provide many of the key links between information systems, closing the gap between business needs and the capability of central systems. Recent regulations have brought these vulnerable parts of information supply chains into focus. The risk they present to the organisation depends on the role that they fulfil, with generic differences between their use as modeling tools and as operational applications. Four sections of the Sarbanes-Oxley Act (SOX) are particularly relevant to the use of spreadsheets. Compliance with each of these sections is dependent on maintaining the integrity of those spreadsheets acting as operational applications. This can be achieved manually but at high cost. There are a range of commercially available off-the-shelf solutions that can reduce this cost. These may be divided into those that assist in the debugging of logic and more recently the arrival of solutions that monitor the change and user activity taking place in business-critical spreadsheets. ClusterSeven provides one of these monitoring solutions, highlighting areas of operational risk whilst also establishing a database of information to deliver new business intelligence.",Computer Science
"This article provides a formalism making it possible to manage the solutions of the direct and inverse kinematic models of the fully parallel manipulators. We introduce the concept of working modes to separate the solutions from the opposite geometrical model. Then, we define, for each working mode, the aspects of these manipulators. To separate the solutions from the direct kinematics model, we introduce the concept of characteristic surfaces. Then, we define the uniqueness domains, as being the greatest domains of the workspace in which there is unicity of solutions. The principal applications of this work are the design, the trajectory planning.",Computer Science
"We show that disjointness requires randomized communication Omega(n^{1/(k+1)}/2^{2^k}) in the general k-party number-on-the-forehead model of complexity. The previous best lower bound for k >= 3 was log(n)/(k-1). Our results give a separation between nondeterministic and randomized multiparty number-on-the-forehead communication complexity for up to k=log log n - O(log log log n) many players. Also by a reduction of Beame, Pitassi, and Segerlind, these results imply subexponential lower bounds on the size of proofs needed to refute certain unsatisfiable CNFs in a broad class of proof systems, including tree-like Lovasz-Schrijver proofs.",Computer Science
"This paper details the use of the IT Infrastructure Library Framework (ITIL) for optimising process workflows in the IT Service Centre of Harz University in Wernigerode, Germany, exemplified by the Release Management Process. It is described, how, during the course of a special ITIL project, the As-Is-Status of the various original processes was documented as part of the process life cycle and then transformed in the To-Be-Status, according to the ITIL Best Practice Framework. It is also shown, how the ITIL framework fits into the four-layered-process model, that could be derived from interviews with the universities IT support staff, and how the various modified processes interconnect with each other to form a value chain. The paper highlights the final results of the project and gives an outlook on the future use of ITIL as a business modelling tool in the IT Service Centre of Harz University. It is currently being considered, whether the process model developed during the project could be used as a reference model for other university IT centres.",Computer Science
"A proof is provided of the operational achievability of $R_\mathrm{rt}$ by the recursive training scheme in \cite{zhang07:it}, for general wide-sense stationary and ergodic Rayleigh fading processes.",Computer Science
"Integer octagonal constraints (a.k.a. ``Unit Two Variables Per Inequality'' or ``UTVPI integer constraints'') constitute an interesting class of constraints for the representation and solution of integer problems in the fields of constraint programming and formal analysis and verification of software and hardware systems, since they couple algorithms having polynomial complexity with a relatively good expressive power. The main algorithms required for the manipulation of such constraints are the satisfiability check and the computation of the inferential closure of a set of constraints. The latter is called `tight' closure to mark the difference with the (incomplete) closure algorithm that does not exploit the integrality of the variables. In this paper we present and fully justify an O(n^3) algorithm to compute the tight closure of a set of UTVPI integer constraints.",Computer Science
"In Magnetic Resonance Imaging (MRI), to achieve sufficient Signal to Noise Ratio (SNR), the electrical performance of the RF coil is critical. We developed a device (microcoil) based on the original concept of monolithic resonator. This paper presents the used fabrication process based on micromoulding. The dielectric substrates are flexible thin films of polymer, which allow the microcoil to be form fitted to none-plane surface. Electrical characterizations of the RF coils are first performed and results are compared to the attempted values. Proton MRI of a saline phantom using a flexible RF coil of 15 mm in diameter is performed. When the coil is conformed to the phantom surface, a SNR gain up to 2 is achieved as compared to identical but planar RF coil. Finally, the flexible coil is used in vivo to perform MRI with high spatial resolution on a mouse using a small animal dedicated scanner operating at in a 2.35 T.",Computer Science
"Neural network models of real-world systems, such as industrial processes, made from sensor data must often rely on incomplete data. System states may not all be known, sensor data may be biased or noisy, and it is not often known which sensor data may be useful for predictive modelling. Genetic algorithms may be used to help to address this problem by determining the near optimal subset of sensor variables most appropriate to produce good models. This paper describes the use of genetic search to optimize variable selection to determine inputs into the neural network model. We discuss genetic algorithm implementation issues including data representation types and genetic operators such as crossover and mutation. We present the use of this technique for neural network modelling of a typical industrial application, a liquid fed ceramic melter, and detail the results of the genetic search to optimize the neural network model for this application.",Computer Science
"The Golden space-time trellis coded modulation (GST-TCM) scheme was proposed in \cite{Hong06} for a high rate $2\times 2$ multiple-input multiple-output (MIMO) system over slow fading channels. In this letter, we present the performance analysis of GST-TCM over block fading channels, where the channel matrix is constant over a fraction of the codeword length and varies from one fraction to another, independently. In practice, it is not useful to design such codes for specific block fading channel parameters and a robust solution is preferable. We then show both analytically and by simulation that the GST-TCM designed for slow fading channels are indeed robust to all block fading channel conditions.",Computer Science
"This article is presented new method of description information systems in abstract 4-dimensional pseudo-Euclidean information space (4-DPIES) with using special relativity (SR) methods. This purpose core postulates of existence 4-DPIES are formulated. The theorem setting existence criteria of the invariant velocity of the information transference is formulated and proved. One more theorem allowed relating discrete parameters of information and continuous space-time treating and also row of supplementary theorems is formulated and proved. For description of dynamics and interaction of information, in article is introduced general parameter of information - generalized information emotion (GIE), reminding simultaneously on properties the mass and the charge. At performing calculation of information observable parameters in the information space is introduced continual integration methods of Feynman. The applying idea about existence of GIE as measures of the information inertness and the interaction carrier, and using continual integration methods of Feynman can be calculated probability of information process in 4-DPIES. In this frame presented approach has allowed considering information systems when interest is presented with information processes, their related with concrete definition without necessity. The relation between 4-DPIES and real systems parameters is set at modelling of matching between observable processes and real phenomena from information interpretation.",Computer Science
We have presented an optimal buffer sizing and buffer insertion methodology which uses stochastic models of the architecture and Continuous Time Markov Decision Processes CTMDPs. Such a methodology is useful in managing the scarce buffer resources available on chip as compared to network based data communication which can have large buffer space. The modeling of this problem in terms of a CT-MDP framework lead to a nonlinear formulation due to usage of bridges in the bus architecture. We present a methodology to split the problem into several smaller though linear systems and we then solve these subsystems.,Computer Science
"Geometric complexity theory (GCT) is an approach to the $P$ vs. $NP$ and related problems through algebraic geometry and representation theory. This article gives a high-level exposition of the basic plan of GCT based on the principle, called the flip, without assuming any background in algebraic geometry or representation theory.",Computer Science
"The next generation of virtual environments for training is oriented towards collaborative aspects. Therefore, we have decided to enhance our platform for virtual training environments, adding collaboration opportunities and integrating humanoids. In this paper we put forward a model of humanoid that suits both virtual humans and representations of real users, according to collaborative training activities. We suggest adaptations to the scenario model of our platform making it possible to write collaborative procedures. We introduce a mechanism of action selection made up of a global repartition and an individual choice. These models are currently being integrated and validated in GVT, a virtual training tool for maintenance of military equipments, developed in collaboration with the French company NEXTER-Group.",Computer Science
"In this paper, the performance of signaling strategies with high peak-to-average power ratio is analyzed in both coherent and noncoherent fading channels. Two recently proposed modulation schemes, namely on-off binary phase-shift keying and on-off quaternary phase-shift keying, are considered. For these modulation formats, the optimal decision rules used at the detector are identified and analytical expressions for the error probabilities are obtained. Numerical techniques are employed to compute the error probabilities. It is concluded that increasing the peakedness of the signals results in reduced error rates for a given power level and hence improve the energy efficiency.",Computer Science
"On a fading channel with no channel state information at the receiver, calculating true log-likelihood ratios (LLR) is complicated. Existing work assume that the power of the additive noise is known and use the expected value of the fading gain in a linear function of the channel output to find approximate LLRs. In this work, we first assume that the power of the additive noise is known and we find the optimum linear approximation of LLRs in the sense of maximum achievable transmission rate on the channel. The maximum achievable rate under this linear LLR calculation is almost equal to the maximum achievable rate under true LLR calculation. We also observe that this method appears to be the optimum in the sense of bit error rate performance too. These results are then extended to the case that the noise power is unknown at the receiver and a performance almost identical to the case that the noise power is perfectly known is obtained.",Computer Science
"The need for high availability and performance in data management systems has been fueling a long running interest in database replication from both academia and industry. However, academic groups often attack replication problems in isolation, overlooking the need for completeness in their solutions, while commercial teams take a holistic approach that often misses opportunities for fundamental innovation. This has created over time a gap between academic research and industrial practice.   This paper aims to characterize the gap along three axes: performance, availability, and administration. We build on our own experience developing and deploying replication systems in commercial and academic settings, as well as on a large body of prior related work. We sift through representative examples from the last decade of open-source, academic, and commercial database replication systems and combine this material with case studies from real systems deployed at Fortune 500 customers. We propose two agendas, one for academic research and one for industrial R&D, which we believe can bridge the gap within 5-10 years. This way, we hope to both motivate and help researchers in making the theory and practice of middleware-based database replication more relevant to each other.",Computer Science
"We analyze a slow-fading interference network with MN non-cooperating single-antenna sources and M non-cooperating single-antenna destinations. In particular, we assume that the sources are divided into M mutually exclusive groups of N sources each, every group is dedicated to transmit a common message to a unique destination, all transmissions occur concurrently and in the same frequency band and a dedicated 1-bit broadcast feedback channel from each destination to its corresponding group of sources exists. We provide a feedback-based iterative distributed (multi-user) beamforming algorithm, which ""learns"" the channels between each group of sources and its assigned destination. This algorithm is a straightforward generalization, to the multi-user case, of the feedback-based iterative distributed beamforming algorithm proposed recently by Mudumbai et al., in IEEE Trans. Inf. Th. (submitted) for networks with a single group of sources and a single destination. Putting the algorithm into a Markov chain context, we provide a simple convergence proof. We then show that, for M finite and N approaching infinity, spatial multiplexing based on the beamforming weights produced by the algorithm achieves full spatial multiplexing gain of M and full per-stream array gain of N, provided the time spent ""learning'' the channels scales linearly in N. The network is furthermore shown to ""crystallize''. Finally, we characterize the corresponding crystallization rate.",Computer Science
"We consider the problem of estimating the probability of an observed string drawn i.i.d. from an unknown distribution. The key feature of our study is that the length of the observed string is assumed to be of the same order as the size of the underlying alphabet. In this setting, many letters are unseen and the empirical distribution tends to overestimate the probability of the observed letters. To overcome this problem, the traditional approach to probability estimation is to use the classical Good-Turing estimator. We introduce a natural scaling model and use it to show that the Good-Turing sequence probability estimator is not consistent. We then introduce a novel sequence probability estimator that is indeed consistent under the natural scaling model.",Computer Science
"In this paper we discuss the impact of open source on both the security and transparency of a software system. We focus on the more technical aspects of this issue, combining and extending arguments developed over the years. We stress that our discussion of the problem only applies to software for general purpose computing systems. For embedded systems, where the software usually cannot easily be patched or upgraded, different considerations may apply.",Computer Science
"The distributed source coding problem is considered when the sensors, or encoders, are under Byzantine attack; that is, an unknown number of sensors have been reprogrammed by a malicious intruder to undermine the reconstruction at the fusion center. Three different forms of the problem are considered. The first is a variable-rate setup, in which the decoder adaptively chooses the rates at which the sensors transmit. An explicit characterization of the variable-rate minimum achievable sum rate is stated, given by the maximum entropy over the set of distributions indistinguishable from the true source distribution by the decoder. In addition, two forms of the fixed-rate problem are considered, one with deterministic coding and one with randomized coding. The achievable rate regions are given for both these problems, with a larger region achievable using randomized coding, though both are suboptimal compared to variable-rate coding.",Computer Science
"For a state-dependent DMC with input alphabet $\mathcal{X}$ and state alphabet $\mathcal{S}$ where the i.i.d. state sequence is known causally at the transmitter, it is shown that by using at most $|\mathcal{X}||\mathcal{S}|-|\mathcal{S}|+1$ out of $|\mathcal{X}|^{|\mathcal{S}|}$ input symbols of the Shannon's \emph{associated} channel, the capacity is achievable. As an example of state-dependent channels with side information at the transmitter, $M$-ary signal transmission over AWGN channel with additive $Q$-ary interference where the sequence of i.i.d. interference symbols is known causally at the transmitter is considered. For the special case where the Gaussian noise power is zero, a sufficient condition, which is independent of interference, is given for the capacity to be $\log_2 M$ bits per channel use. The problem of maximization of the transmission rate under the constraint that the channel input given any current interference symbol is uniformly distributed over the channel input alphabet is investigated. For this setting, the general structure of a communication system with optimal precoding is proposed.",Computer Science
Mining for trees in a graph is shown to be NP-complete.,Computer Science
"A new approach for enhancing the process-variation tolerance of digital circuits is described. We extend recent advances in statistical timing analysis into an optimization framework. Our objective is to reduce the performance variance of a technology-mapped circuit where delays across elements are represented by random variables which capture the manufacturing variations. We introduce the notion of statistical critical paths, which account for both means and variances of performance variation. An optimization engine is used to size gates with a goal of reducing the timing variance along the statistical critical paths. We apply a pair of nested statistical analysis methods deploying a slower more accurate approach for tracking statistical critical paths and a fast engine for evaluation of gate size assignments. We derive a new approximation for the max operation on random variables which is deployed for the faster inner engine. Circuit optimization is carried out using a gain-based algorithm that terminates when constraints are satisfied or no further improvements can be made. We show optimization results that demonstrate an average of 72% reduction in performance variation at the expense of average 20% increase in design area.",Computer Science
"This paper describes experiments on learning Dutch phonotactic rules using Inductive Logic Programming, a machine learning discipline based on inductive logical operators. Two different ways of approaching the problem are experimented with, and compared against each other as well as with related work on the task. The results show a direct correspondence between the quality and informedness of the background knowledge and the constructed theory, demonstrating the ability of ILP to take good advantage of the prior domain knowledge available. Further research is outlined.",Computer Science
"Several types of term rewriting systems can be distinguished by the way their rules overlap. In particular, we define the classes of prefix, suffix, bottom-up and top-down systems, which generalize similar classes on words. Our aim is to study the derivation relation of such systems (i.e. the reflexive and transitive closure of their rewriting relation) and, if possible, to provide a finite mechanism characterizing it. Using a notion of rational relations based on finite graph grammars, we show that the derivation of any bottom-up, top-down or suffix systems is rational, while it can be non recursive for prefix systems.",Computer Science
"This paper addresses the architecture optimization of a 3-DOF translational parallel mechanism designed for machining applications. The design optimization is conducted on the basis of a prescribed Cartesian workspace with prescribed kinetostatic performances. The resulting machine, the Orthoglide, features three fixed parallel linear joints which are mounted orthogonally and a mobile platform which moves in the Cartesian x-y-z space with fixed orientation. The interesting features of the Orthoglide are a regular Cartesian workspace shape, uniform performances in all directions and good compactness. A small-scale prototype of the Orthoglide under development is presented at the end of this paper.",Computer Science
"We investigate the following question: if a polynomial can be evaluated at rational points by a polynomial-time boolean algorithm, does it have a polynomial-size arithmetic circuit? We argue that this question is certainly difficult. Answering it negatively would indeed imply that the constant-free versions of the algebraic complexity classes VP and VNP defined by Valiant are different. Answering this question positively would imply a transfer theorem from boolean to algebraic complexity. Our proof method relies on Lagrange interpolation and on recent results connecting the (boolean) counting hierarchy to algebraic complexity classes. As a byproduct we obtain two additional results: (i) The constant-free, degree-unbounded version of Valiant's hypothesis that VP and VNP differ implies the degree-bounded version. This result was previously known to hold for fields of positive characteristic only. (ii) If exponential sums of easy to compute polynomials can be computed efficiently, then the same is true of exponential products. We point out an application of this result to the P=NP problem in the Blum-Shub-Smale model of computation over the field of complex numbers.",Computer Science
"In this paper we propose a new design criterion and a new class of unitary signal constellations for differential space-time modulation for multiple-antenna systems over Rayleigh flat-fading channels with unknown fading coefficients. Extensive simulations show that the new codes have significantly better performance than existing codes. We have compared the performance of our codes with differential detection schemes using orthogonal design, Cayley differential codes, fixed-point-free group codes and product of groups and for the same bit error rate, our codes allow smaller signal to noise ratio by as much as 10 dB. The design of the new codes is accomplished in a systematic way through the optimization of a performance index that closely describes the bit error rate as a function of the signal to noise ratio. The new performance index is computationally simple and we have derived analytical expressions for its gradient with respect to constellation parameters. Decoding of the proposed constellations is reduced to a set of one-dimensional closest point problems that we solve using parallel sphere decoder algorithms. This decoding strategy can also improve efficiency of existing codes.",Computer Science
"Model checking properties are often described by means of finite automata. Any particular such automaton divides the set of infinite trees into finitely many classes, according to which state has an infinite run. Building the full type hierarchy upon this interpretation of the base type gives a finite semantics for simply-typed lambda-trees.   A calculus based on this semantics is proven sound and complete. In particular, for regular infinite lambda-trees it is decidable whether a given automaton has a run or not. As regular lambda-trees are precisely recursion schemes, this decidability result holds for arbitrary recursion schemes of arbitrary level, without any syntactical restriction.",Computer Science
"This paper describes a flexible logic BIST scheme that features high fault coverage achieved by fault-simulation guided test point insertion, real at-speed test capability for multi-clock designs without clock frequency manipulation, and easy physical implementation due to the use of a low-speed SE signal. Application results of this scheme to two widely used IP cores are also reported.",Computer Science
Can there be independent higher level laws of nature if everything is reducible to the fundamental laws of physics? The computer science notion of level of abstraction explains why there can -- illustrating how computational thinking can solve one of philosophy's most vexing problems.,Computer Science
"In this survey we concern ourself with the question, wether there exists a fix-free code for a given sequence of codeword lengths. For a given alphabet, we obtain the {\em Kraftsum} of a code, if we divide for every length the number of codewords of this length in the code by the total number of all possible words of this length and then take summation over all codeword lengths which appears in the code. The same way the Kraftsum of a lengths sequence $(l_1,..., l_n) $ is given by $\sum_{i=1}^n q^{-l_i} $, where $q$ is the numbers of letters in the alphabet. Kraft and McMillan have shown in \cite{kraft} (1956), that there exists a prefix-free code with codeword lengths of a certain lengths sequence, if the Kraftsum of the lengths sequence is smaller than or equal to one. Furthermore they have shown, that the converse also holds for all (uniquely decipherable) codes.\footnote{In this survey a code means a set of words, such that any message which is encoded with these words can be uniquely decoded. Therefore we omit in future the ""uniquely decipherable"" and write only ""code"".} The question rises, if Kraft's and McMillan's result can be generalized to other types of codes? Throughout, we try to give an answer on this question for the class of fix-free codes. Since any code has Kraftsum smaller than or equal to one, this answers the question for the second implication of Kraft-McMillan's theorem. Therefore we pay attention mainly to the first implication.",Computer Science
"In this paper we propose a systematic strategy for migrating crosscutting concerns in existing object-oriented systems to aspect-based solutions. The proposed strategy consists of four steps: mining, exploration, documentation and refactoring of crosscutting concerns. We discuss in detail a new approach to aspect refactoring that is fully integrated with our strategy, and apply the whole strategy to an object-oriented system, namely the JHotDraw framework. The result of this migration is made available as an open-source project, which is the largest aspect refactoring available to date. We report on our experiences with conducting this case study and reflect on the success and challenges of the migration process, as well as on the feasibility of automatic aspect refactoring.",Computer Science
"This article is a short introduction to generic case complexity, which is a recently developed way of measuring the difficulty of a computational problem while ignoring atypical behavior on a small set of inputs. Generic case complexity applies to both recursively solvable and recursively unsolvable problems.",Computer Science
"The animation of human avatars seems very successful; the computer graphics industry shows outstanding results in films everyday, the game industry achieves exploits... Nevertheless, the animation and control processes of such manikins are very painful. It takes days to a specialist to build such animated sequences, and it is not adaptive to any type of modifications. Our main purpose is the virtual human for engineering, especially virtual prototyping. As for this domain of activity, such amounts of time are prohibitive.",Computer Science
Advances in material processing such as silicon micromachining are opening the way to vacuum microelectronics. Two-dimensional vacuum components can be fabricated using the microsystems processes. We developed such devices using a single metal layer and silicon micromachining by DRIE. The latter technological step has significant impact on the characteristics of the vacuum components. This paper presents a brief summary of electron emission possibilities and the design leading to the fabrication of a lateral field emission diode. First measurement results and the aging of the devices are also discussed.,Computer Science
"Cooperative transmission can greatly improve communication system performance by taking advantage of the broadcast nature of wireless channels. Most previous work on resource allocation for cooperation transmission is based on centralized control. In this paper, we propose two share auction mechanisms, the SNR auction and the power auction, to distributively coordinate the resource allocation among users. We prove the existence, uniqueness and effectiveness of the auction results. In particular, the SNR auction leads to a fair resource allocation among users, and the power auction achieves a solution that is close to the efficient allocation.",Computer Science
"MANY TECHNIQUES for synthesizing digital hardware from C-like languages have been proposed, but none have emerged as successful as Verilog or VHDL for register-transfer-level design. This paper looks at two of the fundamental challenges: concurrency and timing control.",Computer Science
"We introduce the straggler identification problem, in which an algorithm must determine the identities of the remaining members of a set after it has had a large number of insertion and deletion operations performed on it, and now has relatively few remaining members. The goal is to do this in o(n) space, where n is the total number of identities. The straggler identification problem has applications, for example, in determining the set of unacknowledged packets in a high-bandwidth multicast data stream. We provide a deterministic solution to the straggler identification problem that uses only O(d log n) bits and is based on a novel application of Newton's identities for symmetric polynomials. This solution can identify any subset of d stragglers from a set of n O(log n)-bit identifiers, assuming that there are no false deletions of identities not already in the set. Indeed, we give a lower bound argument that shows that any small-space deterministic solution to the straggler identification problem cannot be guaranteed to handle false deletions. Nevertheless, we show that there is a simple randomized solution using O(d log n log(1/epsilon)) bits that can maintain a multiset and solve the straggler identification problem, tolerating false deletions, where epsilon>0 is a user-defined parameter bounding the probability of an incorrect response. This randomized solution is based on a new type of Bloom filter, which we call the invertible Bloom filter.",Computer Science
"The combination of source coding with decoder side-information (Wyner-Ziv problem) and channel coding with encoder side-information (Gel'fand-Pinsker problem) can be optimally solved using the separation principle. In this work we show an alternative scheme for the quadratic-Gaussian case, which merges source and channel coding. This scheme achieves the optimal performance by a applying modulo-lattice modulation to the analog source. Thus it saves the complexity of quantization and channel decoding, and remains with the task of ""shaping"" only. Furthermore, for high signal-to-noise ratio (SNR), the scheme approaches the optimal performance using an SNR-independent encoder, thus it is robust to unknown SNR at the encoder.",Computer Science
"Support vector machines represent a promising development in machine learning research that is not widely used within the remote sensing community. This paper reports the results of Multispectral(Landsat-7 ETM+) and Hyperspectral DAIS)data in which multi-class SVMs are compared with maximum likelihood and artificial neural network methods in terms of classification accuracy. Our results show that the SVM achieves a higher level of classification accuracy than either the maximum likelihood or the neural classifier, and that the support vector machine can be used with small training datasets and high-dimensional data.",Computer Science
"We develop a framework to optimize the tradeoff between diversity, multiplexing, and delay in MIMO systems to minimize end-to-end distortion. We first focus on the diversity-multiplexing tradeoff in MIMO systems, and develop analytical results to minimize distortion of a vector quantizer concatenated with a space-time MIMO channel code. In the high SNR regime we obtain a closed-form expression for the end-to-end distortion as a function of the optimal point on the diversity-multiplexing tradeoff curve. For large but finite SNR we find this optimal point via convex optimization. We then consider MIMO systems using ARQ retransmission to provide additional diversity at the expense of delay. For sources without a delay constraint, distortion is minimized by maximizing the ARQ window size. This results in an ARQ-enhanced multiplexing-diversity tradeoff region, with distortion minimized over this region in the same manner as without ARQ. Under a source delay constraint the problem formulation changes to account for delay distortion associated with random message arrival and random ARQ completion times. We use a dynamic programming formulation to capture the channel diversity-multiplexing tradeoff at finite SNR as well as the random arrival and retransmission dynamics; we solve for the optimal multiplexing-diversity-delay tradeoff to minimize end-to-end distortion associated with the source encoder, channel, and ARQ retransmissions. Our results show that a delay-sensitive system should adapt its operating point on the diversity-multiplexing-delay tradeoff region to the system dynamics. We provide numerical results that demonstrate significant performance gains of this adaptive policy over a static allocation of diversity/multiplexing in the channel code and a static ARQ window size.",Computer Science
"This paper provides simple lower bounds on the number of iterations which is required for successful message-passing decoding of some important families of graph-based code ensembles (including low-density parity-check codes and variations of repeat-accumulate codes). The transmission of the code ensembles is assumed to take place over a binary erasure channel, and the bounds refer to the asymptotic case where we let the block length tend to infinity. The simplicity of the bounds derived in this paper stems from the fact that they are easily evaluated and are expressed in terms of some basic parameters of the ensemble which include the fraction of degree-2 variable nodes, the target bit erasure probability and the gap between the channel capacity and the design rate of the ensemble. This paper demonstrates that the number of iterations which is required for successful message-passing decoding scales at least like the inverse of the gap (in rate) to capacity, provided that the fraction of degree-2 variable nodes of these turbo-like ensembles does not vanish (hence, the number of iterations becomes unbounded as the gap to capacity vanishes).",Computer Science
"Substitute valuations (in some contexts called gross substitute valuations) are prominent in combinatorial auction theory. An algorithm is given in this paper for generating a substitute valuation through Monte Carlo simulation. In addition, the geometry of the set of all substitute valuations for a fixed number of goods K is investigated. The set consists of a union of polyhedrons, and the maximal polyhedrons are identified for K=4. It is shown that the maximum dimension of the maximal polyhedrons increases with K nearly as fast as two to the power K. Consequently, under broad conditions, if a combinatorial algorithm can present an arbitrary substitute valuation given a list of input numbers, the list must grow nearly as fast as two to the power K.",Computer Science
"A generalized Davenport-Schinzel sequence is one over a finite alphabet that contains no subsequences isomorphic to a fixed forbidden subsequence. One of the fundamental problems in this area is bounding (asymptotically) the maximum length of such sequences. Following Klazar, let Ex(\sigma,n) be the maximum length of a sequence over an alphabet of size n avoiding subsequences isomorphic to \sigma. It has been proved that for every \sigma, Ex(\sigma,n) is either linear or very close to linear; in particular it is O(n 2^{\alpha(n)^{O(1)}}), where \alpha is the inverse-Ackermann function and O(1) depends on \sigma. However, very little is known about the properties of \sigma that induce superlinearity of \Ex(\sigma,n).   In this paper we exhibit an infinite family of independent superlinear forbidden subsequences. To be specific, we show that there are 17 prototypical superlinear forbidden subsequences, some of which can be made arbitrarily long through a simple padding operation. Perhaps the most novel part of our constructions is a new succinct code for representing superlinear forbidden subsequences.",Computer Science
"Topology Control (TC) aims at tuning the topology of highly dynamic networks to provide better control over network resources and to increase the efficiency of communication. Recently, many TC protocols have been proposed. The protocols are designed for preserving connectivity, minimizing energy consumption, maximizing the overall network coverage or network capacity. Each TC protocol makes different assumptions about the network topology, environment detection resources, and control capacities. This circumstance makes it extremely difficult to comprehend the role and purpose of each protocol. To tackle this situation, a taxonomy for TC protocols is presented throughout this paper. Additionally, some TC protocols are classified based upon this taxonomy.",Computer Science
"The recursion theorem in the weak form {e}(z)=x(e,z) (universal function not needed) and in Rogers form {n}(z)={{x}(n)}(z) and Rice theorem are proved a first time using programs in C, and a second time with scripts in Bash.",Computer Science
"This paper addresses the following question, which is of interest in the design of a multiuser decentralized network. Given a total system bandwidth of W Hz and a fixed data rate constraint of R bps for each transmission, how many frequency slots N of size W/N should the band be partitioned into in order to maximize the number of simultaneous links in the network? Dividing the available spectrum results in two competing effects. On the positive side, a larger N allows for more parallel, noninterfering communications to take place in the same area. On the negative side, a larger N increases the SINR requirement for each link because the same information rate must be achieved over less bandwidth. Exploring this tradeoff and determining the optimum value of N in terms of the system parameters is the focus of the paper. Using stochastic geometry, the optimal SINR threshold - which directly corresponds to the optimal spectral efficiency - is derived for both the low SNR (power-limited) and high SNR (interference-limited) regimes. This leads to the optimum choice of the number of frequency bands N in terms of the path loss exponent, power and noise spectral density, desired rate, and total bandwidth.",Computer Science
"The notation of mutually unbiased bases(MUB) was first introduced by Ivanovic to reconstruct density matrixes\cite{Ivanovic}. The subject about how to use MUB to analyze, process, and utilize the information of the second moments between random variables is studied in this paper. In the first part, the mathematical foundation will be built. It will be shown that the spectra of MUB have complete information for the correlation matrixes of finite discrete signals, and the nice properties of them. Roughly speaking, it will be shown that each spectrum from MUB plays an equal role for finite discrete signals, and the effect between any two spectra can be treated as a global constant shift. These properties will be used to find some important and natural characterizations of random vectors and random discrete operators/filters. For a technical reason, it will be shown that any MUB spectra can be found as fast as Fourier spectrum when the length of the signal is a prime number.   In the second part, some applications will be presented. First of all, a protocol about how to increase the number of users in a basic digital communication model will be studied, which has bring some deep insights about how to encode the information into the second moments between random variables. Secondly, the application of signal analysis will be studied. It is suggested that complete ""MUB"" spectra analysis works well in any case, and people can just choose the spectra they are interested in to do analysis. For instance, single Fourier spectra analysis can be also applied in nonstationary case. Finally, the application of MUB in dimensionality reduction will be considered, when the prior knowledge of the data isn't reliable.",Computer Science
"Mobile entities with wireless links are able to form a mobile ad-hoc network. Such an infrastructureless network does not have to be administrated. However, self-organizing principles have to be applied to deal with upcoming problems, e.g. information dissemination. These kinds of problems are not easy to tackle, requiring complex algorithms. Moreover, the usefulness of pure ad-hoc networks is arguably limited. Hence, enthusiasm for mobile ad-hoc networks, which could eliminate the need for any fixed infrastructure, has been damped. The goal is to overcome the limitations of pure ad-hoc networks by augmenting them with instant Internet access, e.g. via integration of UMTS respectively GSM links. However, this raises multiple questions at the technical as well as the organizational level. Motivated by characteristics of small-world networks that describe an efficient network even without central or organized design, this paper proposes to combine mobile ad-hoc networks and infrastructured networks to form hybrid wireless networks. One main objective is to investigate how this approach can reduce the costs of a permanent backbone link and providing in the same way the benefits of useful information from Internet connectivity or service providers. For the purpose of bridging between the different types of networks, an adequate middleware service is the focus of our investigation. This paper shows our first steps forward to this middleware by introducing the Injection Communication paradigm as principal concept.",Computer Science
"Combining the the results of A.R. Meyer and L.J. Stockmeyer ""The Equivalence Problem for Regular Expressions with Squaring Requires Exponential Space"", and K.S. Booth ""Isomorphism testing for graphs, semigroups, and finite automata are polynomiamlly equivalent problems"" shows that graph isomorphism is PSPACE-complete.",Computer Science
"A game-theoretic model is proposed to study the cross-layer problem of joint power and rate control with quality of service (QoS) constraints in multiple-access networks. In the proposed game, each user seeks to choose its transmit power and rate in a distributed manner in order to maximize its own utility while satisfying its QoS requirements. The user's QoS constraints are specified in terms of the average source rate and an upper bound on the average delay where the delay includes both transmission and queuing delays. The utility function considered here measures energy efficiency and is particularly suitable for wireless networks with energy constraints. The Nash equilibrium solution for the proposed non-cooperative game is derived and a closed-form expression for the utility achieved at equilibrium is obtained. It is shown that the QoS requirements of a user translate into a ""size"" for the user which is an indication of the amount of network resources consumed by the user. Using this competitive multiuser framework, the tradeoffs among throughput, delay, network capacity and energy efficiency are studied. In addition, analytical expressions are given for users' delay profiles and the delay performance of the users at Nash equilibrium is quantified.",Computer Science
"Let's be clear from the outset: SoC can most certainly make use of UML; SoC just doesn't need more UML, or even all of it. The advent of model mappings, coupled with marks that indicate which mapping rule to apply, enable a major simplification of the use of UML in SoC.",Computer Science
"We consider a real-time communication system with noisy feedback consisting of a Markov source, a forward and a backward discrete memoryless channels, and a receiver with finite memory. The objective is to design an optimal communication strategy (that is, encoding, decoding, and memory update strategies) to minimize the total expected distortion over a finite horizon. We present a sequential decomposition for the problem, which results in a set of nested optimality equations to determine optimal communication strategies. This provides a systematic methodology to determine globally optimal joint source-channel encoding and decoding strategies for real-time communication systems with noisy feedback.",Computer Science
"Motivated by distributed implementations of game-theoretical algorithms, we study symmetric process systems and the problem of attaining common knowledge between processes. We formalize our setting by defining a notion of peer-to-peer networks(*) and appropriate symmetry concepts in the context of Communicating Sequential Processes (CSP), due to the common knowledge creating effects of its synchronous communication primitives. We then prove that CSP with input and output guards makes common knowledge in symmetric peer-to-peer networks possible, but not the restricted version which disallows output statements in guards and is commonly implemented.   (*) Please note that we are not dealing with fashionable incarnations such as file-sharing networks, but merely use this name for a mathematical notion of a network consisting of directly connected peers ""treated on an equal footing"", i.e. not having a client-server structure or otherwise pre-determined roles.)",Computer Science
"Recently the AAGL (Anshel-Anshel-Goldfeld-Lemieux) has been proposed which can be used for RFID tags. We give algorithms for the problem (we call the MSCSPv) on which the security of the AAGL protocol is based upon. Hence we give various attacks for general parameters on the recent AAGL protocol proposed. One of our attacks is a deterministic algorithm which has space complexity and time complexity both atleast exponentialin the worst case. In a better case using a probabilistic algorithm the time complexity canbe O(|XSS(ui')^L5*(n^(1+e)) and the space complexity can be O(|XSS(ui')|^L6), where the element ui' is part of a public key, n is the index of braid group, XSS is a summit type set and e is a constant in a limit. The above shows the AAGL protocol is potentially not significantly more secure as using key agreement protocols based on the conjugacy problem such as the AAG (Anshel-Anshel-Goldfeld) protocol because both protocols can be broken with complexity which do not significantly differ. We think our attacks can be improved.",Computer Science
"In RF-MEMS packaging, next to the protection of movable structures, optimization of package electrical performance plays a very important role. In this work, a wafer-level packaging process has been investigated and optimized in order to minimize electrical parasitic effects. The RF-MEMS package concept used is based on a wafer-level bonding of a capping silicon substrate to an RF-MEMS wafer. The capping silicon substrate resistivity, substrate thickness and the geometry of through-substrate electrical interconnect vias have been optimized using finite-element electromagnetic simulations (Ansoft HFSS). Test structures for electrical characterization have been designed and after their fabrication, measurement results will be compared with simulations.",Computer Science
"We show that the Brier game of prediction is mixable and find the optimal learning rate and substitution function for it. The resulting prediction algorithm is applied to predict results of football and tennis matches. The theoretical performance guarantee turns out to be rather tight on these data sets, especially in the case of the more extensive tennis data.",Computer Science
"Bayesian neural networks were used to model the relationship between input parameters, Democracy, Allies, Contingency, Distance, Capability, Dependency and Major Power, and the output parameter which is either peace or conflict. The automatic relevance determination was used to rank the importance of input variables. Control theory approach was used to identify input variables that would give a peaceful outcome. It was found that using all four controllable variables Democracy, Allies, Capability and Dependency; or using only Dependency or only Capabilities avoids all the predicted conflicts.",Computer Science
The paper presents probabilistic extensions of interval temporal logic (ITL) and duration calculus (DC) with infinite intervals and complete Hilbert-style proof systems for them. The completeness results are a strong completeness theorem for the system of probabilistic ITL with respect to an abstract semantics and a relative completeness theorem for the system of probabilistic DC with respect to real-time semantics. The proposed systems subsume probabilistic real-time DC as known from the literature. A correspondence between the proposed systems and a system of probabilistic interval temporal logic with finite intervals and expanding modalities is established too.,Computer Science
"We present a joint source-channel multiple description (JSC-MD) framework for resource-constrained network communications (e.g., sensor networks), in which one or many deprived encoders communicate a Markov source against bit errors and erasure errors to many heterogeneous decoders, some powerful and some deprived. To keep the encoder complexity at minimum, the source is coded into K descriptions by a simple multiple description quantizer (MDQ) with neither entropy nor channel coding. The code diversity of MDQ and the path diversity of the network are exploited by decoders to correct transmission errors and improve coding efficiency. A key design objective is resource scalability: powerful nodes in the network can perform JSC-MD distributed estimation/decoding under the criteria of maximum a posteriori probability (MAP) or minimum mean-square error (MMSE), while primitive nodes resort to simpler MD decoding, all working with the same MDQ code. The application of JSC-MD to distributed estimation of hidden Markov models in a sensor network is demonstrated. The proposed JSC-MD MAP estimator is an algorithm of the longest path in a weighted directed acyclic graph, while the JSC-MD MMSE decoder is an extension of the well-known forward-backward algorithm to multiple descriptions. Both algorithms simultaneously exploit the source memory, the redundancy of the fixed-rate MDQ, and the inter-description correlations. They outperform the existing hard-decision MDQ decoders by large margins (up to 8dB). For Gaussian Markov sources, the complexity of JSC-MD distributed MAP sequence estimation can be made as low as that of typical single description Viterbi-type algorithms.",Computer Science
"This paper examines the joint problem of detection and identification of a sudden and unobservable change in the probability distribution function (pdf) of a sequence of independent and identically distributed (i.i.d.) random variables to one of finitely many alternative pdf's. The objective is quick detection of the change and accurate inference of the ensuing pdf. Following a Bayesian approach, a new sequential decision strategy for this problem is revealed and is proven optimal. Geometrical properties of this strategy are demonstrated via numerical examples.",Computer Science
"In this paper, the application of a cycle accurate binary translator for rapid prototyping of SoCs will be presented. This translator generates code to run on a rapid prototyping system consisting of a VLIW processor and FPGAs. The generated code is annotated with information that triggers cycle generation for the hardware in parallel to the execution of the translated program. The VLIW processor executes the translated program whereas the FPGAs contain the hardware for the parallel cycle generation and the bus interface that adapts the bus of the VLIW processor to the SoC bus of the emulated processor core.",Computer Science
"One of the most famous and investigated lossless data-compression scheme is the one introduced by Lempel and Ziv about 40 years ago. This compression scheme is known as ""dictionary-based compression"" and consists of squeezing an input string by replacing some of its substrings with (shorter) codewords which are actually pointers to a dictionary of phrases built as the string is processed. Surprisingly enough, although many fundamental results are nowadays known about upper bounds on the speed and effectiveness of this compression process and references therein), ``we are not aware of any parsing scheme that achieves optimality when the LZ77-dictionary is in use under any constraint on the codewords other than being of equal length'' [N. Rajpoot and C. Sahinalp. Handbook of Lossless Data Compression, chapter Dictionary-based data compression. Academic Press, 2002. pag. 159]. Here optimality means to achieve the minimum number of bits in compressing each individual input string, without any assumption on its generating source. In this paper we provide the first LZ-based compressor which computes the bit-optimal parsing of any input string in efficient time and optimal space, for a general class of variable-length codeword encodings which encompasses most of the ones typically used in data compression and in the design of search engines and compressed indexes.",Computer Science
"Data compression has been widely applied in many data processing areas. Compression methods use variable-size codes with the shorter codes assigned to symbols or groups of symbols that appear in the data frequently. Fibonacci coding, as a representative of these codes, is used for compressing small numbers. Time consumption of a decompression algorithm is not usually as important as the time of a compression algorithm. However, efficiency of the decompression may be a critical issue in some cases. For example, a real-time compression of tree data structures follows this issue. Tree's pages are decompressed during every reading from a secondary storage into the main memory. In this case, the efficiency of a decompression algorithm is extremely important. We have developed a Fast Fibonacci decompression for this purpose. Our approach is up to $3.5\times$ faster than the original implementation.",Computer Science
"Wider adoption of the Grid concept has led to an increasing amount of federated computational, storage and visualisation resources being available to scientists and researchers. Distributed and heterogeneous nature of these resources renders most of the legacy cluster monitoring and management approaches inappropriate, and poses new challenges in workflow scheduling on such systems. Effective resource utilisation monitoring and highly granular yet adaptive measurements are prerequisites for a more efficient Grid scheduler. We present a suite of measurement applications able to monitor per-process resource utilisation, and a customisable tool for emulating observed utilisation models. We also outline our future work on a predictive and probabilistic Grid scheduler. The research is undertaken as part of UK e-Science EPSRC sponsored project SO-GRM (Self-Organising Grid Resource Management) in cooperation with BT.",Computer Science
"Where Prolog is commonly seen as a component in a Web application that is either embedded or communicates using a proprietary protocol, we propose an architecture where Prolog communicates to other components in a Web application using the standard HTTP protocol. By avoiding embedding in external Web servers development and deployment become much easier. To support this architecture, in addition to the transfer protocol, we must also support parsing, representing and generating the key Web document types such as HTML, XML and RDF.   This paper motivates the design decisions in the libraries and extensions to Prolog for handling Web documents and protocols. The design has been guided by the requirement to handle large documents efficiently. The described libraries support a wide range of Web applications ranging from HTML and XML documents to Semantic Web RDF processing.   To appear in Theory and Practice of Logic Programming (TPLP)",Computer Science
"For a given connected graph G on n vertices and m edges, we prove that its independence number is at least (2m+n+2-sqrt(sqr(2m+n+2)-16sqr(n)))/8.",Computer Science
"We propose skewed stable random projections for approximating the pth frequency moments of dynamic data streams (0<p<=2), which has been frequently studied in theoretical computer science and database communities. Our method significantly (or even infinitely when p->1) improves previous methods based on (symmetric) stable random projections.   Our proposed method is applicable to data streams that are (a) insertion only (the cash-register model); or (b) always non-negative (the strict Turnstile model), or (c) eventually non-negative at check points. This is only a minor restriction for practical applications.   Our method works particularly well when p = 1+/- \Delta and \Delta is small, which is a practically important scenario. For example, \Delta may be the decay rate or interest rate, which are usually small. Of course, when \Delta = 0, one can compute the 1th frequent moment (i.e., the sum) essentially error-free using a simple couter. Our method may be viewed as a ``genearlized counter'' in that it can count the total value in the future, taking in account of the effect of decaying or interest accruement.   In a summary, our contributions are two-fold. (A) This is the first propsal of skewed stable random projections. (B) Based on first principle, we develop various statistical estimators for skewed stable distributions, including their variances and error (tail) probability bounds, and consequently the sample complexity bounds.",Computer Science
"We describe an algorithm to count the number of distinct real zeros of a polynomial (square) system f. The algorithm performs O(n D kappa(f)) iterations where n is the number of polynomials (as well as the dimension of the ambient space), D is a bound on the polynomials' degree, and kappa(f) is a condition number for the system. Each iteration uses an exponential number of operations. The algorithm uses finite-precision arithmetic and a polynomial bound for the precision required to ensure the returned output is correct is exhibited. This bound is a major feature of our algorithm since it is in contrast with the exponential precision required by the existing (symbolic) algorithms for counting real zeros. The algorithm parallelizes well in the sense that each iteration can be computed in parallel polynomial time with an exponential number of processors.",Computer Science
"BACKGROUND: Prostate brachytherapy consists in placing radioactive seeds for tumour destruction under transrectal ultrasound imaging (TRUS) control. It requires prostate delineation from the images for dose planning. Because ultrasound imaging is patient- and operator-dependent, we have proposed to fuse MRI data to TRUS data to make image processing more reliable. The technical accuracy of this approach has already been evaluated. METHODS: We present work in progress concerning the evaluation of the approach from the dosimetry viewpoint. The objective is to determine what impact this system may have on the treatment of the patient. Dose planning is performed from initial TRUS prostate contours and evaluated on contours modified by data fusion. RESULTS: For the eight patients included, we demonstrate that TRUS prostate volume is most often underestimated and that dose is overestimated in a correlated way. However, dose constraints are still verified for those eight patients. CONCLUSIONS: This confirms our initial hypothesis.",Computer Science
"Current skyline evaluation techniques assume a fixed ordering on the attributes. However, dynamic preferences on nominal attributes are more realistic in known applications. In order to generate online response for any such preference issued by a user, we propose two methods of different characteristics. The first one is a semi-materialization method and the second is an adaptive SFS method. Finally, we conduct experiments to show the efficiency of our proposed algorithms.",Computer Science
"We consider approximating data structures with collections of the items that they contain. For examples, lists, binary trees, tuples, etc, can be approximated by sets or multisets of the items within them. Such approximations can be used to provide partial correctness properties of logic programs. For example, one might wish to specify than whenever the atom $sort(t,s)$ is proved then the two lists $t$ and $s$ contain the same multiset of items (that is, $s$ is a permutation of $t$). If sorting removes duplicates, then one would like to infer that the sets of items underlying $t$ and $s$ are the same. Such results could be useful to have if they can be determined statically and automatically. We present a scheme by which such collection analysis can be structured and automated. Central to this scheme is the use of linear logic as a omputational logic underlying the logic of Horn clauses.",Computer Science
"A new approach for upper bounding the channel reliability function using the code spectrum is described. It allows to treat both low and high rate cases in a unified way. In particular, the earlier known upper bounds are improved, and a new derivation of the sphere-packing bound is presented.",Computer Science
"As device sizes shrink and current densities increase, the probability of device failures due to gate oxide breakdown (OBD) also increases. To provide designs that are tolerant to such failures, we must investigate and understand the manifestations of this physical phenomenon at the circuit and system level. In this paper, we develop a model for operational OBD defects, and we explore how to test for faults due to OBD. For a NAND gate, we derive the necessary input conditions that excite and detect errors due to OBD defects at the gate level. We show that traditional pattern generators fail to exercise all of these defects. Finally, we show that these test patterns can be propagated and justified for a combinational circuit in a manner similar to traditional ATPG.",Computer Science
"We present a genetic algorithm which is distributed in two novel ways: along genotype and temporal axes. Our algorithm first distributes, for every member of the population, a subset of the genotype to each network node, rather than a subset of the population to each. This genotype distribution is shown to offer a significant gain in running time. Then, for efficient use of the computational resources in the network, our algorithm divides the candidate solutions into pipelined sets and thus the distribution is in the temporal domain, rather that in the spatial domain. This temporal distribution may lead to temporal inconsistency in selection and replacement, however our experiments yield better efficiency in terms of the time to convergence without incurring significant penalties.",Computer Science
"Application of Microelectronic to bioanalysis is an emerging field which holds great promise. From the standpoint of electronic and system design, biochips imply a radical change of perspective, since new, completely different constraints emerge while other usual constraints can be relaxed. While electronic parts of the system can rely on the usual established design-flow, fluidic and packaging design, calls for a new approach which relies significantly on experiments. We hereby make some general considerations based on our experience in the development of biochips for cell analysis.",Computer Science
"In this paper, the bit error performance of a family of likelihood ascent search (LAS) multiuser detectors is analyzed. An upper bound on the BER of any LAS detector is obtained by bounding the fixed point region with the worst initial detector. The concept of indecomposable errors developed by Verdu is applied to tighten the upper bound. In a special instance, the upper bound is reduced to that for all the local maximum likelihood detectors. The upper bound is comparable with that of the optimum detector obtained by Verdu. A lower bound on the asymptotic multiuser efficiency (AME) is then obtained. It is shown that there are nontrivial CDMA channels such that a LAS detector can achieve unit AME regardless of user number. The AME lower bound provides a means for further seeking a good set of spreading sequences and power distribution for spectral and power efficient CDMA.",Computer Science
This work considers the problem of transmitting multiple compressible sources over a network at minimum cost. The aim is to find the optimal rates at which the sources should be compressed and the network flows using which they should be transmitted so that the cost of the transmission is minimal. We consider networks with capacity constraints and linear cost functions. The problem is complicated by the fact that the description of the feasible rate region of distributed source coding problems typically has a number of constraints that is exponential in the number of sources. This renders general purpose solvers inefficient. We present a framework in which these problems can be solved efficiently by exploiting the structure of the feasible rate regions coupled with dual decomposition and optimization techniques such as the subgradient method and the proximal bundle method.,Computer Science
"The traffic behavior of University of Louisville network with the interconnected backbone routers and the number of Virtual Local Area Network (VLAN) subnets is investigated using the Random Matrix Theory (RMT) approach. We employ the system of equal interval time series of traffic counts at all router to router and router to subnet connections as a representation of the inter-VLAN traffic. The cross-correlation matrix C of the traffic rate changes between different traffic time series is calculated and tested against null-hypothesis of random interactions.   The majority of the eigenvalues \lambda_{i} of matrix C fall within the bounds predicted by the RMT for the eigenvalues of random correlation matrices. The distribution of eigenvalues and eigenvectors outside of the RMT bounds displays prominent and systematic deviations from the RMT predictions. Moreover, these deviations are stable in time.   The method we use provides a unique possibility to accomplish three concurrent tasks of traffic analysis. The method verifies the uncongested state of the network, by establishing the profile of random interactions. It recognizes the system-specific large-scale interactions, by establishing the profile of stable in time non-random interactions. Finally, by looking into the eigenstatistics we are able to detect and allocate anomalies of network traffic interactions.",Computer Science
"The notion of innocent strategy was introduced by Hyland and Ong in order to capture the interactive behaviour of lambda-terms and PCF programs. An innocent strategy is defined as an alternating strategy with partial memory, in which the strategy plays according to its view. Extending the definition to non-alternating strategies is problematic, because the traditional definition of views is based on the hypothesis that Opponent and Proponent alternate during the interaction. Here, we take advantage of the diagrammatic reformulation of alternating innocence in asynchronous games, in order to provide a tentative definition of innocence in non-alternating games. The task is interesting, and far from easy. It requires the combination of true concurrency and game semantics in a clean and organic way, clarifying the relationship between asynchronous games and concurrent games in the sense of Abramsky and Melli\`es. It also requires an interactive reformulation of the usual acyclicity criterion of linear logic, as well as a directed variant, as a scheduling criterion.",Computer Science
"In earlier work, the Abstract State Machine Thesis -- that arbitrary algorithms are behaviorally equivalent to abstract state machines -- was established for several classes of algorithms, including ordinary, interactive, small-step algorithms. This was accomplished on the basis of axiomatizations of these classes of algorithms. Here we extend the axiomatization and, in a companion paper, the proof, to cover interactive small-step algorithms that are not necessarily ordinary. This means that the algorithms (1) can complete a step without necessarily waiting for replies to all queries from that step and (2) can use not only the environment's replies but also the order in which the replies were received.",Computer Science
"We give several new algorithms for dense polynomial multiplication based on the Kronecker substitution method. For moderately sized input polynomials, the new algorithms improve on the performance of the standard Kronecker substitution by a sizeable constant, both in theory and in empirical tests.",Computer Science
"We present in this paper a generic object-oriented benchmark (the Object Clustering Benchmark) that has been designed to evaluate the performances of clustering policies in object-oriented databases. OCB is generic because its sample database may be customized to fit the databases introduced by the main existing benchmarks (e.g., OO1). OCB's current form is clustering-oriented because of its clustering-oriented workload, but it can be easily adapted to other purposes. Lastly, OCB's code is compact and easily portable. OCB has been implemented in a real system (Texas, running on a Sun workstation), in order to test a specific clustering policy called DSTC. A few results concerning this test are presented.",Computer Science
"This paper introduces a novel concept from coalitional game theory which allows the dynamic formation of coalitions among wireless nodes. A simple and distributed merge and split algorithm for coalition formation is constructed. This algorithm is applied to study the gains resulting from the cooperation among single antenna transmitters for virtual MIMO formation. The aim is to find an ultimate transmitters coalition structure that allows cooperating users to maximize their utilities while accounting for the cost of coalition formation. Through this novel game theoretical framework, the wireless network transmitters are able to self-organize and form a structured network composed of disjoint stable coalitions. Simulation results show that the proposed algorithm can improve the average individual user utility by 26.4% as well as cope with the mobility of the distributed users.",Computer Science
"The power dominating set (PDS) problem is the following extension of the well-known dominating set problem: find a smallest-size set of nodes $S$ that power dominates all the nodes, where a node $v$ is power dominated if (1) $v$ is in $S$ or $v$ has a neighbor in $S$, or (2) $v$ has a neighbor $w$ such that $w$ and all of its neighbors except $v$ are power dominated. We show a hardness of approximation threshold of $2^{\log^{1-\epsilon}{n}}$ in contrast to the logarithmic hardness for the dominating set problem. We give an $O(\sqrt{n})$ approximation algorithm for planar graphs, and show that our methods cannot improve on this approximation guarantee. Finally, we initiate the study of PDS on directed graphs, and show the same hardness threshold of $2^{\log^{1-\epsilon}{n}}$ for directed \emph{acyclic} graphs. Also we show that the directed PDS problem can be solved optimally in linear time if the underlying undirected graph has bounded tree-width.",Computer Science
"The aim of this paper is to determine the expectations that French-speaking disabled persons have for electronic administrative sites (utility). At the same time, it is a matter of identifying the difficulties of use that the manipulation of these E-services poses concretely for blind people (usability) and of evaluating the psychosocial impacts on the way of life of these people with specific needs. We show that the lack of numerical accessibility is likely to accentuate the social exclusion of which these people are victim by establishing a numerical glass ceiling.",Computer Science
"Second-order coding rate of channel coding is discussed for general sequence of channels. The optimum second-order transmission rate with a constant error constraint $\epsilon$ is obtained by using the information spectrum method. We apply this result to the discrete memoryless case, the discrete memoryless case with a cost constraint, the additive Markovian case, and the Gaussian channel case with an energy constraint. We also clarify that the Gallager bound does not give the optimum evaluation in the second-order coding rate.",Computer Science
"The McEliece cryptosystem is a public-key cryptosystem based on coding theory that has successfully resisted cryptanalysis for thirty years. The original version, based on Goppa codes, is able to guarantee a high level of security, and is faster than competing solutions, like RSA. Despite this, it has been rarely considered in practical applications, due to two major drawbacks: i) large size of the public key and ii) low transmission rate. Low-Density Parity-Check (LDPC) codes are state-of-art forward error correcting codes that permit to approach the Shannon limit while ensuring limited complexity. Quasi-Cyclic (QC) LDPC codes are a particular class of LDPC codes, able to join low complexity encoding of QC codes with high-performing and low-complexity decoding of LDPC codes. In a previous work it has been proposed to adopt a particular family of QC-LDPC codes in the McEliece cryptosystem to reduce the key size and increase the transmission rate. Recently, however, new attacks have been found that are able to exploit a flaw in the transformation from the private key to the public one. Such attacks can be effectively countered by changing the form of some constituent matrices, without altering the system parameters. This work gives an overview of the QC-LDPC codes-based McEliece cryptosystem and its cryptanalysis. Two recent versions are considered, and their ability to counter all the currently known attacks is discussed. A third version able to reach a higher security level is also proposed. Finally, it is shown that the new QC-LDPC codes-based cryptosystem scales favorably with the key length.",Computer Science
"Four different ways of obtaining low-density parity-check codes from expander graphs are considered. For each case, lower bounds on the minimum stopping set size and the minimum pseudocodeword weight of expander (LDPC) codes are derived. These bounds are compared with the known eigenvalue-based lower bounds on the minimum distance of expander codes. Furthermore, Tanner's parity-oriented eigenvalue lower bound on the minimum distance is generalized to yield a new lower bound on the minimum pseudocodeword weight. These bounds are useful in predicting the performance of LDPC codes under graph-based iterative decoding and linear programming decoding.",Computer Science
"This paper is concerned with the form of typed name binding used by the FreshML family of languages. Its characteristic feature is that a name binding is represented by an abstract (name,value)-pair that may only be deconstructed via the generation of fresh bound names. The paper proves a new result about what operations on names can co-exist with this construct. In FreshML the only observation one can make of names is to test whether or not they are equal. This restricted amount of observation was thought necessary to ensure that there is no observable difference between alpha-equivalent name binders. Yet from an algorithmic point of view it would be desirable to allow other operations and relations on names, such as a total ordering. This paper shows that, contrary to expectations, one may add not just ordering, but almost any relation or numerical function on names without disturbing the fundamental correctness result about this form of typed name binding (that object-level alpha-equivalence precisely corresponds to contextual equivalence at the programming meta-level), so long as one takes the state of dynamically created names into account.",Computer Science
"This paper I assume that in humans the creation of knowledge depends on a discrete time, or stage, sequential decision-making process subjected to a stochastic, information transmitting environment. For each time-stage, this environment randomly transmits Shannon type information-packets to the decision-maker, who examines each of them for relevancy and then determines his optimal choices. Using this set of relevant information-packets, the decision-maker adapts, over time, to the stochastic nature of his environment, and optimizes the subjective expected rate-of-growth of knowledge. The decision-maker's optimal actions, lead to a decision function that involves, over time, his view of the subjective entropy of the environmental process and other important parameters at each time-stage of the process. Using this model of human behavior, one could create psychometric experiments using computer simulation and real decision-makers, to play programmed games to measure the resulting human performance.",Computer Science
"I postulate that human or other intelligent agents function or should function as follows. They store all sensory observations as they come - the data is holy. At any time, given some agent's current coding capabilities, part of the data is compressible by a short and hopefully fast program / description / explanation / world model. In the agent's subjective eyes, such data is more regular and more ""beautiful"" than other data. It is well-known that knowledge of regularity and repeatability may improve the agent's ability to plan actions leading to external rewards. In absence of such rewards, however, known beauty is boring. Then ""interestingness"" becomes the first derivative of subjective beauty: as the learning agent improves its compression algorithm, formerly apparently random data parts become subjectively more regular and beautiful. Such progress in compressibility is measured and maximized by the curiosity drive: create action sequences that extend the observation history and yield previously unknown / unpredictable but quickly learnable algorithmic regularity. We discuss how all of the above can be naturally implemented on computers, through an extension of passive unsupervised learning to the case of active data selection: we reward a general reinforcement learner (with access to the adaptive compressor) for actions that improve the subjective compressibility of the growing data. An unusually large breakthrough in compressibility deserves the name ""discovery"". The ""creativity"" of artists, dancers, musicians, pure mathematicians can be viewed as a by-product of this principle. Several qualitative examples support this hypothesis.",Computer Science
"Single Event Upsets (SEU) as well as permanent faults can significantly affect the correct on-line operation of digital systems, such as memories and microprocessors; a memory can be made resilient to permanent and transient faults by using modular redundancy and coding. In this paper, different memory systems are compared: these systems utilize simplex and duplex arrangements with a combination of Reed Solomon coding and scrubbing. The memory systems and their operations are analyzed by novel Markov chains to characterize performance for dynamic reconfiguration as well as error detection and correction under the occurrence of permanent and transient faults. For a specific Reed Solomon code, the duplex arrangement allows to efficiently cope with the occurrence of permanent faults, while the use of scrubbing allows to cope with transient faults.",Computer Science
"As the Grid evolves from a high performance cluster middleware to a multipurpose utility computing framework, a good understanding of Grid applications, their statistics and utilisation patterns is required. This study looks at job execution times and resource utilisations in a Grid environment, and their significance in cluster and network dimensioning, local level scheduling and resource management.",Computer Science
"We introduce a distributed algorithm for clock synchronization in sensor networks. Our algorithm assumes that nodes in the network only know their immediate neighborhoods and an upper bound on the network's diameter. Clock-synchronization messages are only sent as part of the communication, assumed reasonably frequent, that already takes place among nodes. The algorithm has the gradient property of [2], achieving an O(1) worst-case skew between the logical clocks of neighbors. As in the case of [3,8], the algorithm's actions are such that no constant lower bound exists on the rate at which logical clocks progress in time, and for this reason the lower bound of [2,5] that forbids constant skew between neighbors does not apply.",Computer Science
"Each node in a wireless multi-hop network can adjust the power level at which it transmits and thus change the topology of the network to save energy by choosing the neighbors with which it directly communicates. Many previous algorithms for distributed topology control have assumed an ability at each node to deduce some location-based information such as the direction and the distance of its neighbor nodes with respect to itself. Such a deduction of location-based information, however, cannot be relied upon in real environments where the path loss exponents vary greatly leading to significant errors in distance estimates. Also, multipath effects may result in different signal paths with different loss characteristics, and none of these paths may be line-of-sight, making it difficult to estimate the direction of a neighboring node. In this paper, we present Step Topology Control (STC), a simple distributed topology control algorithm which reduces energy consumption while preserving the connectivity of a heterogeneous sensor network without use of any location-based information. We show that the STC algorithm achieves the same or better order of communication and computational complexity when compared to other known algorithms that also preserve connectivity without the use of location-based information. We also present a detailed simulation-based comparative analysis of the energy savings and interference reduction achieved by the algorithms. The results show that, in spite of not incurring a higher communication or computational complexity, the STC algorithm performs better than other algorithms in uniform wireless environments and especially better when path loss characteristics are non-uniform.",Computer Science
"Current algorithms for bounded model checking use SAT methods for checking satisfiability of Boolean formulae. These methods suffer from the potential memory explosion problem. Methods based on the validity of Quantified Boolean Formulae (QBF) allow an exponentially more succinct representation of formulae to be checked, because no ""unrolling"" of the transition relation is required. These methods have not been widely used, because of the lack of an efficient decision procedure for QBF. We evaluate the usage of QBF in bounded model checking (BMC), using general-purpose SAT and QBF solvers. We develop a special-purpose decision procedure for QBF used in BMC, and compare our technique with the methods using general-purpose SAT and QBF solvers on real-life industrial benchmarks.",Computer Science
"We are concerned with the problem of maximizing the worst-case lifetime of a data-gathering wireless sensor network consisting of a set of sensor nodes directly communicating with a base-station.We propose to solve this problem by modeling sensor node and base-station communication as the interactive communication between multiple correlated informants (sensor nodes) and a recipient (base-station). We provide practical and scalable interactive communication protocols for data gathering in sensor networks and demonstrate their efficiency compared to traditional approaches.   In this paper, we first develop a formalism to address the problem of worst-case interactive communication between a set of multiple correlated informants and a recipient. We realize that there can be different objectives to achieve in such a communication scenario and compute the optimal number of messages and bits exchanged to realize these objectives. Then, we propose to adapt these results in the context of single-hop data-gathering sensor networks. Finally, based on this proposed formalism, we propose a clustering based communication protocol for large sensor networks and demonstrate its superiority over a traditional clustering protocol.",Computer Science
"In many channel measurement applications, one needs to estimate some characteristics of the channels based on a limited set of measurements. This is mainly due to the highly time varying characteristics of the channel. In this contribution, it will be shown how free probability can be used for channel capacity estimation in MIMO systems. Free probability has already been applied in various application fields such as digital communications, nuclear physics and mathematical finance, and has been shown to be an invaluable tool for describing the asymptotic behaviour of many large-dimensional systems. In particular, using the concept of free deconvolution, we provide an asymptotically (w.r.t. the number of observations) unbiased capacity estimator for MIMO channels impaired with noise called the free probability based estimator. Another estimator, called the Gaussian matrix mean based estimator, is also introduced by slightly modifying the free probability based estimator. This estimator is shown to give unbiased estimation of the moments of the channel matrix for any number of observations. Also, the estimator has this property when we extend to MIMO channels with phase off-set and frequency drift, for which no estimator has been provided so far in the literature. It is also shown that both the free probability based and the Gaussian matrix mean based estimator are asymptotically unbiased capacity estimators as the number of transmit antennas go to infinity, regardless of whether phase off-set and frequency drift are present. The limitations in the two estimators are also explained. Simulations are run to assess the performance of the estimators for a low number of antennas and samples to confirm the usefulness of the asymptotic results.",Computer Science
"This paper defines a theory of conformal parametrization of digital surfaces made of surfels equipped with a normal vector. The main idea is to locally project each surfel to the tangent plane, therefore deforming its aspect-ratio. It is a generalization of the theory known for polyhedral surfaces. The main difference is that the conformal ratios that appear are no longer real in general. It yields a generalization of the standard Laplacian on weighted graphs.",Computer Science
"There is a growing body of work on sorting and selection in models other than the unit-cost comparison model. This work is the first treatment of a natural stochastic variant of the problem where the cost of comparing two elements is a random variable. Each cost is chosen independently and is known to the algorithm. In particular we consider the following three models: each cost is chosen uniformly in the range $[0,1]$, each cost is 0 with some probability $p$ and 1 otherwise, or each cost is 1 with probability $p$ and infinite otherwise. We present lower and upper bounds (optimal in most cases) for these problems. We obtain our upper bounds by carefully designing algorithms to ensure that the costs incurred at various stages are independent and using properties of random partial orders when appropriate.",Computer Science
"In this paper, a multiple-relay network in considered, in which $K$ single-antenna relays assist a single-antenna transmitter to communicate with a single-antenna receiver in a half-duplex mode. A new Amplify and Forward (AF) scheme is proposed for this network and is shown to achieve the optimum diversity-multiplexing trade-off curve.",Computer Science
We show that the space of polygonizations of a fixed planar point set S of n points is connected by O(n^2) ``moves'' between simple polygons. Each move is composed of a sequence of atomic moves called ``stretches'' and ``twangs''. These atomic moves walk between weakly simple ``polygonal wraps'' of S. These moves show promise to serve as a basis for generating random polygons.,Computer Science
"Nepomnjascii's Theorem states that for all 0 <= \epsilon < 1 and k > 0 the class of languages recognized in nondeterministic time n^k and space n^\epsilon, NTISP[n^k, n^\epsilon ], is contained in the linear time hierarchy. By considering restrictions on the size of the universal quantifiers in the linear time hierarchy, this paper refines Nepomnjascii's result to give a sub- hierarchy, Eu-LinH, of the linear time hierarchy that is contained in NP and which contains NTISP[n^k, n^\epsilon ]. Hence, Eu-LinH contains NL and SC. This paper investigates basic structural properties of Eu-LinH. Then the relationships between Eu-LinH and the classes NL, SC, and NP are considered to see if they can shed light on the NL = NP or SC = NP questions. Finally, a new hierarchy, zeta -LinH, is defined to reduce the space requirements needed for the upper bound on Eu-LinH.",Computer Science
"We approximate the price of the American put for jump diffusions by a sequence of functions, which are computed iteratively. This sequence converges to the price function uniformly and exponentially fast. Each element of the approximating sequence solves an optimal stopping problem for geometric Brownian motion, and can be numerically computed using the classical finite difference methods. We prove the convergence of this numerical scheme and present examples to illustrate its performance.",Computer Science
"This paper studies the performance of transmission schemes that have rate that increases with average SNR while maintaining a fixed outage probability. This is in contrast to the classical Zheng-Tse diversity-multiplexing tradeoff (DMT) that focuses on increasing rate and decreasing outage probability. Three different systems are explored: antenna diversity systems, time/frequency diversity systems, and automatic repeat request (ARQ) systems. In order to accurately study performance in the fixed outage setting, it is necesary to go beyond the coarse, asymptotic multiplexing gain metric. In the case of antenna diversity and time/frequency diversity, an affine approximation to high SNR outage capacity (i.e., multiplexing gain plus a power/rate offset) accurately describes performance and shows the very significant benefits of diversity. ARQ is also seen to provide a significant performance advantage, but even an affine approximation to outage capacity is unable to capture this advantage and outage capacity must be directly studied in the non-asymptotic regime.",Computer Science
"Maximum Satisfiability (MaxSAT) is a well-known optimization pro- blem, with several practical applications. The most widely known MAXS AT algorithms are ineffective at solving hard problems instances from practical application domains. Recent work proposed using efficient Boolean Satisfiability (SAT) solvers for solving the MaxSAT problem, based on identifying and eliminating unsatisfiable subformulas. However, these algorithms do not scale in practice. This paper analyzes existing MaxSAT algorithms based on unsatisfiable subformula identification. Moreover, the paper proposes a number of key optimizations to these MaxSAT algorithms and a new alternative algorithm. The proposed optimizations and the new algorithm provide significant performance improvements on MaxSAT instances from practical applications. Moreover, the efficiency of the new generation of unsatisfiability-based MaxSAT solvers becomes effectively indexed to the ability of modern SAT solvers to proving unsatisfiability and identifying unsatisfiable subformulas.",Computer Science
"In the classical s-t network reliability problem a fixed network G is given including two designated vertices s and t (called terminals). The edges are subject to independent random failure, and the task is to compute the probability that s and t are connected in the resulting network, which is known to be #P-complete. In this paper we are interested in approximating the s-t reliability in case of a directed acyclic original network G. We introduce and analyze a specialized version of the Monte-Carlo algorithm given by Karp and Luby. For the case of uniform edge failure probabilities, we give a worst-case bound on the number of samples that have to be drawn to obtain an epsilon-delta approximation, being sharper than the original upper bound. We also derive a variance reduction of the estimator which reduces the expected number of iterations to perform to achieve the desired accuracy when applied in conjunction with different stopping rules. Initial computational results on two types of random networks (directed acyclic Delaunay graphs and a slightly modified version of a classical random graph) with up to one million vertices are presented. These results show the advantage of the introduced Monte-Carlo approach compared to direct simulation when small reliabilities have to be estimated and demonstrate its applicability on large-scale instances.",Computer Science
"The MultiNoC system implements a programmable on-chip multiprocessing platform built on top of an efficient, low area overhead intra-chip interconnection scheme. The employed interconnection structure is a Network on Chip, or NoC. NoCs are emerging as a viable alternative to increasing demands on interconnection architectures, due to the following characteristics: (i) energy efficiency and reliability; (ii) scalability of bandwidth, when compared to traditional bus architectures; (iii) reusability; (iv) distributed routing decisions. An external host computer feeds MultiNoC with application instructions and data. After this initialization procedure, MultiNoC executes some algorithm. After finishing execution of the algorithm, output data can be read back by the host. Sequential or parallel algorithms conveniently adapted to the MultiNoC structure can be executed. The main motivation to propose this design is to enable the investigation of current trends to increase the number of embedded processors in SoCs, leading to the concept of ""sea of processors"" systems.",Computer Science
"The aim of this paper is to characterize the moveability of fully-parallel manipulators in the presence of obstacles. Fully parallel manipulators are used in applications where accuracy, stiffness or high speeds and accelerations are required \cite{Merlet:97}. However, one of its main drawbacks is a relatively small workspace compared to the one of serial manipulators. This is due mainly to the existence of potential internal collisions, and the existence of singularities. In this paper, the notion of free aspect is defined which permits to exhibit domains of the workspace and the joint space free of singularity and collision. The main application of this study is the moveability analysis in the workspace of the manipulator as well as path-planning, control and design.",Computer Science
"The distributed source coding problem is considered when the sensors, or encoders, are under Byzantine attack; that is, an unknown group of sensors have been reprogrammed by a malicious intruder to undermine the reconstruction at the fusion center. Three different forms of the problem are considered. The first is a variable-rate setup, in which the decoder adaptively chooses the rates at which the sensors transmit. An explicit characterization of the variable-rate achievable sum rates is given for any number of sensors and any groups of traitors. The converse is proved constructively by letting the traitors simulate a fake distribution and report the generated values as the true ones. This fake distribution is chosen so that the decoder cannot determine which sensors are traitors while maximizing the required rate to decode every value. Achievability is proved using a scheme in which the decoder receives small packets of information from a sensor until its message can be decoded, before moving on to the next sensor. The sensors use randomization to choose from a set of coding functions, which makes it probabilistically impossible for the traitors to cause the decoder to make an error. Two forms of the fixed-rate problem are considered, one with deterministic coding and one with randomized coding. The achievable rate regions are given for both these problems, and it is shown that lower rates can be achieved with randomized coding.",Computer Science
"We consider a multi-channel opportunistic communication system where the states of these channels evolve as independent and statistically identical Markov chains (the Gilbert-Elliot channel model). A user chooses one channel to sense and access in each slot and collects a reward determined by the state of the chosen channel. The problem is to design a sensing policy for channel selection to maximize the average reward, which can be formulated as a multi-arm restless bandit process. In this paper, we study the structure, optimality, and performance of the myopic sensing policy. We show that the myopic sensing policy has a simple robust structure that reduces channel selection to a round-robin procedure and obviates the need for knowing the channel transition probabilities. The optimality of this simple policy is established for the two-channel case and conjectured for the general case based on numerical results. The performance of the myopic sensing policy is analyzed, which, based on the optimality of myopic sensing, characterizes the maximum throughput of a multi-channel opportunistic communication system and its scaling behavior with respect to the number of channels. These results apply to cognitive radio networks, opportunistic transmission in fading environments, and resource-constrained jamming and anti-jamming.",Computer Science
"All of the countries within Africa experience a serious shortage of medical professionals, particularly specialists, a problem that is only exacerbated by high emigration of doctors with better prospects overseas. As a result, those that remain in Africa, particularly those practicing in rural regions, experience a shortage of specialists and other colleagues with whom to exchange ideas. Telemedicine and teleconsultation are key areas that attempt to address this problem by leveraging remote expertise for local problems. This paper presents an overview of teleconsultation in the developing world, with a particular focus on how lessons learned apply to Africa. By teleconsultation, we are addressing non-real-time communication between health care professionals for the purposes of providing expertise and informal recommendations, without the real-time, interactive requirements typical of diagnosis and patient care, which is impractical for the vast majority of existing medical practices. From these previous experiences, we draw a set of guidelines and examine their relevance to Ghana in particular. Based on 6 weeks of needs assessment, we identify key variables that guide our framework, and then illustrate how our framework is used to inform the iterative design of a prototype system.",Computer Science
I describe an approach to similarity motivated by Bayesian methods. This yields a similarity function that is learnable using a standard Bayesian methods. The relationship of the approach to variable kernel and variable metric methods is discussed. The approach is related to variable kernel Experimental results on character recognition and 3D object recognition are presented..,Computer Science
"For a certain class of functions, the distribution of the function values can be calculated in the trellis or a sub-trellis. The forward/backward recursion known from the BCJR algorithm is generalized to compute the moments of these distributions. In analogy to the symbol probabilities, by introducing a constraint at a certain depth in the trellis we obtain symbol moments. These moments are required for an efficient implementation of the discriminated belief propagation algorithm in [2], and can furthermore be utilized to compute conditional entropies in the trellis.   The moment computation algorithm has the same asymptotic complexity as the BCJR algorithm. It is applicable to any commutative semi-ring, thus actually providing a generalization of the Viterbi algorithm.",Computer Science
"Mobile multi-hop ad hoc networks allow establishing local groups of communicating devices in a self-organizing way. However, in a global setting such networks fail to work properly due to network partitioning. Providing that devices are capable of communicating both locally-e.g. using Wi-Fi or Bluetooth-and additionally also with arbitrary remote devices-e.g. using GSM/UMTS links-the objective is to find efficient ways of inter-linking multiple network partitions. Tackling this problem of topology control, we focus on the class of small-world networks that obey two distinguishing characteristics: they have a strong local clustering while still retaining a small average distance between two nodes. This paper reports on results gained investigating the question if small-world properties are indicative for an efficient link management in multiple multi-hop ad hoc network partitions.",Computer Science
"Cellular Simultaneous Recurrent Neural Network (SRN) has been shown to be a function approximator more powerful than the MLP. This means that the complexity of MLP would be prohibitively large for some problems while SRN could realize the desired mapping with acceptable computational constraints. The speed of training of complex recurrent networks is crucial to their successful application. Present work improves the previous results by training the network with extended Kalman filter (EKF). We implemented a generic Cellular SRN and applied it for solving two challenging problems: 2D maze navigation and a subset of the connectedness problem. The speed of convergence has been improved by several orders of magnitude in comparison with the earlier results in the case of maze navigation, and superior generalization has been demonstrated in the case of connectedness. The implications of this improvements are discussed.",Computer Science
"Inspired by the context of compressing encrypted sources, this paper considers the general tradeoff between rate, end-to-end delay, and probability of error for lossless source coding with side-information. The notion of end-to-end delay is made precise by considering a sequential setting in which source symbols are revealed in real time and need to be reconstructed at the decoder within a certain fixed latency requirement. Upper bounds are derived on the reliability functions with delay when side-information is known only to the decoder as well as when it is also known at the encoder.   When the encoder is not ignorant of the side-information (including the trivial case when there is no side-information), it is possible to have substantially better tradeoffs between delay and probability of error at all rates. This shows that there is a fundamental price of ignorance in terms of end-to-end delay when the encoder is not aware of the side information. This effect is not visible if only fixed-block-length codes are considered. In this way, side-information in source-coding plays a role analogous to that of feedback in channel coding.   While the theorems in this paper are asymptotic in terms of long delays and low probabilities of error, an example is used to show that the qualitative effects described here are significant even at short and moderate delays.",Computer Science
"A discrete memoryless half-duplex relay channel is constructed from a broadcast channel from the source to the relay and destination and a multiple access channel from the source and relay to the destination. When the relay listens, the channel operates in the broadcast mode. The channel switches to the multiple access mode when the relay transmits. If the broadcast component channel is physically degraded, the half-duplex relay channel will also be referred to as physically degraded. The capacity of this degraded half-duplex relay channel is examined. It is shown that the block Markov coding suggested in the seminal paper by Cover and El Gamal can be modified to achieve capacity for the degraded half-duplex relay channel. In the code construction, the listen-transmit schedule of the relay is made to depend on the message to be sent and hence the schedule carries information itself. If the schedule is restricted to be deterministic, it is shown that the capacity can be achieved by a simple management of information flows across the broadcast and multiple access component channels.",Computer Science
The Extended BP (EBP) Generalized EXIT (GEXIT) function introduced in \cite{MMRU05} plays a fundamental role in the asymptotic analysis of sparse graph codes. For transmission over the binary erasure channel (BEC) the analytic properties of the EBP GEXIT function are relatively simple and well understood. The general case is much harder and even the existence of the curve is not known in general. We introduce some tools from non-linear analysis which can be useful to prove the existence of EXIT like curves in some cases. The main tool is the Krasnoselskii-Rabinowitz (KR) bifurcation theorem.,Computer Science
"In the paper a new programming construct, called concept, is introduced. Concept is pair of two classes: a reference class and an object class. Instances of the reference classes are passed-by-value and are intended to represent objects. Instances of the object class are passed-by-reference. An approach to programming where concepts are used instead of classes is called concept-oriented programming (CoP). In CoP objects are represented and accessed indirectly by means of references. The structure of concepts describes a hierarchical space with a virtual address system. The paper describes this new approach to programming including such mechanisms as reference resolution, complex references, method interception, dual methods, life-cycle management inheritance and polymorphism.",Computer Science
"In an undirected connected graph G=(V,E), the vertex separator problem (VSP) asks for a partition of V into nonempty subsets A, B, C such that |C| is minimized such that there is no edge between A and B, and sizes of A and B are similar. This paper presents a polyhedral approach of the (VSP), introducing new efficient valid inequalities and providing computational tests and results.",Computer Science
"Leveraging the potential power of even small handheld devices able to communicate wirelessly requires dedicated support. In particular, collaborative applications need sophisticated assistance in terms of querying and exchanging different kinds of data. Using a concrete example from the domain of mobile learning, the general need for information dissemination is motivated. Subsequently, and driven by infrastructural conditions, realization strategies of an appropriate middleware service are discussed.",Computer Science
"A linear mesh network is considered in which a single user per cell communicates to a local base station via a dedicated relay (two-hop communication). Exploiting the possibly relevant inter-cell channel gains, rate splitting with successive cancellation in both hops is investigated as a promising solution to improve the rate of basic single-rate communications. Then, an alternative solution is proposed that attempts to improve the performance of the second hop (from the relays to base stations) by cooperative transmission among the relay stations. The cooperative scheme leverages the common information obtained by the relays as a by-product of the use of rate splitting in the first hop. Numerical results bring insight into the conditions (network topology and power constraints) under which rate splitting, with possible relay cooperation, is beneficial. Multi-cell processing (joint decoding at the base stations) is also considered for reference.",Computer Science
"The JPEG2000 standard defines the discrete wavelet transform (DWT) as a linear space-to-frequency transform of the image domain in an irreversible compression. This irreversible discrete wavelet transform is implemented by FIR filter using 9/7 Daubechies coefficients or a lifting scheme of factorizated coefficients from 9/7 Daubechies coefficients. This work investigates the tradeoffs between area, power and data throughput (or operating frequency) of several implementations of the Discrete Wavelet Transform using the lifting scheme in various pipeline designs. This paper shows the results of five different architectures synthesized and simulated in FPGAs. It concludes that the descriptions with pipelined operators provide the best area-power-operating frequency trade-off over non-pipelined operators descriptions. Those descriptions require around 40% more hardware to increase the maximum operating frequency up to 100% and reduce power consumption to less than 50%. Starting from behavioral HDL descriptions provide the best area-power-operating frequency trade-off, improving hardware cost and maximum operating frequency around 30% in comparison to structural descriptions for the same power requirement.",Computer Science
"This paper presents a simple method to fabricate micro-ball lens and its array. The key technology is to use the hydrophobic characteristics of polyterafluoroethylene (PTFE) substrate. High contact angle between melted photoresist pattern and PTFE can generate micro-ball lens and its array. PTFE thin film was spun onto a silicon wafer and dried in oven. Photoresist AZ4620 was used to pattern micro-columns with different diameters 60, 70 and 80 $\mu$m. A thermal reflow process then was applied to melt these micro-column patterns resulted in micro-ball lens array. The achieved micro-ball lens array with diameter 98 $\mu$m was fabricated using 80 $\mu$m in diameter patterns. This method provides a simple fabrication process and low material cost.",Computer Science
"As Grid computing is becoming an inevitable future, managing, scheduling and monitoring dynamic, heterogeneous resources will present new challenges. Solutions will have to be agile and adaptive, support self-organization and autonomous management, while maintaining optimal resource utilisation. Presented in this paper are basic principles and architectural concepts for efficient resource allocation in heterogeneous Grid environment.",Computer Science
"Manufacturing is using Virtual Reality tools to enhance the product life cycle. Their definitions are still in flux and it is necessary to define their connections. Thus, firstly, we will introduce more closely some definitions where we will find that, if the Virtual manufacturing concepts originate from machining operations and evolve in this manufacturing area, there exist a lot of applications in different fields such as casting, forging, sheet metalworking and robotics (mechanisms). From the recent projects in Europe or in USA, we notice that the human perception or the simulation of mannequin is more and more needed in both fields. In this context, we have isolated some applications as ergonomic studies, assembly and maintenance simulation, design or training where the virtual reality tools can be applied. Thus, we find out a family of applications where the virtual reality tools give the engineers the main role in the optimization process. We will illustrate our paper by several examples where virtual reality interfaces are used and combined with optimization tools as multi-agent systems.",Computer Science
"Self-stabilization is a strong property that guarantees that a network always resume correct behavior starting from an arbitrary initial state. Weaker guarantees have later been introduced to cope with impossibility results: probabilistic stabilization only gives probabilistic convergence to a correct behavior. Also, weak stabilization only gives the possibility of convergence. In this paper, we investigate the relative power of weak, self, and probabilistic stabilization, with respect to the set of problems that can be solved. We formally prove that in that sense, weak stabilization is strictly stronger that self-stabilization. Also, we refine previous results on weak stabilization to prove that, for practical schedule instances, a deterministic weak-stabilizing protocol can be turned into a probabilistic self-stabilizing one. This latter result hints at more practical use of weak-stabilization, as such algorthms are easier to design and prove than their (probabilistic) self-stabilizing counterparts.",Computer Science
"Recommender systems are crucial tools to overcome the information overload brought about by the Internet. Rigorous tests are needed to establish to what extent sophisticated methods can improve the quality of the predictions. Here we analyse a refined correlation-based collaborative filtering algorithm and compare it with a novel spectral method for recommending. We test them on two databases that bear different statistical properties (MovieLens and Jester) without filtering out the less active users and ordering the opinions in time, whenever possible. We find that, when the distribution of user-user correlations is narrow, simple averages work nearly as well as advanced methods. Recommender systems can, on the other hand, exploit a great deal of additional information in systems where external influence is negligible and peoples' tastes emerge entirely. These findings are validated by simulations with artificially generated data.",Computer Science
"The paper discusses and analyzes the scientific search service Google Scholar (GS). The focus is on an exploratory study which investigates the coverage of scientific serials in GS. The study shows deficiencies in the coverage and up-to-dateness of the GS index. Furthermore, the study points up which Web servers are the most important data providers for this search service and which information sources are highly represented. We can show that there is a relatively large gap in Google Scholars coverage of German literature as well as weaknesses in the accessibility of Open Access content.   Keywords: Search engines, Digital libraries, Worldwide Web, Serials, Electronic journals",Computer Science
"A Bayesian optimization algorithm for the nurse scheduling problem is presented, which involves choosing a suitable scheduling rule from a set for each nurses assignment. Unlike our previous work that used Gas to implement implicit learning, the learning in the proposed algorithm is explicit, ie. Eventually, we will be able to identify and mix building blocks directly. The Bayesian optimization algorithm is applied to implement such explicit learning by building a Bayesian network of the joint distribution of solutions. The conditional probability of each variable in the network is computed according to an initial set of promising solutions. Subsequently, each new instance for each variable is generated, ie in our case, a new rule string has been obtained. Another set of rule strings will be generated in this way, some of which will replace previous strings based on fitness selection. If stopping conditions are not met, the conditional probabilities for all nodes in the Bayesian network are updated again using the current set of promising rule strings. Computational results from 52 real data instances demonstrate the success of this approach. It is also suggested that the learning mechanism in the proposed approach might be suitable for other scheduling problems.",Computer Science
"This paper introduces a variation on Kak's three-stage quanutm key distribution protocol which allows for defence against the man in the middle attack. In addition, we introduce a new protocol, which also offers similar resiliance against such an attack.",Computer Science
"In this paper, we propose a spreading activation approach for collaborative filtering (SA-CF). By using the opinion spreading process, the similarity between any users can be obtained. The algorithm has remarkably higher accuracy than the standard collaborative filtering (CF) using Pearson correlation. Furthermore, we introduce a free parameter $\beta$ to regulate the contributions of objects to user-user correlations. The numerical results indicate that decreasing the influence of popular objects can further improve the algorithmic accuracy and personality. We argue that a better algorithm should simultaneously require less computation and generate higher accuracy. Accordingly, we further propose an algorithm involving only the top-$N$ similar neighbors for each target user, which has both less computational complexity and higher algorithmic accuracy.",Computer Science
"The adoption of probabilistic models for the best individuals found so far is a powerful approach for evolutionary computation. Increasingly more complex models have been used by estimation of distribution algorithms (EDAs), which often result better effectiveness on finding the global optima for hard optimization problems. Supervised and unsupervised learning of Bayesian networks are very effective options, since those models are able to capture interactions of high order among the variables of a problem. Diversity preservation, through niching techniques, has also shown to be very important to allow the identification of the problem structure as much as for keeping several global optima. Recently, clustering was evaluated as an effective niching technique for EDAs, but the performance of simpler low-order EDAs was not shown to be much improved by clustering, except for some simple multimodal problems. This work proposes and evaluates a combination operator guided by a measure from information theory which allows a clustered low-order EDA to effectively solve a comprehensive range of benchmark optimization problems.",Computer Science
"This paper introduces a new counting code. Its design was motivated by distributed video coding where, for decoding, error correction methods are applied to improve predictions. Those error corrections sometimes fail which results in decoded values worse than the initial prediction. Our code exploits the fact that bit errors are relatively unlikely events: more than a few bit errors in a decoded pixel value are rare. With a carefully designed counting code combined with a prediction those bit errors can be corrected and sometimes the original pixel value recovered. The error correction improves significantly. Our new code not only maximizes the Hamming distance between adjacent (or ""near 1"") codewords but also between nearby (for example ""near 2"") codewords. This is why our code is significantly different from the well-known maximal counting sequences which have maximal average Hamming distance. Fortunately, the new counting code can be derived from Gray Codes for every code word length (i.e. bit depth).",Computer Science
"A virtual plague is a process in which a behavior-affecting property spreads among characters in a Massively Multiplayer Online Game (MMOG). The MMOG individuals constitute a synthetic population, and the game can be seen as a form of interactive executable model for studying disease spread, albeit of a very special kind. To a game developer maintaining an MMOG, recognizing, monitoring, and ultimately controlling a virtual plague is important, regardless of how it was initiated. The prospect of using tools, methods and theory from the field of epidemiology to do this seems natural and appealing. We will address the feasibility of such a prospect, first by considering some basic measures used in epidemiology, then by pointing out the differences between real world epidemics and virtual plagues. We also suggest directions for MMOG developer control through epidemiological modeling. Our aim is understanding the properties of virtual plagues, rather than trying to eliminate them or mitigate their effects, as would be in the case of real infectious disease.",Computer Science
"Composition of weighted transducers is a fundamental algorithm used in many applications, including for computing complex edit-distances between automata, or string kernels in machine learning, or to combine different components of a speech recognition, speech synthesis, or information extraction system. We present a generalization of the composition of weighted transducers, 3-way composition, which is dramatically faster in practice than the standard composition algorithm when combining more than two transducers. The worst-case complexity of our algorithm for composing three transducers $T_1$, $T_2$, and $T_3$ resulting in $T$, \ignore{depending on the strategy used, is $O(|T|_Q d(T_1) d(T_3) + |T|_E)$ or $(|T|_Q d(T_2) + |T|_E)$,} is $O(|T|_Q \min(d(T_1) d(T_3), d(T_2)) + |T|_E)$, where $|\cdot|_Q$ denotes the number of states, $|\cdot|_E$ the number of transitions, and $d(\cdot)$ the maximum out-degree. As in regular composition, the use of perfect hashing requires a pre-processing step with linear-time expected complexity in the size of the input transducers. In many cases, this approach significantly improves on the complexity of standard composition. Our algorithm also leads to a dramatically faster composition in practice. Furthermore, standard composition can be obtained as a special case of our algorithm. We report the results of several experiments demonstrating this improvement. These theoretical and empirical improvements significantly enhance performance in the applications already mentioned.",Computer Science
"This paper describes a novel numerical model aiming at solving moving-boundary problems such as free-surface flows or fluid-structure interaction. This model uses a moving-grid technique to solve the Navier--Stokes equations expressed in the arbitrary Lagrangian--Eulerian kinematics. The discretization in space is based on the spectral element method. The coupling of the fluid equations and the moving-grid equations is essentially done through the conditions on the moving boundaries. Two- and three-dimensional simulations are presented: translation and rotation of a cylinder in a fluid, and large-amplitude sloshing in a rectangular tank. The accuracy and robustness of the present numerical model is studied and discussed.",Computer Science
"We present a theory of threads, interleaving of threads, and interaction between threads and services with features of molecular dynamics, a model of computation that bears on computations in which dynamic data structures are involved. Threads can interact with services of which the states consist of structured data objects and computations take place by means of actions which may change the structure of the data objects. The features introduced include restriction of the scope of names used in threads to refer to data objects. Because that feature makes it troublesome to provide a model based on structural operational semantics and bisimulation, we construct a projective limit model for the theory.",Computer Science
"We show how to test whether a graph with n vertices and m edges is a partial cube, and if so how to find a distance-preserving embedding of the graph into a hypercube, in the near-optimal time bound O(n^2), improving previous O(nm)-time solutions.",Computer Science
"The paper proposes a novel calibration approach for the Orthoglide-type mechanisms based on observations of the manipulator leg parallelism during mo-tions between the prespecified test postures. It employs a low-cost measuring system composed of standard comparator indicators attached to the universal magnetic stands. They are sequentially used for measuring the deviation of the relevant leg location while the manipulator moves the TCP along the Cartesian axes. Using the measured differences, the developed algorithm estimates the joint offsets that are treated as the most essential parameters to be adjusted. The sensitivity of the meas-urement methods and the calibration accuracy are also studied. Experimental re-sults are presented that demonstrate validity of the proposed calibration technique",Computer Science
"We study Probabilistic Group Testing of a set of N items each of which is defective with probability p. We focus on the double limit of small defect probability, p<<1, and large number of variables, N>>1, taking either p->0 after $N\to\infty$ or $p=1/N^{\beta}$ with $\beta\in(0,1/2)$. In both settings the optimal number of tests which are required to identify with certainty the defectives via a two-stage procedure, $\bar T(N,p)$, is known to scale as $Np|\log p|$. Here we determine the sharp asymptotic value of $\bar T(N,p)/(Np|\log p|)$ and construct a class of two-stage algorithms over which this optimal value is attained. This is done by choosing a proper bipartite regular graph (of tests and variable nodes) for the first stage of the detection. Furthermore we prove that this optimal value is also attained on average over a random bipartite graph where all variables have the same degree, while the tests have Poisson-distributed degrees. Finally, we improve the existing upper and lower bound for the optimal number of tests in the case $p=1/N^{\beta}$ with $\beta\in[1/2,1)$.",Computer Science
"Recently the strong demands in wireless communication requires expanding development for the application of RF MEMS (Radio Frequency micro electro mechanical systems) sensing devices such as micro-switches, tunable capacitors because it offers lower power consumption, lower losses, higher linearity and higher Q factors compared with conventional communications components. To accelerate commercialisation of RF MEMS products, development for packaging technologies is one of the most critical issues should be solved beforehand.",Computer Science
"This paper analyzes the scaling window of a random CSP model (i.e. model RB) for which we can identify the threshold points exactly, denoted by $r_{cr}$ or $p_{cr}$. For this model, we establish the scaling window $W(n,\delta)=(r_{-}(n,\delta), r_{+}(n,\delta))$ such that the probability of a random instance being satisfiable is greater than $1-\delta$ for $r<r_{-}(n,\delta)$ and is less than $\delta$ for $r>r_{+}(n,\delta)$. Specifically, we obtain the following result $$W(n,\delta)=(r_{cr}-\Theta(\frac{1}{n^{1-\epsilon}\ln n}), \ r_{cr}+\Theta(\frac{1}{n\ln n})),$$ where $0\leq\epsilon<1$ is a constant. A similar result with respect to the other parameter $p$ is also obtained. Since the instances generated by model RB have been shown to be hard at the threshold, this is the first attempt, as far as we know, to analyze the scaling window of such a model with hard instances.",Computer Science
"Recently, Roth and Skachek proposed two methods for constructing nearly maximum-distance separable (MDS) expander codes. We show that through the simple modification of using mixed-alphabet codes derived from MDS codes as constituent codes in their code designs, one can obtain nearly MDS codes of significantly smaller alphabet size, albeit at the expense of a (very slight) reduction in code rate.",Computer Science
"Buffer insertion is a popular technique to reduce the interconnect delay. The classic buffer insertion algorithm of van Ginneken has time complexity O(n^2), where n is the number of buffer positions. Lillis, Cheng and Lin extended van Ginneken's algorithm to allow b buffer types in time O (b^2 n^2). For modern design libraries that contain hundreds of buffers, it is a serious challenge to balance the speed and performance of the buffer insertion algorithm. In this paper, we present a new algorithm that computes the optimal buffer insertion in O (bn^2) time. The reduction is achieved by the observation that the (Q, C) pairs of the candidates that generate the new candidates must form a convex hull. On industrial test cases, the new algorithm is faster than the previous best buffer insertion algorithms by orders of magnitude.",Computer Science
"Internet worms cause billions of dollars in damage yearly, affecting millions of users worldwide. For countermeasures to be deployed timeously, it is necessary to use an automated system to detect the spread of a worm. This paper discusses a method of determining the presence of a worm, based on routing information currently available from Internet routers. An autoencoder, which is a specialized type of neural network, was used to detect anomalies in normal routing behavior. The autoencoder was trained using information from a single router, and was able to detect both global instability caused by worms as well as localized routing instability.",Computer Science
"Markov random fields are used to model high dimensional distributions in a number of applied areas. Much recent interest has been devoted to the reconstruction of the dependency structure from independent samples from the Markov random fields. We analyze a simple algorithm for reconstructing the underlying graph defining a Markov random field on $n$ nodes and maximum degree $d$ given observations. We show that under mild non-degeneracy conditions it reconstructs the generating graph with high probability using $\Theta(d \epsilon^{-2}\delta^{-4} \log n)$ samples where $\epsilon,\delta$ depend on the local interactions. For most local interaction $\eps,\delta$ are of order $\exp(-O(d))$.   Our results are optimal as a function of $n$ up to a multiplicative constant depending on $d$ and the strength of the local interactions. Our results seem to be the first results for general models that guarantee that {\em the} generating model is reconstructed. Furthermore, we provide explicit $O(n^{d+2} \epsilon^{-2}\delta^{-4} \log n)$ running time bound. In cases where the measure on the graph has correlation decay, the running time is $O(n^2 \log n)$ for all fixed $d$. We also discuss the effect of observing noisy samples and show that as long as the noise level is low, our algorithm is effective. On the other hand, we construct an example where large noise implies non-identifiability even for generic noise and interactions. Finally, we briefly show that in some simple cases, models with hidden nodes can also be recovered.",Computer Science
"This paper presents deformable templates as a tool for segmentation and localization of biological structures in medical images. Structures are represented by a prototype template, combined with a parametric warp mapping used to deform the original shape. The localization procedure is achieved using a multi-stage, multi-resolution algorithm de-signed to reduce computational complexity and time. The algorithm initially identifies regions in the image most likely to contain the desired objects and then examines these regions at progressively increasing resolutions. The final stage of the algorithm involves warping the prototype template to match the localized objects. The algorithm is presented along with the results of four example applications using MRI, x-ray and ultrasound images.",Computer Science
"One of the main theoretical motivations for the emerging area of network coding is the achievability of the max-flow/min-cut rate for single source multicast. This can exceed the rate achievable with routing alone, and is achievable with linear network codes. The multi-source problem is more complicated. Computation of its capacity region is equivalent to determination of the set of all entropy functions $\Gamma^*$, which is non-polyhedral. The aim of this paper is to demonstrate that this difficulty can arise even in single source problems. In particular, for single source networks with hierarchical sink requirements, and for single source networks with secrecy constraints. In both cases, we exhibit networks whose capacity regions involve $\Gamma^*$. As in the multi-source case, linear codes are insufficient.",Computer Science
"As Moore's Law continues to fuel the ability to build ever increasingly complex system-on-chips (SoCs), achieving performance goals is rising as a critical challenge to completing designs. In particular, the system interconnect must efficiently service a diverse set of data flows with widely ranging quality-of-service (QoS) requirements. However, the known solutions for off-chip interconnects such as large-scale networks are not necessarily applicable to the on-chip environment. Latency and memory constraints for on-chip interconnects are quite different from larger-scale interconnects. This paper introduces a novel on-chip interconnect arbitration scheme. We show how this scheme can be distributed across a chip for high-speed implementation. We compare the performance of the arbitration scheme with other known interconnect arbitration schemes. Existing schemes typically focus heavily on either low latency of service for some initiators, or alternatively on guaranteed bandwidth delivery for other initiators. Our scheme allows service latency on some initiators to be traded off smoothly against jitter bounds on other initiators, while still delivering bandwidth guarantees. This scheme is a subset of the QoS controls that are available in the SonicsMX? (SMX) product.",Computer Science
"The topological structures of the Internet and the Web have received considerable attention. However, there has been little research on the topological properties of individual web sites. In this paper, we consider whether web sites (as opposed to the entire Web) exhibit structural similarities. To do so, we exhaustively crawled 18 web sites as diverse as governmental departments, commercial companies and university departments in different countries. These web sites consisted of as little as a few thousand pages to millions of pages. Statistical analysis of these 18 sites revealed that the internal link structure of the web sites are significantly different when measured with first and second-order topological properties, i.e. properties based on the connectivity of an individual or a pairs of nodes. However, examination of a third-order topological property that consider the connectivity between three nodes that form a triangle, revealed a strong correspondence across web sites, suggestive of an invariant. Comparison with the Web, the AS Internet, and a citation network, showed that this third-order property is not shared across other types of networks. Nor is the property exhibited in generative network models such as that of Barabasi and Albert.",Computer Science
"The Nash Equilibrium is a much discussed, deceptively complex, method for the analysis of non-cooperative games. If one reads many of the commonly available definitions the description of the Nash Equilibrium is deceptively simple in appearance. Modern research has discovered a number of new and important complex properties of the Nash Equilibrium, some of which remain as contemporary conundrums of extraordinary difficulty and complexity. Among the recently discovered features which the Nash Equilibrium exhibits under various conditions are heteroclinic Hamiltonian dynamics, a very complex asymptotic structure in the context of two-player bi-matrix games and a number of computationally complex or computationally intractable features in other settings. This paper reviews those findings and then suggests how they may inform various market prediction strategies.",Computer Science
"This paper investigates point-to-point information transmission over a wideband slow-fading channel, modeled as an (asymptotically) large number of independent identically distributed parallel channels, with the random channel fading realizations remaining constant over the entire coding block. On the one hand, in the wideband limit the minimum achievable energy per nat required for reliable transmission, as a random variable, converges in probability to certain deterministic quantity. On the other hand, the exponential decay rate of the outage probability, termed as the wideband outage exponent, characterizes how the number of parallel channels, {\it i.e.}, the ``bandwidth'', should asymptotically scale in order to achieve a target outage probability at a target energy per nat. We examine two scenarios: when the transmitter has no channel state information and adopts uniform transmit power allocation among parallel channels; and when the transmitter is endowed with an one-bit channel state feedback for each parallel channel and accordingly allocates its transmit power. For both scenarios, we evaluate the wideband minimum energy per nat and the wideband outage exponent, and discuss their implication for system performance.",Computer Science
"This paper introduces a new feedback topology for the Pulsed Digital Oscillator (PDO) and compares it to the classical topology. The `classic' or single feedback topology, introduced in previous works, shows a strong behavior dependence on the damping losses in the MEMS resonator. A new double feedback topology is introduced here in order to help solving this problem. Comparative discrete-time simulations and preliminary experimental measurements have been carried out for both topologies, showing how the new double feedback topology may increase PDO performance for some frequency ranges.",Computer Science
"In this paper, collocated and distributed space-time block codes (DSTBCs) which admit multi-group maximum likelihood (ML) decoding are studied. First the collocated case is considered and the problem of constructing space-time block codes (STBCs) which optimally tradeoff rate and ML decoding complexity is posed. Recently, sufficient conditions for multi-group ML decodability have been provided in the literature and codes meeting these sufficient conditions were called Clifford Unitary Weight (CUW) STBCs. An algebraic framework based on extended Clifford algebras is proposed to study CUW STBCs and using this framework, the optimal tradeoff between rate and ML decoding complexity of CUW STBCs is obtained for few specific cases. Code constructions meeting this tradeoff optimally are also provided. The paper then focuses on multi-group ML decodable DSTBCs for application in synchronous wireless relay networks and three constructions of four-group ML decodable DSTBCs are provided. Finally, the OFDM based Alamouti space-time coded scheme proposed by Li-Xia for a 2 relay asynchronous relay network is extended to a more general transmission scheme that can achieve full asynchronous cooperative diversity for arbitrary number of relays. It is then shown how differential encoding at the source can be combined with the proposed transmission scheme to arrive at a new transmission scheme that can achieve full cooperative diversity in asynchronous wireless relay networks with no channel information and also no timing error knowledge at the destination node. Four-group decodable DSTBCs applicable in the proposed OFDM based transmission scheme are also given.",Computer Science
"We report on the development of some process capabilities for a polymer-based, multi-layer microelectrofluidic platform, namely: the hot embossing process, metallization on polymer and polymer bonding. Hot embossing experiments were conducted to look at the effects of load applied, embossing temperature and embossing time on the fidelity of line arrays representing micro channels. The results revealed that the embossing temperature is a more sensitive parameter than the others due to its large effect on the polymer material's viscoelastic properties. Dynamic mechanical analysis (DMA) on polymethyl methacrylate (PMMA) revealed a steep glass transition over a 20 oC range, with the material losing more than 95 % of its storage modulus. The data explained the hot embossing results which showed large change in the embossed channel dimensions when the temperature is within the glass transition range. It was demonstrated that the micro-printing of silver epoxy is a possible low-cost technique in the mass production of disposable lab chips. An interconnecting network of electrical traces was fabricated in the form of a four-layer PMMA-based device. A four PMMA layer device with interconnecting microfluidic channels was also fabricated and tested.",Computer Science
"The design of reliable circuits has received a lot of attention in the past, leading to the definition of several design techniques introducing fault detection and fault tolerance properties in systems for critical applications/environments. Such design methodologies tackled the problem at different abstraction levels, from switch-level to logic, RT level, and more recently to system level. Aim of this paper is to introduce a novel system-level technique based on the redefinition of the operators functionality in the system specification. This technique provides reliability properties to the system data path, transparently with respect to the designer. Feasibility, fault coverage, performance degradation and overheads are investigated on a FIR circuit.",Computer Science
"Tagging communities represent a subclass of a broader class of user-generated content-sharing online communities. In such communities users introduce and tag content for later use. Although recent studies advocate and attempt to harness social knowledge in this context by exploiting collaboration among users, little research has been done to quantify the current level of user collaboration in these communities. This paper introduces two metrics to quantify the level of collaboration: content reuse and shared interest. Using these two metrics, this paper shows that the current level of collaboration in CiteULike and Connotea is consistently low, which significantly limits the potential of harnessing the social knowledge in communities. This study also discusses implications of these findings in the context of recommendation and reputation systems.",Computer Science
"This paper describes two research projects that develop new low-cost techniques for testing devices with multiple high-speed (2 to 5 Gbps) signals. Each project uses commercially available components to keep costs low, yet achieves performance characteristics comparable to (and in some ways exceeding) more expensive ATE. A common CMOS FPGA-based logic core provides flexibility, adaptability, and communication with controlling computers while customized positive emitter-coupled logic (PECL) achieves multi-gigahertz data rates with about $\pm$25ps timing accuracy.",Computer Science
"This paper explores several extensions of proof nets for the Lambek calculus in order to handle the different connectives of display logic in a natural way. The new proof net calculus handles some recent additions to the Lambek vocabulary such as Galois connections and Grishin interactions. It concludes with an exploration of the generative capacity of the Lambek-Grishin calculus, presenting an embedding of lexicalized tree adjoining grammars into the Lambek-Grishin calculus.",Computer Science
"In order to understand the key merits of multiuser diversity techniques in relay-assisted cellular multihop networks, this paper analyzes the spectral efficiency of opportunistic (i.e., channel-aware) scheduling algorithms over a fading multiuser relay channel with $K$ users in the asymptotic regime of large (but finite) number of users. Using tools from extreme-value theory, we characterize the limiting distribution of spectral efficiency focusing on Type I convergence and utilize it in investigating the large system behavior of the multiuser relay channel as a function of the number of users and physical channel signal-to-noise ratios (SNRs). Our analysis results in very accurate formulas in the large (but finite) $K$ regime, provides insights on the potential performance enhancements from multihop routing and spectrum reuse policies in the presence of multiuser diversity gains from opportunistic scheduling and helps to identify the regimes and conditions in which relay-assisted multiuser communication provides a clear advantage over direct multiuser communication.",Computer Science
"Data transfer and staging services are common components in Grid-based, or more generally, in service-oriented applications. Security mechanisms play a central role in such services, especially when they are deployed in sensitive application fields like e-health. The adoption of WS-Security and related standards to SOAP-based transfer services is, however, problematic as a straightforward adoption of SOAP with MTOM introduces considerable inefficiencies in the signature generation process when large data sets are involved. This paper proposes a non-blocking, signature generation approach enabling a stream-like processing with considerable performance enhancements.",Computer Science
"We consider the discrete-time infinite-horizon optimal control problem formalized by Markov Decision Processes. We revisit the work of Bertsekas and Ioffe, that introduced $\lambda$ Policy Iteration, a family of algorithms parameterized by $\lambda$ that generalizes the standard algorithms Value Iteration and Policy Iteration, and has some deep connections with the Temporal Differences algorithm TD($\lambda$) described by Sutton and Barto. We deepen the original theory developped by the authors by providing convergence rate bounds which generalize standard bounds for Value Iteration described for instance by Puterman. Then, the main contribution of this paper is to develop the theory of this algorithm when it is used in an approximate form and show that this is sound. Doing so, we extend and unify the separate analyses developped by Munos for Approximate Value Iteration and Approximate Policy Iteration. Eventually, we revisit the use of this algorithm in the training of a Tetris playing controller as originally done by Bertsekas and Ioffe. We provide an original performance bound that can be applied to such an undiscounted control problem. Our empirical results are different from those of Bertsekas and Ioffe (which were originally qualified as ""paradoxical"" and ""intriguing""), and much more conform to what one would expect from a learning experiment. We discuss the possible reason for such a difference.",Computer Science
"In this research, a novel contact resistance model for the flat panel display (FPD) packaging based on the within layer parallel and between layers series resistance concepts was proposed. The FJ2530 anisotropic conductive films (ACF) by Sony Inc. containing the currently smallest 3micron conductive particles was used to conduct the experiments to verify the accuracy of the proposed model. Calculated resistance of the chip-on-glass (COG) packaging by the proposed model is 0.163\Omega. It is found that the gold bump with 0.162\Omega resistance play the major role of the overall resistance. Although the predicted resistance by the proposed model is only one third of the experimentally measured value, it has been three-fold improvement compared to the existing models.",Computer Science
"This paper presents the results of an empirical evaluation of the quality of a structured methodology for the development of spreadsheet models, proposed in numerous previous papers by Rajalingham K, Knight B and Chadwick D et al. This paper also describes an improved version of their methodology, supported by appropriate examples. The principal objective of a structured and disciplined methodology for the construction of spreadsheet models is to reduce the occurrence of user-generated errors in the models. The evaluation of the effectiveness of the methodology has been carried out based on a number of real-life experiments. The results of these experiments demonstrate the methodology's potential for improved integrity control and enhanced comprehensibility of spreadsheet models.",Computer Science
This paper presents an expression to compute the exact period of a recursive random number generator based on d-sequences. Using the multi-recursive version of this generator we can produce large number of pseudorandom sequences.,Computer Science
"Bounds on the risk play a crucial role in statistical learning theory. They usually involve as capacity measure of the model studied the VC dimension or one of its extensions. In classification, such ""VC dimensions"" exist for models taking values in {0, 1}, {1,..., Q} and R. We introduce the generalizations appropriate for the missing case, the one of models with values in R^Q. This provides us with a new guaranteed risk for M-SVMs which appears superior to the existing one.",Computer Science
"This paper has been withdrawn by the author, due an error in claim 1.",Computer Science
"This paper introduces U-relations, a succinct and purely relational representation system for uncertain databases. U-relations support attribute-level uncertainty using vertical partitioning. If we consider positive relational algebra extended by an operation for computing possible answers, a query on the logical level can be translated into, and evaluated as, a single relational algebra query on the U-relation representation. The translation scheme essentially preserves the size of the query in terms of number of operations and, in particular, number of joins. Standard techniques employed in off-the-shelf relational database management systems are effective for optimizing and processing queries on U-relations. In our experiments we show that query evaluation on U-relations scales to large amounts of data with high degrees of uncertainty.",Computer Science
"In this paper will be presented methodology of encoding information in valuations of discrete lattice with some translational invariant constrains in asymptotically optimal way. The method is based on finding statistical description of such valuations and changing it into statistical algorithm, which allows to construct deterministically valuation with given statistics. Optimal statistics allow to generate valuations with uniform distribution - we get maximum information capacity this way. It will be shown that we can reach the optimum for one-dimensional models using maximal entropy random walk and that for the general case we can practically get as close to the capacity of the model as we want (found numerically: lost 10^{-10} bit/node for Hard Square). There will be also presented simpler alternative to arithmetic coding method which can be used as cryptosystem and data correction method too.",Computer Science
"Generic programming is an effective methodology for developing reusable software libraries. Many programming languages provide generics and have features for describing interfaces, but none completely support the idioms used in generic programming. To address this need we developed the language G. The central feature of G is the concept, a mechanism for organizing constraints on generics that is inspired by the needs of modern C++ libraries. G provides modular type checking and separate compilation (even of generics). These characteristics support modular software development, especially the smooth integration of independently developed components. In this article we present the rationale for the design of G and demonstrate the expressiveness of G with two case studies: porting the Standard Template Library and the Boost Graph Library from C++ to G. The design of G shares much in common with the concept extension proposed for the next C++ Standard (the authors participated in its design) but there are important differences described in this article.",Computer Science
"In this paper we discuss a relationship between the following two algebras: (i) the subconstituent algebra $T$ of a distance-regular graph that has $q$-Racah type; (ii) the $q$-tetrahedron algebra $\boxtimes_q$ which is a $q$-deformation of the three-point $sl_2$ loop algebra. Assuming that every irreducible $T$-module is thin, we display an algebra homomorphism from $\boxtimes_q$ into $T$ and show that $T$ is generated by the image together with the center $Z(T)$.",Mathematics
"We study a variation of the combinatorial game of 2-pile Nim. Move as in 2-pile Nim but with the following constraint:   Suppose the previous player has just removed say $x>0$ tokens from the shorter pile (either pile in case they have the same height). If the next player now removes $x$ tokens from the larger pile, then he imitates his opponent. For a predetermined natural number $p$, by the rules of the game, neither player is allowed to imitate his opponent on more than $p-1$ consecutive moves.   We prove that the strategy of this game resembles closely that of a variant of Wythoff Nim--a variant with a blocking manoeuvre on $p-1$ diagonal positions. In fact, we show a slightly more general result in which we have relaxed the notion of what an imitation is.",Mathematics
"We consider the properties weak cancellation, K_1-surjectivity, good index theory, and K_1-injectivity for the class of extremally rich C*-algebras, and for the smaller class of isometrically rich C*-algebras. We establish all four properties for isometrically rich C*-algebras and for extremally rich C*-algebras that are either purely infinite or of real rank zero, K_1-injectivity in the real rank zero case following from a prior result of H. Lin. We also show that weak cancellation implies the other properties for extremally rich C*-algebras and that the class of extremally rich C*-algebras with weak cancellation is closed under extensions. Moreover, we consider analogous properties which replace the group K_1(A) with the extremal K-set K_e(A) as well as two versions of K_0-surjectivity.",Mathematics
"We prove dispersive estimates at low frequency in dimensions n greater or equal to 4 for the wave equation for a very large class of real-valued potentials, provided the zero is neither an eigenvalue nor a resonance.",Mathematics
"Let $X\hookrightarrow \cpn $ be a smooth complex projective variety of dimension $n$. Let $\lambda$ be an algebraic one parameter subgroup of $G:=\gc$. Let $ 0\leq l\leq n+1$. We associate to the coefficients $F_{l}(\lambda)$ of the normalized weight of $\lambda$ on the $mth$ Hilbert point of $X$ new energies $F_{\om,l}(\vp)$. The (logarithmic) asymptotics of $F_{\om,l}(\vp)$ along the potential deduced from $\lambda$ is the weight $F_{l}(\lambda)$. $F_{\om,l}(\vp)$ reduces to the Aubin energy when $l=0$ and the K-Energy map of Mabuchi when $l=1$. When $l\geq 2$ $F_{\om,l}(\vp)$ coincides (modulo lower order terms) with the functional $E_{\om,l-1}(\vp)$ introduced by X.X. Chen and G.Tian.",Mathematics
"We associate a quasisymmetric function to any Bruhat interval in a general Coxeter group. This association can be seen to be a morphism of Hopf algebras to the subalgebra of all peak functions, leading to an extension of the cd-index of convex polytopes. We show how the Kazhdan-Lusztig polynomial of the Bruhat interval can be expressed in terms of this complete cd-index and otherwise explicit combinatorially defined polynomials. In particular, we obtain the simplest closed formula for the Kazhdan-Lusztig polynomials that holds in complete generality.",Mathematics
"An (upward) skip-free Markov chain with the set of nonnegative integers as state space is a chain for which upward jumps may be only of unit size; there is no restriction on downward jumps. In a 1987 paper, Brown and Shao determined, for an irreducible continuous-time skip-free chain and any d, the passage time distribution from state 0 to state d. When the nonzero eigenvalues nu_j of the generator are all real, their result states that the passage time is distributed as the sum of d independent exponential random variables with rates nu_j. We give another proof of their theorem. In the case of birth-and-death chains, our proof leads to an explicit representation of the passage time as a sum of independent exponential random variables. Diaconis and Miclo recently obtained the first such representation, but our construction is much simpler.   We obtain similar (and new) results for a fastest strong stationary time T of an ergodic continuous-time skip-free chain with stochastically monotone time-reversal started in state 0, and we also obtain discrete-time analogs of all our results.   In the paper's final section we present extensions of our results to more general chains.",Mathematics
"We partially describe equivariant Dirac and generalized complex structures on a homogeneous space $G/K$ by giving equivalent data involving only the Lie algebra. We consider real semisimple adjoint orbits in any semisimple Lie algebra over $\mathbb R$ and real nilpotent orbits in $sl_n (\mathbb R)$. We give a complete classification for Riemannian symmetric spaces and for a compact group modulo a closed, connected subgroup containing a Cartan subgroup.",Mathematics
"In this paper, we first study the local rings of a Berkovich analytic space from the point of view of commutative algebra. We show that those rings are excellent ; we introduce the notion of a an analytically separable extension of non-archimedean complete fields (it includes the case of the finite separable extensions, and also the case of any complete extension of a perfect complete non-archimedean field) and show that the usual commutative algebra properties (Rm, Sm, Gorenstein, Cohen-Macaulay, Complete Intersection) are stable under analytically separable ground field extensions; we also establish a GAGA principle with respect to those properties for any finitely generated scheme over an affinoid algebra.   A second part of the paper deals with more global geometric notions : we define, show the existence and establish basic properties of the irreducible components of analytic space ; we define, show the existence and establish basic properties of its normalization ; and we study the behaviour of connectedness and irreducibility with respect to base change.",Mathematics
"In this note, we consider generalizations of the asymptotic Hopf invariant, or helicity, for Hamiltonian systems with one-and-a-half degrees of freedom and symplectic diffeomorphisms of a two-disk to itself.",Mathematics
"We give, for each level of complexity L, a Hurewicz-like characterization of the Borel subsets with countable sections of a product of two Polish spaces that cannot become in L by changing the two Polish topologies.",Mathematics
"We study several deformation functors associated to the normalization of a reduced curve singularity $(X,0) \subset (\c^n,0)$. The main new results are explicit formulas, in terms of classical invariants of (X,0), for the cotangent cohomology groups $T^i, i = 0,1,2,$ of these functors. Thus we obtain precise statements about smoothness and dimension of the corresponding local moduli spaces. We apply the results to obtain explicit formulas resp. estimates for the $\hoa{A}_e$-codimension of a parametrized curve singularity, where $\hoa{A}_e$ denotes the Mather-Wall group of left-right equivalence.",Mathematics
"If A is a cocommutative algebra with coproduct, then so is the smash product algebra of a symmetric algebra Sym(V) with A, where V is an A-module. Such smash product algebras, with A a group ring or a Lie algebra, have families of deformations that have been studied widely in the literature; examples include symplectic reflection algebras and infinitesimal Hecke algebras. We introduce a family of deformations of these smash product algebras for general A, and characterize the PBW property. We then characterize the Jacobi identity for ""grouplike"" algebras (that include group rings and the nilCoxeter algebra), and precisely identify the PBW deformations in the example where A is the nilCoxeter algebra. We end with the more prominent case - where A is a Hopf algebra. We show the equivalence of several versions of the ""deformed"" relations in the smash product, and identify the PBW deformations which are Hopf algebras as well.",Mathematics
"The purpose of the present article is to show the multilinearity for symbols in Goodwillie-Lichtenbaum complex in two cases.   The first case shown is where the degree is equal to the weight. In this case, the motivic cohomology groups of a field are isomorphic to the Milnor's K-groups as shown by Nesterenko-Suslin, Totaro and Suslin-Voevodsky for various motivic complexes, but we give an explicit isomorphism for Goodwillie-Lichtenbaum complex in a form which visibly carries multilinearity of Milnor's symbols to our multilinearity of motivic symbols. Next, we establish multilinearity and skew-symmetry for irreducible Goodwillie-Lichtenbaum symbols in H^{l-1} (Spec k, Z(l)). These properties have been expected to hold from the author's construction of a bilinear form of dilogarithm in case k is a subfield of the field of complex numbers and l=2.   Next, we establish multilinearity and skew-symmetry for Goodwillie-Lichtenbaum symbols in H^{l-1} (Spec k, Z(l)). These properties have been expected to hold from the author's construction of a bilinear form of dilogarithm in case k is a subfield of the field of complex numbers and l=2.   The multilinearity of symbols may be viewed as a generalization of the well-known formula det(AB) = det(A) det(B) for tuples of commuting matrices.",Mathematics
"We prove that an arbitrary (not necessarily countably generated) Hilbert $G$-$\cla$ module on a G-C^* algebra $\cla$ admits an equivariant embedding into a trivial $G-\cla$ module, provided G is a compact Lie group and its action on $\cla$ is ergodic.",Mathematics
"A discrete Laplace transform and its inversion formula are obtained by using a quadrature of the continuous Fourier transform which is given in terms of Hermite polynomials and its zeros. This approach yields a convergent discrete formula for the two-sided Laplace transform if the function to be transformed falls off rapidly to zero and satisfy certain conditions of integrability, achieving convergence also for singular functions. The inversion formula becomes a quadrature formula for the Bromwich integral. This procedure also yields a quadrature formula for the Mellin transform and its corresponding inversion formula that can be generalized straightforwardly for functions of several variables.",Mathematics
"The aim of this work is a systematic investigation of the possible parameters of quasi-perfect (QP) binary and ternary linear codes of small dimensions and preparing a complete classification of all such codes. First we give a list of infinite families of QP codes which includes all binary, ternary and quaternary codes known to is. We continue further with a list of sporadic examples of binary and ternary QP codes. Later we present the results of our investigation where binary QP codes of dimensions up to 14 and ternary QP codes of dimensions up to 13 are classified.",Mathematics
"In this paper we show how to find nearly optimal embeddings of large trees in several natural classes of graphs. The size of the tree T can be as large as a constant fraction of the size of the graph G, and the maximum degree of T can be close to the minimum degree of G. For example, we prove that any graph of minimum degree d without 4-cycles contains every tree of size \epsilon d^2 and maximum degree at most (1-2\epsilon)d - 2. As there exist d-regular graphs without 4-cycles of size O(d^2), this result is optimal up to constant factors. We prove similar nearly tight results for graphs of given girth, graphs with no complete bipartite subgraph K_{s,t}, random and certain pseudorandom graphs. These results are obtained using a simple and very natural randomized embedding algorithm, which can be viewed as a ""self-avoiding tree-indexed random walk"".",Mathematics
"In this paper we characterize all the $r$-parameter families of count distributions (satisfying mild conditions) that are closed under addition and under binomial subsampling. Surprisingly, few families satisfy both properties and the resulting models consist of the $r$th-order univariate Hermite distributions. Among these, we find the Poisson ($r=1$) and the ordinary Hermite distributions ($r=2$).",Mathematics
"v2: We improved a little bit according to the referee's wishes.   v1: On $X$ projective smooth over a field $k$, Pink and Roessler conjecture that the dimension of the Hodge cohomology of an invertible $n$-torsion sheaf $L$ is the same as the one of its $a$-th power $L^a$ if $a$ is prime to $n$, under the assumptions that $X$ lifts to $W_2(k)$ and $dim X\le p$, if $k$ has characteristic $p>0$. They show this if $k$ has characteristic 0 and if $n$ is prime to $p$ in characteristic $p>0$. We show the conjecture in characteristic $p>0$ if $n=p$ assuming in addition that $X$ is ordinary (in the sense of Bloch-Kato).",Mathematics
"We establish existence of travelling waves to the gradient system $u_t = u_{zz} - \nabla W(u)$ connecting two minima of $W$ when $u : \R \times (0,\infty) \larrow \R^N$, that is, we establish existence of a pair $(U,c) \in [C^2(\R)]^N \by (0,\infty)$, satisfying \[ \{{array}{l}   U_{xx} - \nabla W (U) = - c U_x   U(\pm \infty) = a^{\pm}, {array}. \] where $a^{\pm}$ are local minima of the potential $W \in C_{\textrm{loc}}^2(\R^N)$ with $W(a^-)< W(a^+)=0$ and $N \geq 1$. Our method is variational and based on the minimization of the functional $E_c (U) = \int_{\R}\Big\{{1/2}|U_x|^2 + W(U) \Big\}e^{cx} dx$ in the appropriate space setup. Following Alikakos-Fusco \cite{A-F}, we introduce an artificial constraint to restore compactness and force the desired asymptotic behavior, which we later remove. We provide variational characterizations of the travelling wave and the speed. In particular, we show that $E_c(U)=0$.",Mathematics
"By studying connectedness at infinity of systolic groups we distinguish them from some other classes of groups, in particular from the fundamental groups of manifolds covered by euclidean space of dimension at least three. We also study semistability at infinity for some systolic groups.",Mathematics
We prove that existentially closed $CSA$-groups have the independence property. This is done by showing that there exist words having the independence property relatively to the class of torsion-free hyperbolic groups.,Mathematics
"We construct two new families of basis for finite field extensions. Basis in the first family, the so-called elliptic basis, are not quite normal basis, but they allow very fast Frobenius exponentiation while preserving sparse multiplication formulas. Basis in the second family, the so-called normal elliptic basis are normal basis and allow fast (quasi linear) arithmetic. We prove that all extensions admit models of this kind.",Mathematics
"Let X be an affine irreducible variety over an algebraically closed field k of characteristic zero. Given an automorphism F, we denote by k(X)^F its field of invariants, i.e. the set of rational functions f on X such that f(F)=f. Let n(F) be the transcendence degree of k(X)^F over k. In this paper, we study the class of automorphisms F of X for which n(F)= dim X - 1. More precisely, we show that under some conditions on X, every such automorphism is of the form F=A_g, where A is an algebraic action of a linear algebraic group G of dimension 1 on X, and where g belongs to G. As an application, we determine the conjugacy classes of automorphisms of the plane for which n(F)=1.",Mathematics
"Multivariate statistics are often available as well as necessary in hypothesis tests. We study how to use such statistics to control not only false discovery rate (FDR) but also positive FDR (pFDR) with good power. We show that FDR can be controlled through nested regions of multivariate $p$-values of test statistics. If the distributions of the test statistics are known, then the regions can be constructed explicitly to achieve FDR control with maximum power among procedures satisfying certain conditions. On the other hand, our focus is where the distributions are only partially known. Under certain conditions, a type of nested regions are proposed and shown to attain (p)FDR control with asymptotically maximum power as the pFDR control level approaches its attainable limit. The procedure based on the nested regions is compared with those based on other nested regions that are easier to construct as well as those based on more straightforward combinations of the test statistics.",Mathematics
We introduce a new class of canonical AZD's (called the supercanonical AZD's) on the canonical bundles of smooth projective varieties with pseudoeffective canonical classes. We study the variation of the supercanonical AZD $\hat{h}_{can}$ under projective deformations and give a new proof of the invariance of plurigenera.,Mathematics
"We consider a transient random walk $(X_n)$ in random environment on a Galton--Watson tree. Under fairly general assumptions, we give a sharp and explicit criterion for the asymptotic speed to be positive. As a consequence, situations with zero speed are revealed to occur. In such cases, we prove that $X_n$ is of order of magnitude $n^{\Lambda}$, with $\Lambda \in (0,1)$. We also show that the linearly edge reinforced random walk on a regular tree always has a positive asymptotic speed, which improves a recent result of Collevecchio \cite{Col06}.",Mathematics
"Nous \'{e}tudions les cha\^{{\i}}nes de Markov $(X_n)_{n\in\mathbf{Z}}$ gouvern\'{e}es par une relation de r\'{e}currence de la forme $X_{n+1}=f(X_n,V_{n+1})$, o\`{u} $(V_n)_{n\in\mathbf{Z}}$ est une suite de variables al\'{e}atoires ind\'{e}pendantes et de m\^{e}me loi telle pour tout $n\in \mathbf{Z}$, $V_{n+1}$ est ind\'{e}pendante de la suite $((X_k,V_k))_{k\le n}$. L'objet de l'article est de donner une condition n\'{e}cessaire et suffisante pour que les innovations $(V_n)_{n\in\mathbf{Z}}$ d\'{e}terminent compl\`{e}tement la suite $(X_n)_{n\in \mathbf{Z}}$ et de d\'{e}crire l'information manquante dans le cas contraire.",Mathematics
"We consider Jacobi matrices whose essential spectrum is a finite union of closed intervals. We focus on Szego's theorem, Jost solutions, and Szego asymptotics for this situation. This announcement describes talks the authors gave at OPSFA 2007.",Mathematics
"We consider a continuous function $f$ on a domain in $\mathbf C^n$ satisfying the inequality that $|\bar \partial f|\leq |f|$ off its zero set. The main conclusion is that the zero set of $f$ is a complex variety.   We also obtain removable singularity theorem of Rado type for J-holomorphic maps. Let $\Omega$ be an open subset in $\mathbf C$ and let $E$ be a closed polar subset of $\Omega$. Let $u$ be a continuous map from $\Omega$ into an almost complex manifold $(M,J)$ with $J$ of class $C^1$. We show that if $u$ is J-holomorphic on $\Omega\setminus E$ then it is J-holomorphic on $\Omega$.",Mathematics
"We study the notion of joinings of W*-dynamical systems, building on ideas from measure theoretic ergodic theory. In particular we prove sufficient and necessary conditions for ergodicity in terms of joinings, and also briefly look at conditional expectation operators associated with joinings.",Mathematics
"This work is inspired by conversations with Izzet Coskun and Joe Harris. We run the log minimal model program for the Kontsevich space of stable maps $\bar{\mathcal M}_{0,0}(\mathbb P^{3}, 3)$ and give modular interpretations to all the intermediate spaces appearing in the process. In particular, we show that one component of the Hilbert scheme $\mathcal H_{3,0,3}$ is the flip of $\bar{\mathcal M}_{0,0}(\mathbb P^{3}, 3)$ over the Chow variety. Finally as an easy corollary we obtain that $\bar{\mathcal M}_{0,0}(\mathbb P^{3}, 3)$ is a Mori dream space.",Mathematics
"We study the biharmonic stress-energy tensor $S_2$ of Gauss map. Adding few assumptions, the Gauss map with vanishing $S_2$ would be harmonic.",Mathematics
"We study measures on $\mathbb{R}^d$ which are induced by a class of infinite and recursive iterations in symbolic dynamics. Beginning with a finite set of data, we analyze prescribed recursive iteration systems, each involving subdivisions. The construction includes measures arising from affine and contractive iterated function systems with and without overlap (IFSs), i.e., limit measures $\mu$ induced by a finite family of affine mappings in $\mathbb{R}^d$ (the focus of our paper), as well as equilibrium measures in complex dynamics.   By a systematic analysis of the Fourier transform of the measure $\mu$ at hand (frequency domain), we identify asymptotic laws, spectral types, dichotomy, and chaos laws. In particular we show that the cases when $\mu$ is singular carry a gradation, ranging from Cantor-like fractal measures to measures exhibiting chaos, i.e., a situation when small changes in the initial data produce large fluctuations in the outcome, or rather, the iteration limit (in this case the measures). Our method depends on asymptotic estimates on the Fourier transform of $\mu$ for paths at infinity in $\mathbb{R}^d$. We show how properties of $\mu$ depend on perturbations of the initial data, e.g., variations in a prescribed finite set of affine mappings in $\mathbb{R}^d$, in parameters of a rational function in one complex variable (Julia sets and equilibrium measures), or in the entries of a given infinite positive definite matrix.",Mathematics
"To any cleft Hopf Galois object, i.e., any algebra H[t] obtained from a Hopf algebra H by twisting its multiplication with a two-cocycle t, we attach two ""universal algebras"" A(H,t) and U(H,t). The algebra A(H,t) is obtained by twisting the multiplication of H with the most general two-cocycle u formally cohomologous to t. The cocycle u takes values in the field of rational functions on H. By construction, A(H,t) is a cleft H-Galois extension of a ""big"" commutative algebra B(H,t). Any ""form"" of H[t] can be obtained from A(H,t) by a specialization of B(H,t) and vice versa. If the algebra H[t] is simple, then A(H,t) is an Azumaya algebra with center B(H,t). The algebra U(H,t) is constructed using a general theory of polynomial identities that we set up for arbitrary comodule algebras; it is the universal comodule algebra in which all comodule algebra identities of H[t] are satisfied. We construct an embedding of U(H,t) into A(H,t); this embedding maps the center Z(H,t) of U(H,t) into B(H,t) when the algebra H[t] is simple. In this case, under an additional assumption, A(H,t) is isomorphic to B(H,t) \otimes_{Z(H,t)} U(H,t), thus turning A(H,t) into a central localization of U(H,t). We work out these constructions in full detail for the four-dimensional Sweedler algebra.",Mathematics
"The main goal of the paper is to address the issue of the existence of Kempf's distortion function and the Tian-Yau-Zelditch (TYZ) asymptotic expansion for the Kepler manifold - an important example of non compact manfold. Motivated by the recent results for compact manifolds we construct Kempf's distortion function and derive a precise TYZ asymptotic expansion for the Kepler manifold. We get an exact formula: finite asymptotic expansion of $n-1$ terms and exponentially small error terms uniformly with respect to the discrete quantization parameter $m\to \infty $ and $\rho \to \infty$, $\rho$ being the polar radius in $\C^n$.   Moreover, the coefficents are calculated explicitly and they turned out to be homogeneous functions with respect to the polar radius in the Kepler manifold. We also prove and derive an asymptotic expansion of the obtstruction term with the coefficients being defined by geometrical quantities. We show that our estimates are sharp by analyzing the nonharmonic behaviour of $T_m$ and the error term of the approximation of the Fubini--Study metric by $m\omega$ for $m\to +\infty$. The arguments of the proofs combine geometrical methods, quantization tools and functional analytic techniques for investigating asymptotic expansions in the framework of analytic-Gevrey spaces.",Mathematics
"In this paper, we investigate the asymptotic spectrum of complex or real Deformed Wigner matrices $(M_N)_N$ defined by $M_N=W_N/\sqrt{N}+A_N$ where $W_N$ is an $N\times N$ Hermitian (resp., symmetric) Wigner matrix whose entries have a symmetric law satisfying a Poincar\'{e} inequality. The matrix $A_N$ is Hermitian (resp., symmetric) and deterministic with all but finitely many eigenvalues equal to zero. We first show that, as soon as the first largest or last smallest eigenvalues of $A_N$ are sufficiently far from zero, the corresponding eigenvalues of $M_N$ almost surely exit the limiting semicircle compact support as the size $N$ becomes large. The corresponding limits are universal in the sense that they only involve the variance of the entries of $W_N$. On the other hand, when $A_N$ is diagonal with a sole simple nonnull eigenvalue large enough, we prove that the fluctuations of the largest eigenvalue are not universal and vary with the particular distribution of the entries of $W_N$.",Mathematics
Suppose a group $G$ is quasi-isometric to a free product of a finite set $S$ of finitely generated abelian groups; let $S'$ denote the set of ranks of the free abelian parts of the groups in $S$. Then $G$ is commensurable with the free product of $\Z$ with a $\Z^n$ for each $n$ occurring in $S'$.,Mathematics
We study an asymptotic behaviour of the principal eigenvalue for an elliptic operator with large advection which is given by a gradient of a potential function. It is shown that the principal eigenvalue decays exponentially under the velocity potential well condition as the parameter tends to infinity.,Mathematics
"We show existence and regularity result for the Navier Stokes system for small data in the space $\Phi(2)$, and we show relations with some classical results.",Mathematics
"In this paper we show that the quotient Aubry set associated to certain Lagrangians is totally disconnected (i.e., every connected component consists of a single point). Moreover, we discuss the relation between this problem and a Morse-Sard type property for (difference of) critical subsolutions of Hamilton-Jacobi equations.",Mathematics
"We consider compact hyperbolic Coxeter polytopes whose Coxeter diagram contains a unique dotted edge. We prove that such a polytope in d-dimensional hyperbolic space has at most d+3 facets. In view of results of Lann\'er, Kaplinskaja, Esselmann, and the second author, this implies that compact hyperbolic Coxeter polytopes with a unique pair of non-intersecting facets are completely classified. They do exist only up to dimension 6 and in dimension 8.",Mathematics
"It is proved that for any two subsets $A$ and $B$ of an arbitrary finite field $\Fq$ such that $|A||B|>q$ the identity $16AB=\Fq$ holds. Moreover, it is established that for every subsets $X, Y\subset \Fq$ with the property $|X||Y|\geqslant 2q$ the equality $8XY=\Fq$ holds.",Mathematics
"Let $X$ be a set of points whose coordinates are known with limited accuracy; our aim is to give a characterization of the vanishing ideal $I(X)$ independent of the data uncertainty. We present a method to compute a polynomial basis $B$ of $I(X)$ which exhibits structural stability, that is, if $\widetilde X$ is any set of points differing only slightly from $X$, there exists a polynomial set $\widetilde B$ structurally similar to $B$, which is a basis of the perturbed ideal $ I(\widetilde X)$.",Mathematics
"Let $\frak{m}$ be a Levi factor of a proper parabolic subalgebra $\frak{q}$ of a complex semisimple Lie algebra $\frak{g}$. Let $\frak{t} = cent \frak{m}$. A nonzero element $\nu \in \frak{t}^*$ is called a $\frak {t}$-root if the corresponding adjoint weight space $\frak{g}_{nu}$ is not zero. If $\nu$ is a $\frak{t}$-root, some time ago we proved that $\frak{g}_{\nu}$ is $ad \frak{m}$ irreducible. Based on this result we develop in the present paper a theory of $\frak{t}$-roots which replicates much of the structure of classical root theory (case where $\frak{t}$ is a Cartan subalgebra). The results are applied to obtain new reults about the structure of the nilradical $\frak{n}$ of $\frak{q}$. Also applications in the case where $dim \frak{t}=1$ are used in Borel-de Siebenthal theory to determine irreducibility theorems for certain equal rank subalgebras of $\frak{g}$. In fact the irreducibility results readily yield a proof of the main assertions of the Borel-de Siebenthal theory.",Mathematics
"Cayley cones in the octonions $\mathbb{O}$ that are ruled by oriented 2-planes are equivalent to pseudoholomorphic curves in the Grassmannian of oriented 2-planes G(2,8). The well known twistor fibration $G(2,8) -> S^6$ is used to prove the existence of immersed higher-genus pseudoholomorphic curves in $\gro$. Equivalently, this produces Cayley cones whose links are $S^1$-bundles over genus-$g$ Riemann surfaces. When the degree of an immersed pseudoholomorphic curve is large enough, the corresponding 2-ruled Cayley cone is the asymptotic cone of a non-conical 2-ruled Cayley 4-fold.",Mathematics
"The fundamental characteristics of soliton and chaos in nonlinear equation are completely different. But all nonlinear equations with a soliton solution may derive chaos. While only some equations with a chaos solution have a soliton. The conditions of the two solutions are different. When some parameters are certain constants, the soliton is derived; while these parameters vary in a certain region, the bifurcation-chaos appears. It connects a chaotic control probably. The double solutions correspond possibly to the wave-particle duality in quantum theory, and connect the double solution theory of the nonlinear wave mechanics. Some nonlinear equations possess soliton and chaos, whose new meanings are discussed briefly in mathematics, physics and particle theory.",Mathematics
"We study the spectral sequence associated to the filtration by powers of the augmentation ideal on the (twisted) equivariant chain complex of the universal cover of a connected CW-complex X. In the process, we identify the d^1 differential in terms of the coalgebra structure of H_*(X,\k), and the \k\pi_1(X)-module structure on the twisting coefficients. In particular, this recovers in dual form a result of Reznikov, on the mod p cohomology of cyclic p-covers of aspherical complexes. This approach provides information on the homology of all Galois covers of X. It also yields computable upper bounds on the ranks of the cohomology groups of X, with coefficients in a prime-power order, rank one local system. When X admits a minimal cell decomposition, we relate the linearization of the equivariant cochain complex of the universal abelian cover to the Aomoto complex, arising from the cup-product structure of H^*(X,\k), thereby generalizing a result of Cohen and Orlik.",Mathematics
"We introduce a renormalization procedure which allows us to study in a unified and concise way different properties of the irrational rotations on the unit circle $\beta \mapsto \set{\alpha+\beta}$, $\alpha \in \R\setminus \Q$. In particular we obtain sharp results for the diffusion of the walk on $\Z$ generated by the location of points of the sequence $\{n\alpha +\beta\}$ on a binary partition of the unit interval. Finally we give some applications of our method.",Mathematics
"Suppose $k$ is a field of characteristic 2, and $n,m\geq 4$ powers of 2. Then the $A_\infty$-structure of the group cohomology algebras $H^*(C_n,k)$ and $H^*(C_m,k)$ are well known. We give results characterizing an $A_\infty$-structure on $H^*(C_n\times C_m,k)$ including limits on non-vanishing low-arity operations and an infinite family of non-vanishing higher operations.",Mathematics
"This paper studies characteristic exponents of flows in relation with the dynamics of flows on flag bundles. The starting point is a flow on a principal bundle with semi-simple group $G$. Projection against the Iwasawa decomposition $G = KAN$ defines an additive cocycle over the flow with values in $\frak{a} = \log A$. Its Lyapunov exponents (limits along trajectories) and Morse exponents (limits along chains) are studied. It is proved a symmetric property of these spectral sets, namely invariance under the Weyl group. It is proved also that these sets are located in certain Weyl chambers, defined from the dynamics on the associated flag bundles. As a special case linear flows on vector bundles are considered.",Mathematics
In the paper we describe basin of attraction and the Siegel discs of the $p$-adic dynamical system $f(x)=x^{2n+1}+ax^{n+1}$ over complex $p$-adic field.,Mathematics
"It is well known that complete prior ignorance is not compatible with learning, at least in a coherent theory of (epistemic) uncertainty. What is less widely known, is that there is a state similar to full ignorance, that Walley calls near-ignorance, that permits learning to take place. In this paper we provide new and substantial evidence that also near-ignorance cannot be really regarded as a way out of the problem of starting statistical inference in conditions of very weak beliefs. The key to this result is focusing on a setting characterized by a variable of interest that is latent. We argue that such a setting is by far the most common case in practice, and we show, for the case of categorical latent variables (and general manifest variables) that there is a sufficient condition that, if satisfied, prevents learning to take place under prior near-ignorance. This condition is shown to be easily satisfied in the most common statistical problems.",Mathematics
"A survey is given of results about coherence for categories with finite products and coproducts. For these results, which were published previously by the authors in several places, some formulations and proofs are here corrected, and matters are updated. The categories investigated in this paper formalize equality of proofs in classical and intuitionistic conjunctive-disjunctive logic without distribution of conjunction over disjunction.",Mathematics
"We consider the problem of unique identification of dielectric coefficients for gratings and sound speeds for wave guides from scattering data. We prove that the ""propagating modes"" given for all frequencies uniquely determine these coefficients. The gratings may contain conductors as well as dielectrics and the boundaries of the conductors are also determined by the propagating modes.",Mathematics
"A finite group $G$ is of central type (in the non-classical sense) if it admits a non-degenerate cohomology class $[c]\in H^2(G,\C^*)$ ($G$ acts trivially on $\C^*$). Groups of central type play a fundamental role in the classification of semisimple triangular complex Hopf algebras and can be determined by their representation theoretical properties.   Suppose that a finite group $Q$ acts on an abelian group $A$ so that there exists a bijective 1-cocycle $\pi\in Z^1(Q,\ach)$, where $\ach=\rm{Hom}(A,\C^*)$ is endowed with the diagonal $Q$-action. Under this assumption, Etingof and Gelaki gave an explicit formula for a non-degenerate 2-cocycle in $Z^2(G,\C^*)$, where $G:=A\rtimes Q$. Hence, the semidirect product $G$ is of central type.   In this paper we present a more general correspondence between bijective and non-degenerate cohomology classes. In particular, given a bijective class $[\pi]\in H^1(Q,\ach)$ as above, we construct non-degenerate classes $[c_{\pi}]\in H^2(G,\C^*)$ for certain extensions $1\to A\to G\to Q\to 1$ which are not necessarily split. We thus strictly extend the above family of central type groups.",Mathematics
The class of the Riemannian almost product manifolds with nonintegrable structure is considered. Some identities for curvature tensor as certain invariant tensors and quantities are obtained.,Mathematics
"We extend the theory of separately holomorphic mappings between complex analytic spaces. Our method is based on Poletsky theory of discs, Rosay Theorem on holomorphic discs and our recent joint-work with Pflug on cross theorems in dimension 1. It also relies on our new technique of conformal mappings and a generalization of Siciak's relative extremal function.   Our approach illustrates the unified character: ``From local informations to global extensions"". Moreover, it avoids systematically the use of the classical method of doubly orthogonal bases of Bergman type.",Mathematics
Sequences whose terms are equal to the number of functions with specified properties are considered. Properties are based on the notion of derangements in a more general sense. Several sequences which generalize the standard notion of derangements are thus obtained. These sequences generate a number of integer sequences from the well-known Sloane's encyclopedia.,Mathematics
"Maximal lattice free bodies are maximal polytopes without interior integral points. Scarf initiated the study of maximal lattice free bodies relative to the facet normals in a fixed matrix. In this paper we give an efficient algorithm for computing the maximal lattice free bodies of an integral matrix A. An important ingredient is a test set for a certain integer program associated with A. This test set may be computed using algebraic methods. As an application we generalize the Scarf-Shallcross algorithm for the three-dimensional Frobenius problem to arbitrary dimension. In this context our method is inspired by the novel algorithm by Einstein, Lichtblau, Strzebonski and Wagon and the Groebner basis approach by Roune.",Mathematics
"An algebraic transformation of the DeTemple-Wang half-integer approximation to the harmonic series produces the general formula and error estimate for the Ramanujan expansion for the nth harmonic number into negative powers of the nth triangular number. We also discuss the history of the Ramanujan expansion for the nth harmonic number as well as sharp estimates of its accuracy, with complete proofs, and we compare it with other approximative formulas.",Mathematics
"For a function g(w) analytic and univalent in {w:1<|w|<\infty} with a simple pole at \infty and a continuous extension to {w:|w|\geq 1}, we consider the Faber polynomials F_n(z), n=0,1,2,..., associated to g(w) via their generating function g'(w)/(g(w)-z)=\sum_{n=0}^\infty F_n(z)w^{-(n+1)}. Assuming that g(w) maps the unit circle T onto a piecewise analytic curve L whose exterior domain has no outward-pointing cusps, and under an additional assumption concerning the ""Lehman expansion"" of g(w) about those points of T mapped onto corners of L, we obtain asymptotic formulas for F_n(z) that yield fine results on the location, limiting distribution and accumulation points of the zeros of the Faber polynomials. The asymptotic formulas are shown to hold uniformly and the exact rate of decay of the error terms involved is provided.",Mathematics
"In this short note we will provide a new and shorter proof of the following exotic shuffle relation of multiple zeta values:   $$\zeta(\{2\}^m \sha\{3,1\}^n)={2n+m\choose m}   \frac{\pi^{4n+2m}}{(2n+1)\cdot (4n+2m+1)!}.$$ This was proved by Zagier when n=0, by Broadhurst when $m=0$, and by Borwein, Bradley, and Broadhurst when m=1. In general this was proved by Bowman and Bradley in \emph{The algebra and combinatorics of shuffles and multiple zeta values}, J. of Combinatorial Theory, Series A, Vol. \textbf{97} (1)(2002), 43--63. Our idea in the general case is to use the method of Borwein et al. to reduce the above general relation to some families of combinatorial identities which can be verified by WZ-method.",Mathematics
"Combinatorics on multisets is used to deduce new upper and lower bounds on the number of numerical semigroups of each given genus, significantly improving existing ones. In particular, it is proved that the number $n_g$ of numerical semigroups of genus $g$ satisfies $2F_{g}\leq n_g\leq 1+3\cdot 2^{g-3}$, where $F_g$ denotes the $g$th Fibonacci number.",Mathematics
"In this paper we establish the local and global well-posedness of the real valued fifth order Kadomstev-Petviashvili I equation in the anisotropic Sobolev spaces with nonnegative indices. In particular, our local well-posedness improves Saut-Tzvetkov's one and our global well-posedness gives an affirmative answer to Saut-Tzvetkov's $L^2$-data conjecture.",Mathematics
"We determine the abelianization of the symmetric mapping class group of a double unbranched cover using the Riemann theta constant, Schottky theta constant, and the theta multiplier. We also give lower bounds of the abelianizations of some finite index subgroups of the mapping class group.",Mathematics
"Higher order normalizations are performed in the generalized photogravitational restricted three body problem with Poynting-Robertson drag. In this problem we have taken bigger primary as a source of radiation and smaller primary as an oblate spheroid. Whittaker method is used to transform the second order part of the Hamiltonian into the normal form. We have also performed Birkhoff's normalization of the Hamiltonian. For this we have tilized Henrard's method and expanded the coordinates of the infinitesimal body in double D'Alembert series. We have found the values of first and second order components. They are affected by radiation pressure, oblateness and P-R drag. Finally we obtained the third order part of the Hamiltonian zero.   Keywords:Higher Order Normalization, Generalized Photogravitational, RTBP,P-R drag",Mathematics
"We consider the generic regularized optimization problem $\hat{\mathsf{\beta}}(\lambda)=\arg \min_{\beta}L({\sf{y}},X{\sf{\beta}})+\lambda J({\sf{\beta}})$. Efron, Hastie, Johnstone and Tibshirani [Ann. Statist. 32 (2004) 407--499] have shown that for the LASSO--that is, if $L$ is squared error loss and $J(\beta)=\|\beta\|_1$ is the $\ell_1$ norm of $\beta$--the optimal coefficient path is piecewise linear, that is, $\partial \hat{\beta}(\lambda)/\partial \lambda$ is piecewise constant. We derive a general characterization of the properties of (loss $L$, penalty $J$) pairs which give piecewise linear coefficient paths. Such pairs allow for efficient generation of the full regularized coefficient paths. We investigate the nature of efficient path following algorithms which arise. We use our results to suggest robust versions of the LASSO for regression and classification, and to develop new, efficient algorithms for existing problems in the literature, including Mammen and van de Geer's locally adaptive regression splines.",Mathematics
We consider Laplacians acting on sections of homogeneous vector bundles over symmetric spaces. By using an integral representation of the heat semi-group we find a formal solution for the heat kernel diagonal that gives a generating function for the whole sequence of heat invariants. We argue that the obtained formal solution correctly reproduces the exact heat kernel diagonal after a suitable regularization and analytical continuation.,Mathematics
"The main goal of this paper is to present a new algorithm bounding the regularity and ``alpha'' (the lowest degree of existing hypersurface) of a linear system of hypersurfaces (in $\mathbb P^n$) passing through multiple points in general position. To do the above we formulate and prove new theorem, which allows to show non-specialty of linear system by splitting it into non-special (and simpler) systems. As a result we give new bounds for multiple point Seshadri constants on $\PP^2$.",Mathematics
"It is shown that the map from the Jacobian of the spectral curve to the moduli of stable bundles of rank 2 is generically simply branched along an irreducible divisor. This observation falsifies the key step in the ""abelianization of the SU(2) WZW connection"" presented in a recent paper [Yoshida, Annals 2006]",Mathematics
"We use heat kernels or eigenfunctions of the Laplacian to construct local coordinates on large classes of Euclidean domains and Riemannian manifolds (not necessarily smooth, e.g. with $\mathcal{C}^\alpha$ metric). These coordinates are bi-Lipschitz on embedded balls of the domain or manifold, with distortion constants that depend only on natural geometric properties of the domain or manifold. The proof of these results relies on estimates, from above and below, for the heat kernel and its gradient, as well as for the eigenfunctions of the Laplacian and their gradient. These estimates hold in the non-smooth category, and are stable with respect to perturbations within this category. Finally, these coordinate systems are intrinsic and efficiently computable, and are of value in applications.",Mathematics
"We consider a regular indefinite Sturm-Liouville problem with two self-adjoint boundary conditions, one being affinely dependent on the eigenparameter. We give sufficient conditions under which a basis of each root subspace for this Sturm-Liouville problem can be selected so that the union of all these bases constitutes a Riesz basis of a corresponding weighted Hilbert space.",Mathematics
"We survey the results in Nane (E. Nane, Higher order PDE's and iterated processes, Trans. American Math. Soc. (to appear)) and Baeumer, Meerschaert, and Nane (B. Baeumer, M.M. Meerschaert and E. Nane, Brownian subordinators and fractional Cauchy problems: Submitted (2007)) which deal with PDE connection of some iterated processes, and obtain a new probabilistic proof of the equivalence of the higher order PDE's and fractional in time PDE's.",Mathematics
This article is devoted to a Log improvement of Prodi-Serrin criterion for global regularity to solutions to Navier-Stokes equations in dimension 3. It is shown that the global regualrity holds under the condition that |u|^5/ log (1+|u|) is integrable in space time variables.,Mathematics
"In this paper we refine a version of bivariant $K$-theory developed by Cuntz to define symmetric spectra representing the $KK$-theory of $C^\ast$-categories and discrete groupoid $C^\ast$-algebras. In both cases, the Kasparov product can be expressed as a smash product of spectra.",Mathematics
"We study conchoids to algebraic curve from the perspective of algebraic geometry, analyzing their main algebraic properties. We introduce the formal definition of conchoid of an algebraic curve by means of incidence diagrams. We prove that, with the exception of a circle centered at the focus and taking $d$ as its radius, the conchoid is an algebraic curve having at most two irreducible components. In addition, we introduce the notions of special and simple components of a conchoid. Moreover we state that, with the exception of lines passing through the focus, the conchoid always has at least one simple component and that, for almost every distance, all the components of the conchoid are simple. We state that, in the reducible case, simple conchoid components are birationally equivalent to the initial curve, and we show how special components can be used to decide whether a given algebraic curve is the conchoid of another curve.",Mathematics
"In interval censored models with current status observations, the variables are indicators of the presence of individuals on observation intervals and covariates. When several individuals share the same observation interval, a simple procedure provides new estimators for the distribution of the observation times and their intensity, in a closed form. They are $n^{1/2}$-consistent for piece-wise constant covariates. Estimators of the sample-sizes are deduced and asymptotic $\chi^2$ tests for independence of the observations on consecutive intervals and for independence between consecutive classes for the observed individuals are proposed.",Mathematics
"In this paper we study a class of backward stochastic differential equations (BSDEs) of the form dY(t)= -AY(t)dt -f_0(t,Y(t))dt -f_1(t,Y(t),Z(t))dt + Z(t)dW(t) on the interval [0,T], with given final condition at time T, in an infinite dimensional Hilbert space H. The unbounded operator A is sectorial and dissipative and the nonlinearity f_0(t,y) is dissipative and defined for y only taking values in a subspace of H. A typical example is provided by the so-called polynomial nonlinearities. Applications are given to stochastic partial differential equations and spin systems.",Mathematics
"This is an introductory document surveying several results in polynomial approximation, known as the Bramble-Hilbert lemma.",Mathematics
"We construct finitely generated groups with strong fixed point properties. Let $\mathcal{X}_{ac}$ be the class of Hausdorff spaces of finite covering dimension which are mod-$p$ acyclic for at least one prime $p$. We produce the first examples of infinite finitely generated groups $Q$ with the property that for any action of $Q$ on any $X\in \mathcal{X}_{ac}$, there is a global fixed point. Moreover, $Q$ may be chosen to be simple and to have Kazhdan's property (T). We construct a finitely presented infinite group $P$ that admits no non-trivial action by diffeomorphisms on any smooth manifold in $\mathcal{X}_{ac}$. In building $Q$, we exhibit new families of hyperbolic groups: for each $n\geq 1$ and each prime $p$, we construct a non-elementary hyperbolic group $G_{n,p}$ which has a generating set of size $n+2$, any proper subset of which generates a finite $p$-group.",Mathematics
"We survey some known results about operator semigroup generated by operator matrices with diagonal or coupled domain. These abstract results are applied to the characterization of well-/ill-posedness for a class of evolution equations with dynamic boundary conditions on domains or metric graphs. In particular, our ill-posedness results on the heat equation with general Wentzell-type boundary conditions complement those previously obtained by, among others, Bandle-von Below-Reichel and Vitillaro-V\'azquez.",Mathematics
We define the concept of weighted lattice polynomial functions as lattice polynomial functions constructed from both variables and parameters. We provide equivalent forms of these functions in an arbitrary bounded distributive lattice. We also show that these functions include the class of discrete Sugeno integrals and that they are characterized by a median based decomposition formula.,Mathematics
"In this paper we study the integral of the supremum process of standard Brownian motion. We present an explicit formula for the moments of the integral (or area) A(T), covered by the process in the time interval [0,T]. The Laplace transform of A(T) follows as a consequence. The main proof involves a double Laplace transform of A(T) and is based on excursion theory and local time for Brownian motion.",Mathematics
"This paper is devoted to the well-posedness for dissipative KdV equations $u_t+u_{xxx}+|D_x|^{2\alpha}u+uu_x=0$, $0<\alpha\leq 1$. An optimal bilinear estimate is obtained in Bourgain's type spaces, which provides global well-posedness in $H^s(\R)$, $s>-3/4$ for $\alpha\leq1/2$ and $s>-3/(5-2\alpha)$ for $\alpha>1/2$.",Mathematics
"We establish elements of a new approch to ellipticity and parametrices within operator algebras on a manifold with higher singularities, only based on some general axiomatic requirements on parameter-dependent operators in suitable scales of spaces. The idea is to model an iterative process with new generations of parameter-dependent operator theories, together with new scales of spaces that satisfy analogous requirements as the original ones, now on a corresponding higher level.   The ""full"" calculus is voluminous; so we content ourselves here with some typical aspects such as symbols in terms of order reducing families, classes of relevant examples, and operators near a corner point.",Mathematics
We establish Bernstein Theorems for Lagrangian graphs which are Hamiltonian minimal or have conformal Maslov form. Some known results of minimal (Lagrangian) submanifolds are generalized.,Mathematics
"This is a concise introduction to Fomin-Zelevinsky's cluster algebras and their links with the representation theory of quivers in the acyclic case. We review the definition of cluster algebras (geometric, without coefficients), construct the cluster category and present the bijection between cluster variables and rigid indecomposable objects of the cluster category.",Mathematics
We prove divisorial canonicity of Fano double hypersurfaces of general position.,Mathematics
An affine Hecke algebras can be realized as an equivariant K-group of the corresponding Steinberg variety. This gives rise naturally to some two-sided ideals of the affine Hecke algebra by means of the closures of nilpotent orbits of the corresponding Lie algebra. In this paper we will show that the two-sided ideals are in fact the two-sided ideals of the affine Hecke algebra defined through two-sided cells of the corresponding affine Weyl group after the two-sided ideals are tensored by rational numbers field. This proves a weak form of a conjecture of Ginzburg proposed in 1987.,Mathematics
"A new characterization of Hamiltonian graphs using f-cutset matrix is proposed. Based on this new characterization, a new exact polynomial time algorithm for the traveling salesman problem (TSP) is developed. We then define the so-called ordered weighted adjacency list for given weighted complete graph and proceed to the paper's main result, namely, the exact algorithm based on the utilization of the ordered weighted adjacency list and the simple properties that any path or circuit must satisfy. This algorithm performs checking of sub-lists, containing (p-1) entries (edge pairs) for paths and p entries (edge pairs) for circuits, chosen from ordered adjacency list in a well defined sequence to determine exactly the shortest Hamiltonian path and shortest Hamiltonian circuit in a weighted complete graph of p vertices. The procedure has intrinsic advantage of landing on the desired solution in quickest possible time and even in worst case in polynomial time. A new characterization of the shortest Hamiltonian tour for a weighted complete graph satisfying triangle inequality (i.e. for tours passing through every city on a realistic map of cities where cities can be taken as points on a Euclidean plane) is also proposed. Finally, we propose a classical algorithm for unstructured search, three new quantum algorithms for unstructured search, which exponentially speed up the searching ability in the unstructured database, and one quantum algorithm for solving a K-SAT problem and indicate its effect on traveling salesman problem and other NP-complete problems.",Mathematics
"We prove global well-posedness for the defocusing cubic wave equation with data in $H^{s} \times H^{s-1}$, $1>s>{13/18}$. The main task is to estimate the variation of an almost conserved quantity on an arbitrary long time interval. We divide it into subintervals. On each of these subintervals we write the solution as the sum of its linear part adapted to the subinterval and its corresponding npnlinear part. Some terms resulting from this decomposition have a controlled global variation and other terms have a slow local variation.",Mathematics
"In this paper we extend a result of Hirata-Kohno, Laishram, Shorey and Tijdeman on the Diophantine equation $n(n+d)...(n+(k-1)d)=by^2,$ where $n,d,k\geq 2$ and $y$ are positive integers such that $\gcd(n,d)=1.$",Mathematics
"We establish rigorously convergence of a semi-discrete upwind scheme for the nonlinear variational wave equation $u_{tt} - c(u)(c(u) u_x)_x = 0$ with $u|_{t=0}=u_0$ and $u_t|_{t=0}=v_0$. Introducing Riemann invariants $R=u_t+c u_x$ and $S=u_t-c u_x$, the variational wave equation is equivalent to $R_t-c R_x=\tilde c (R^2-S^2)$ and $S_t+c S_x=-\tilde c (R^2-S^2)$ with $\tilde c=c'/(4c)$. An upwind scheme is defined for this system. We assume that the the speed $c$ is positive, increasing and both $c$ and its derivative are bounded away from zero and that $R|_{t=0}, S|_{t=0}\in L^1\cap L^3$ are nonpositive. The numerical scheme is illustrated on several examples.",Mathematics
"Bounds for the maximal degree of certain Gr\""obner bases of simplicial toric ideals are given. These bounds are close to the bound stated in Eisenbud-Goto's Conjecture on the Castelnuovo-Mumford regularity.",Mathematics
We describe an expansion of the solution of the wave equation in the De Sitter - Schwarzschild metric in terms of resonances. The main term in the expansion is due to a zero resonance. The error term decays polynomially if we permit a logarithmic derivative loss in the angular directions and exponentially if we permit an small derivative loss in the angular directions.,Mathematics
"Orbital and asymptotic stability for 1-soliton solutions to the Toda lattice equations as well as small solitary waves to the FPU lattice equations are established in the energy space. Unlike analogous Hamiltonian PDEs, the lattice equations do not conserve momentum. Furthermore, the Toda lattice equation is a bidirectional model that does not fit in with existing theory for Hamiltonian system by Grillakis, Shatah and Strauss.   To prove stability of 1-soliton solutions, we split a solution around a 1-soliton into a small solution that moves more slowly than the main solitary wave, and an exponentially localized part. We apply a decay estimate for solutions to a linearized Toda equation which has been recently proved by Mizumachi and Pego to estimate the localized part. We improve the asymptotic stability results for FPU lattices in a weighted space obtained by Friesecke and Pego.",Mathematics
"We complete the classification of Hopf algebras of dimension 16 over an algebraically closed field of characteristic zero. We show that a non-semisimple Hopf algebra of dimension 16, has either the Chevalley property or its dual is pointed.",Mathematics
"We explain how, under some hypotheses, one can construct a sequence of finite dimensional $kG$-modules that lie in certain prescribed additive subcategories, but whose direct limits do not. We use these to show that many of the triangulated quotients of $\Mod$ are not generated, as triangulated categories, by the corresponding quotient of $\mod$ considered as a full subcategory.",Mathematics
"We study reduced-order models of three-dimensional perturbations in linearized channel flow using balanced proper orthogonal decomposition (BPOD). The models are obtained from three-dimensional simulations in physical space as opposed to the traditional single-wavenumber approach, and are therefore better able to capture the effects of localized disturbances or localized actuators. In order to assess the performance of the models, we consider the impulse response and frequency response, and variation of the Reynolds number as a model parameter. We show that the BPOD procedure yields models that capture the transient growth well at a low order, whereas standard POD does not capture the growth unless a considerably larger number of modes is included, and even then can be inaccurate. In the case of a localized actuator, we show that POD modes which are not energetically significant can be very important for capturing the energy growth. In addition, a comparison of the subspaces resulting from the two methods suggests that the use of a non-orthogonal projection with adjoint modes is most likely the main reason for the superior performance of BPOD. We also demonstrate that for single-wavenumber perturbations, low-order BPOD models reproduce the dominant eigenvalues of the full system better than POD models of the same order. These features indicate that the simple, yet accurate BPOD models are a good candidate for developing model-based controllers for channel flow.",Mathematics
"We consider some special classes of L\'evy processes with no gaussian component whose L\'evy measure is of the type $\pi(dx)=e^{\gamma x}\nu(e^x-1) dx$, where $\nu$ is the density of the stable L\'evy measure and $\gamma$ is a positive parameter which depends on its characteristics. These processes were introduced in \cite{CC} as the underlying L\'evy processes in the Lamperti representation of conditioned stable L\'evy processes. In this paper, we compute explicitly the law of these L\'evy processes at their first exit time from a finite or semi-finite interval, the law of their exponential functional and the first hitting time probability of a pair of points.",Mathematics
"Minimum distance diagrams are a way to encode the diameter and routing information of multi-loop networks. For the widely studied case of double-loop networks, it is known that each network has at most two such diagrams and that they have a very definite form ""L-shape''.   In contrast, in this paper we show that there are triple-loop networks with an arbitrarily big number of associated minimum distance diagrams. For doing this, we build-up on the relations between minimum distance diagrams and monomial ideals.",Mathematics
"Let $A_p(\C)$ be the space of entire functions such that $| f(z)|\le Ae^{Bp(z)}$ for some $A,B>0$ and let $V$ be a discrete sequence of complex numbers which is not a uniqueness set for $A_p(\C)$. We use $L^2$ estimates for the $\bar\partial$ equation to charaterize the trace of $A_p(\C)$ on $V$.",Mathematics
"In the RSA cryptosystem integers of the form n=p.q with p and q primes of comparable size (`RSA-integers') play an important role. It is a folklore result of cryptographers that C_r(x), the number of integers n<=x that are of the form n=pq with p and q primes such that p<q<rp, is for fixed r>1 asymptotically equal to c_r*x*log^{-2}x for some constant c_r>0. Here we prove this and show that c_r=2log r.",Mathematics
"Let f: X -> Y be a smooth family of canonically polarized complex varieties over a smooth base. Generalizing the classical Shafarevich hyperbolicity conjecture, Viehweg conjectured that Y is necessarily of log general type if the family has maximal variation. A somewhat stronger and more precise version of Viehweg's conjecture was shown by the authors in arXiv:math/0511378 in the case where Y is a quasi-projective surface. Assuming that the minimal model program holds, this very short paper proves the same result for projective base manifolds Y of arbitrary dimension.",Mathematics
"There are characteristic classes that are the obstructions to the vanishing of the differentials in the Lyndon-Hochischild-Serre spectral sequence of an extension of an integral lattice L by a group G. These characteristic classes exist in a given page of the spectral sequence provided the differentials in the previous pages are all zero. When L decomposes into a sum of G-sublattices, we show that there are defining relations between the characteristic classes of L and the characteristic classes of its summands.",Mathematics
"Let omega(n) be the number of distinct prime factors dividing n and m > n natural numbers. We calculate a formula showing which prime numbers in which intervals divide a given binomial coefficient. From this formula we get an identity omega(binom(nk)(mk))=sum_i (pi(k/b(i))- pi(k/a(i))) + O(sqrt(k)). Erdoes mentioned that omega(binom(nk)(mk))= log n^n/(m^m (n-m)^(n-m)) k/log k + o(k/log k).   As an application of the above identities, we conclude some well-known facts about the distribution of the primes and deduce for all natural numbers k an expression (also well-known) log k = sum_i a_k(i) which generalizes log 2 = sum_i^(infty) (-1)^(j+1) / j.",Mathematics
"We define new symbol classes for pseudodifferntial operators and investigate their pseudodifferential calculus. The symbol classes are parametrized by commutative convolution algebras. To every solid convolution algebra over a lattice we associate a symbol class. Then every operator with such a symbol is almost diagonal with respect to special wave packets (coherent states or Gabor frames), and the rate of almost diagonalization is described precisely by the underlying convolution algebra. Furthermore, the corresponding class of pseudodifferential operators is a Banach algebra of bounded operators on $L^2 $. If a version of Wiener's lemma holds for the underlying convolution algebra, then the algebra of pseudodifferential operators is closed under inversion. The theory contains as a special case the fundamental results about Sj\""ostrand's class and yields a new proof of a theorem of Beals about the H\""ormander class of order 0.",Mathematics
"We give an explicit formula (i.e., a formal stationary phase formula) for the local Fourier-Laplace transform of a formal germ of meromorphic connection of one complex variable with a possibly irregular singularity. This is a complex analogue of the formulas in the preprint math/0702436v1.",Mathematics
We prove a comparison theorem for the compact surfaces with negative Euler characteristic via the Ricci flow.,Mathematics
"We give a number of new characterizations of the Jiang-Su algebra Z, both intrinsic and extrinsic, in terms of C*-algebraic, dynamical, topological and K-theoretic conditions. Along the way we study divisibility properties of C*-algebras, we give a precise characterization of those unital C*-algebras of stable rank one that admit a unital embedding of the dimension-drop C*-algebra Z_{n,n+1}, and we prove a cancellation theorem for the Cuntz semigroup of C*-algebras of stable rank one.",Mathematics
"Nous presentons diverses applications des fibres vectoriels aux equations aux q-differences, dans la lignee de la correspondance de Weil.   (We present some applications of vector bundles to $q$-difference equtions, in continuation of Weil's correspondance.)",Mathematics
"In this paper, we propose a geometric integrator for nonholonomic mechanical systems. It can be applied to discrete Lagrangian systems specified through a discrete Lagrangian defined on QxQ, where Q is the configuration manifold, and a (generally nonintegrable) distribution in TQ. In the proposed method, a discretization of the constraints is not required. We show that the method preserves the discrete nonholonomic momentum map, and also that the nonholonomic constraints are preserved in average. We study in particular the case where Q has a Lie group structure and the discrete Lagrangian and/or nonholonomic constraints have various invariance properties, and show that the method is also energy-preserving in some important cases.",Mathematics
"We study the spectral properties of certain non-self-adjoint matrices associated with large directed graphs. Asymptotically the eigenvalues converge to certain curves, apart from a finite number that have limits not on these curves.",Mathematics
"We enumerate all spaces obtained by gluing in pairs the faces of the octahedron in an orientation-reversing fashion. Whenever such a gluing gives rise to non-manifold points, we remove small open neighbourhoods of these points, so we actually deal with three-dimensional manifolds with (possibly empty) boundary.   There are 298 combinatorially inequivalent gluing patterns, and we show that they define 191 distinct manifolds, of which 132 are hyperbolic and 59 are not. All the 132 hyperbolic manifolds were already considered in different contexts by other authors, and we provide here their known ``names'' together with their main invariants. We also give the connected sum and JSJ decompositions for the 59 non-hyperbolic examples.   Our arguments make use of tools coming from hyperbolic geometry, together with quantum invariants and more classical techniques based on essential surfaces. Many (but not all) proofs were carried out by computer, but they do not involve issues of numerical accuracy.",Mathematics
"We generalize the Wiener-Hopf factorization of Laurent series to more general commutative coefficient rings, and we give explicit formulas for the decomposition. We emphasize the algebraic nature of this factorization.",Mathematics
"In 1987, Shapiro shew that composition operator induced by symbol $\phi$ is compact on the Lipschltz space if and only if the infinity norm of $\phi$ is less than 1 by a spectral-theoretic argument, where $\phi$ is a holomorphic self-map of the unit disk. In this paper, we shall generalize Shapiro's result to the $n$-dimensional case.",Mathematics
"Consider a compound Poisson process with jump measure $\nu$ supported by finitely many positive integers. We propose a method for estimating $\nu$ from a single, equidistantly sampled trajectory and develop associated statistical procedures. The problem is motivated by the question whether nerve cells in the brain exhibit higher-order interactions in their firing patterns. According to the neuronal assembly hypothesis (Hebb [13]), synchronization of action potentials across neurons of different groups is considered a signature of assembly activity, but it was found notoriously difficult to demonstrate it in recordings of neuronal activity. Our approach based on a compound Poisson model allows to detect the presence of joint spike events of any order using only population spike count samples, thus bypassing both the ``curse of dimensionality'' and the need to isolate single-neuron spike trains in population signals.",Mathematics
"We consider Kac's random walk on $n$-dimensional rotation matrices, where each step is a random rotation in the plane generated by two randomly picked coordinates. We show that this process converges to the Haar measure on $\mathit{SO}(n)$ in the $L^2$ transportation cost (Wasserstein) metric in $O(n^2\ln n)$ steps. We also prove that our bound is at most a $O(\ln n)$ factor away from optimal. Previous bounds, due to Diaconis/Saloff-Coste and Pak/Sidenko, had extra powers of $n$ and held only for $L^1$ transportation cost. Our proof method includes a general result of independent interest, akin to the path coupling method of Bubley and Dyer. Suppose that $P$ is a Markov chain on a Polish length space $(M,d)$ and that for all $x,y\in M$ with $d(x,y)\ll1$ there is a coupling $(X,Y)$ of one step of $P$ from $x$ and $y$ (resp.) that contracts distances by a $(\xi+o(1))$ factor on average. Then the map $\mu\mapsto\mu P$ is $\xi$-contracting in the transportation cost metric.",Mathematics
"Given a finite collection P of convex n-polytopes in RP^n (n>1), we consider a real projective manifold M which is obtained by gluing together the polytopes in P along their facets in such a way that the union of any two adjacent polytopes sharing a common facet is convex. We prove that the real projective structure on M is (1) convex if P contains no triangular polytope, and (2) properly convex if, in addition, P contains a polytope whose dual polytope is thick. Triangular polytopes and polytopes with thick duals are defined as analogues of triangles and polygons with at least five edges, respectively.",Mathematics
"Let $x = (x_0,...,x_{n-1})$ be an n-chain, i.e., an n-tuple of non-negative integers $< n$. Consider the operator $s: x \mapsto x' = (x'_0,...,x'_{n-1})$, where x'_j represents the number of $j$'s appearing among the components of x. An n-chain x is said to be perfect if $s(x) = x$. For example, (2,1,2,0,0) is a perfect 5-chain. Analogously to the theory of perfect, amicable, and sociable numbers, one can define from the operator s the concepts of amicable pair and sociable group of chains. In this paper we give an exhaustive list of all the perfect, amicable, and sociable chains.",Mathematics
"We study statistical models, specifically transfer matrices corresponding to a multiparameter hierarchy of braid matrices of $(2n)^2\times(2n)^2$ dimensions with $2n^2$ free parameters $(n=1,2,3,...)$. The simplest, $4\times 4$ case is treated in detail. Powerful recursion relations are constructed giving the dependence on the spectral parameter $\theta$ of the eigenvalues of the transfer matrix explicitly at each level of coproduct sequence. A brief study of higher dimensional cases ($n\geq 2$) is presented pointing out features of particular interest. Spin chain Hamiltonians are also briefly presented for the hierarchy. In a long final section basic results are recapitulated with systematic analysis of their contents. Our eight vertex $4\times 4$ case is compared to standard six vertex and eight vertex models.",Mathematics
"We achieve on self-affine Sierpinski carpets the multifractal analysis of the Birkhoff averages of potentials satisfying a Dini condition. Given such a potential, the corresponding Hausdorff spectrum cannot be deduced from that of the associated Gibbs measure by a simple transformation. Indeed, these spectra are respectively obtained as the Legendre transform of two distinct concave differentiable functions that cannot be deduced from one another by a dilation and a translation. This situation is in contrast with what is observed in the familiar self-similar case. Our results are presented in the framework of almost-multiplicative functions on products of two distinct symbolic spaces and their projection on the associated self-affine carpets.",Mathematics
In this paper the absolute value or distance from the origin analogue of the classical Khintchine-Groshev theorem is established for a single linear form with a `slowly decreasing' error function.,Mathematics
In this paper we construct random conformal snowflakes with large integral means spectrum at different points. These new estimates are significant improvement over previously known lower bound of the universal spectrum. Our estimates are within 5-10 percent from the conjectured value of the universal spectrum.,Mathematics
We study projectively self-dual polygons and curves in the projective plane. Our results provide a partial answer to problem No 1994-17 in the book of Arnold's problems.,Mathematics
We extend classical results of Kostant and al. on multiplets of representations of finite-dimensional Lie algebras and on the cubic Dirac operator to the setting of affine Lie algebras and twisted affine cubic Dirac operator. We prove in this setting an analogue of Vogan's conjecture on infinitesimal characters of Harish-Chandra modules in terms of Dirac cohomology. For our calculations we use the machinery of Lie conformal and vertex algebras.,Mathematics
"We prove that hyperbolic groups are weakly amenable. This partially extends the result of Cowling and Haagerup showing that lattices in simple Lie groups of real rank one are weakly amenable. We take a combinatorial approach in the spirit of Haagerup and prove that for the word length metric d on a hyperbolic group, the Schur multipliers associated with r^d have uniformly bounded norms for 0<r<1. We then combine this with a Bozejko-Picardello type inequality to obtain weak amenability.",Mathematics
"We study some reduced free products of C*-algebras with amalgamations. We give sufficient conditions for the positive cone of the K_0 group to be the largest possible. We also give sufficient conditions for simplicity and uniqueness of trace. We use the later result to give a necessary and sufficient condition for simplicity and uniqueness of trace of the reduced C*-algebras of the Baumslag-Solitar groups BS(m,n).",Mathematics
We construct an A-infinity structure on the tensor product of two A-infinity algebras by using the simplicial decomposition of the Stasheff polytope. The key point is the construction of an operad AA-infinity based on the simplicial Stasheff polytope. The operad AA-infinity admits a coassociative diagonal and the operad A-infinity is a retract by deformation of it. We compare these constructions with analogous constructions due to Saneblidze-Umble and Markl-Shnider based on the Boardman-Vogt cubical decomposition of the Stasheff polytope.,Mathematics
"We investigate if a unital C(X)-algebra is properly infinite when all its fibres are properly infinite. We show that this question can be rephrased in several different ways, including the question if every unital properly infinite C*-algebra is K_1-injective. We provide partial answers to these questions, and we show that the general question on proper infiniteness of C(X)-algebras can be reduced to establishing proper infiniteness of a specific C([0,1])-algebra with properly infinite fibres.",Mathematics
"Let k be an algebraically closed field of characteristic >2, F=k((t)) and Mp(F) denote the metaplectic extension of Sp_{2d}(F). In this paper we propose a geometric analog of the Weil representation of Mp(F). This is a category of certain perverse sheaves on some stack, on which Mp(F) acts by functors. This construction will be used in math.RT/0701170 (and subsequent publications) for a proof of the geometric Langlands functoriality for some dual reductive pairs.",Mathematics
We prove that a Banach space X is not super-reflexive if and only if the hyperbolic infinite tree embeds metrically into X. We improve one implication of J.Bourgain's result who gave a metrical characterization of super-reflexivity in Banach spaces in terms of uniforms embeddings of the finite trees. A characterization of the linear type for Banach spaces is given using the embedding of the infinite tree equipped with a suitable metric.,Mathematics
"We give a completely explicit upper bound for integral points on (standard) affine models of hyperelliptic curves, provided we know at least one rational point and a Mordell-Weil basis of the Jacobian. We also explain a powerful refinement of the Mordell--Weil sieve which, combined with the upper bound, is capable of determining all the integral points. Our method is illustrated by determining the integral points on a two genus 2 hyperelliptic curves with Mordell--Weil Jacobian ranks of 3 and 6.",Mathematics
"Associated to each subset $J$ of the nodes $I$ of a Dynkin diagram is a triangular decomposition of the corresponding Lie algebra $\mathfrak{g}$ into three subalgebras $\widetilde{\mathfrak{g}_{J}}$ (generated by $e_{j}$, $f_{j}$ for $j\in J$ and $h_{i}$ for $i\in I$), $\mathfrak{n}^{-}_{D}$ (generated by $f_{d}$, $d\in D=I\setminus J$) and its dual $\mathfrak{n}_{D}^{+}$.   We demonstrate a quantum counterpart, generalising work of Majid and Rosso, by exhibiting analogous triangular decompositions of $U_{q}(\mathfrak{g})$ and identifying a graded braided Hopf algebra that quantizes $\mathfrak{n}_{D}^{-}$. This algebra has many similar properties to $U_{q}^{-}(\mathfrak{g})$, in many cases being a Nichols algebra and therefore completely determined by its associated braiding.",Mathematics
We show asymptotic upper and lower bounds for the greatest common divisor of N and $\sigma(N)$. We also show that there are infinitely many integers N with fairly large g.c.d. of N and $\sigma(N)$.,Mathematics
"In this work we study two problems about Assouad-Nagata dimension:   1) Is there a metric space of non zero Assouad-Nagata dimension such that all of its asymptotic cones are of Assouad-Nagata dimension zero? (Dydak and Higes)   2) Suppose $G$ is a locally finite group with a proper left invariant metric $d_G$. If $\dim_{AN}(G, d_G)>0$, is $\dim_{AN} (G, d_G)$ infinite? (Brodskiy, Dydak and Lang)   The first question is answered positively not only for general metric spaces but also for discrete groups with proper left invariant metrics.   The second question has a negative solution. We show that for each $n$ there exists a locally finite group of Assouad-Nagata dimension $n$. A generalization to countable groups of arbitrary asymptotic dimension is given",Mathematics
"We consider the problem of determining the boundary perturbations of an object from far-field electric or acoustic measurements. Assuming that the unknown object boundary is a small perturbation of a circle, we develop a linearized relation between the far-field data that result from fixed Dirichlet boundary conditions, entering as parameters, and the shape of the object, entering as variables. This relation is used to find the Fourier coefficients of the perturbation of the shape and makes use of an expansion of the Dirichlet-to-Neumann operator.",Mathematics
"We show that if P is an embedded least area (area minimizing) plane in hyperbolic 3-space whose asymptotic boundary is a simple closed curve with at least one smooth point, then P is properly embedded.",Mathematics
"This note extends Voiculescu's S-transform based analytical machinery for free multiplicative convolution to the case where the mean of the probability measures vanishes. We show that with the right interpretation of the S-transform in the case of vanishing mean, the usual formula makes perfectly good sense.",Mathematics
"In this paper we give an elementary proof of the Fundamental Theorem of Algebra for polynomials over the rational tropical semi-ring. We prove that, tropically, the rational numbers are algebraically closed. We provide a simple algorithm for factoring tropical polynomials of a single variable. A central idea is the concept of least-coefficient polynomials as representatives for classes of functionally equivalent polynomials. This idea has importance far beyond the proof of the Fundamental Theorem of Tropical Algebra.",Mathematics
"We investigate integrable second order equations of the form   F(u_{xx}, u_{xy}, u_{yy}, u_{xt}, u_{yt}, u_{tt})=0.   Familiar examples include the Boyer-Finley equation, the potential form of the dispersionless Kadomtsev-Petviashvili equation, the dispersionless Hirota equation, etc. The integrability is understood as the existence of infinitely many hydrodynamic reductions. We demonstrate that the natural equivalence group of the problem is isomorphic to Sp(6), revealing a remarkable correspondence between differential equations of the above type and hypersurfaces of the Lagrangian Grassmannian. We prove that the moduli space of integrable equations of the dispersionless Hirota type is 21-dimensional, and the action of the equivalence group Sp(6) on the moduli space has an open orbit.",Mathematics
"On a manifold of dimension at least six, let $(g,\tau)$ be a pair consisting of a K\""ahler metric g which is locally K\""ahler irreducible, and a nonconstant smooth function $\tau$. Off the zero set of $\tau$, if the metric $\hat{g}=g/\tau^2$ is a gradient Ricci soliton which has soliton function $1/\tau$, we show that $\hat{g}$ is K\""ahler with respect to another complex structure, and locally of a type first described by Koiso. Moreover, $\tau$ is a special K\""ahler-Ricci potential, a notion defined in earlier works of Derdzinski and Maschler. The result extends to dimension four with additional assumptions. We also discuss a Ricci-Hessian equation, which is a generalization of the soliton equation, and observe that the set of pairs $(g,\tau)$ satisfying a Ricci-Hessian equation is invariant, in a suitable sense, under the map $(g,\tau)\to (\hat{g},1/\tau)$.",Mathematics
"The purpose of this paper is twofold. First, we survey known results about theta dualities on moduli spaces of sheaves on curves and surfaces. Secondly, we establish new such dualities in the surface case. Among others, the case of elliptic K3 surfaces is studied in detail; we propose further conjectures which are shown to imply strange duality.",Mathematics
"We use time-frequency methods for the study of Fourier Integral operators (FIOs). In this paper we shall show that Gabor frames provide very efficient representations for a large class of FIOs. Indeed, similarly to the case of shearlets and curvelets frames, the matrix representation of a Fourier Integral Operator with respect to a Gabor frame is well-organized. This is used as a powerful tool to study the boundedness of FIOs on modulation spaces. As special cases, we recapture boundedness results on modulation spaces for pseudo-differential operators with symbols in $M^{\infty,1}$, for some unimodular Fourier multipliers and metaplectic operators.",Mathematics
We prove the modularity of minimally ramified ordinary residually reducible p-adic Galois representations of an imaginary quadratic field F under certain assumptions. We first exhibit conditions under which the residual representation is unique up to isomorphism. Then we prove the existence of deformations arising from cuspforms on GL_2(A_F) via the Galois representations constructed by Taylor et al. We establish a sufficient condition (in terms of the non-existence of certain field extensions which in many cases can be reduced to a condition on an L-value) for the universal deformation ring to be a discrete valuation ring and in that case we prove an R=T theorem. We also study reducible deformations and show that no minimal characteristic 0 reducible deformation exists.,Mathematics
"We introduce the notion of non-lc ideal sheaves. It is an analogue of the notion of multiplier ideal sheaves. We establish the restriction theorem, which seems to be the most important property of non-lc ideal sheaves.",Mathematics
"We study relatively minimal subgroups in topological groups. We find, in particular, some natural relatively minimal subgroups in unipotent groups which are defined over ""good"" rings. By ""good"" rings we mean archimedean absolute valued (not necessarily associative) division rings. Some of the classical rings which we consider besides the field of reals are the ring of quaternions and the ring of octonions. This way we generalize in part a previous result which was obtained by Dikranjan and Megrelishvili and involved the Heisenberg group.",Mathematics
"We consider a d-dimensional stochastic differential equation with additive noise and a drift coefficient which is assumed only to be a bounded Borel function. We show that, for almost all choices of the driving Brownian path, the equation has a unique solution.",Mathematics
"A complete structure theorem of Sally modules of $\fkm$-primary ideals $I$ in a Cohen-Macaulay local ring $(A, \m)$ satisfying the equality $\e_1(I)=\e_0(I)-\ell_A(A/I)+1$ is given, where $\e_0(I)$ and $\e_1(I)$ denote the first two Hilbert coefficients of $I$.",Mathematics
"The modular variety of non singular and complete hyperelliptic curves with level-two structure of genus 3 is a 5-dimensional quasi projective variety which admits several standard compactifications. The first one, X, comes from the realization of this variety as a sub-variety of the Siegel modular variety of level two and genus three .We will be to describe the equations of X in a suitable projective embedding and its Hilbert function. It will turn out that   X is normal. A further model comes from geometric invariant theory using so-called semistable degenerated point configurations in (P^1)^8 . We denote this GIT-compactification by Y. The equations of this variety in a suitable projective embedding are known. This variety also can by identified with a Baily-Borel compactified ball-quotient. We will describe these results in some detail and obtain new proofs including some finer results for them. We have a birational map between Y and X . In this paper we use the fact that there are graded algebras (closely related to algebras of modular forms) A,B such that X=proj(A) and Y=proj(B). This homomorphism rests on the theory of Thomae (19th century), in which the thetanullwerte of hyperelliptic curves have been computed. Using the explicit equations for $A,B$ we can compute the base locus of the map from Y to X.   Blowing up the base locus and the singularity of Y, we get a dominant, smooth model {\tilde Y}. We will see that {\tilde Y} is isomorphic to the compactification of families of marked projective lines (P^1,x_1,...,x_8), usually denoted by {\bar M_{0,8}}. There are several combinatorial similarities between the models X and Y. These similarities can be described best, if one uses the ball-model to describe Y.",Mathematics
"We show that an elation generalised quadrangle which has p+1 lines on each point, for some prime p, is classical or arises from a flock of a quadratic cone (i.e., is a flock quadrangle).",Mathematics
"We consider the damped wave equation \alpha u_tt + u_t = u_xx - V'(u) on the whole real line, where V is a bistable potential. This equation has travelling front solutions of the form u(x,t) = h(x-st) which describe a moving interface between two different steady states of the system, one of which being the global minimum of V. We show that, if the initial data are sufficiently close to the profile of a front for large |x|, the solution of the damped wave equation converges uniformly on R to a travelling front as t goes to plus infinity. The proof of this global stability result is inspired by a recent work of E. Risler and relies on the fact that our system has a Lyapunov function in any Galilean frame.",Mathematics
"This paper continues arXiv.org:math.AG/0609256, arXiv:0708.3991 and arXiv:0710.0162 .   Using authors's methods of 1980, 1981, some explicit finite sets of number fields containing all ground fields of arithmetic hyperbolic reflection groups in dimension at least 3 are defined, and explicit bounds of their degrees (over Q) are obtained.   Thus, now, explicit bound of degree of ground fields of arithmetic hyperbolic reflection groups is known in all dimensions. Thus, now, we can, in principle, obtain effective finite classification of arithmetic hyperbolic reflection groups in all dimensions together.",Mathematics
"In this paper, we give a quantum interpretation of the Bismut-Chern character form (the loop space lifting of the Chern character form) as well as the Chern character form associated to a complex vector bundle with connection over a smooth manifold in the framework of supersymmetric quantum field theories developed by Stolz and Teichner \cite{ST07}. We show that the Bismut-Chern character form comes up via a loop-deloop process when one goes from $1|1$D theory over a manifold down to a $0|1$D theory over its free loop space. Based on our quantum interpretation of the Bismut-Chern character form and Chern character form, we construct Chern character type maps for SUSY QFTs.",Mathematics
"Let $X_N$ be an $N\ts N$ random symmetric matrix with independent equidistributed entries. If the law $P$ of the entries has a finite second moment, it was shown by Wigner \cite{wigner} that the empirical distribution of the eigenvalues of $X_N$, once renormalized by $\sqrt{N}$, converges almost surely and in expectation to the so-called semicircular distribution as $N$ goes to infinity. In this paper we study the same question when $P$ is in the domain of attraction of an $\alpha$-stable law. We prove that if we renormalize the eigenvalues by a constant $a_N$ of order $N^{\frac{1}{\alpha}}$, the corresponding spectral distribution converges in expectation towards a law $\mu_\alpha$ which only depends on $\alpha$. We characterize $\mu_\alpha$ and study some of its properties; it is a heavy-tailed probability measure which is absolutely continuous with respect to Lebesgue measure except possibly on a compact set of capacity zero.",Mathematics
"The deformation bicomplex of a module-algebra over a bialgebra is constructed. It is then applied to study algebraic deformations in which both the module structure and the algebra structure are deformed. The cases of module-coalgebras, comodule-(co)algebras, and (co)module-bialgebras are also considered.",Mathematics
"The main result of this paper is the computation of TR^n_{\alpha}(F_p;p) for \alpha in R(S^1). These R(S^1)-graded TR-groups are the equivariant homotopy groups naturally associated to the S^1-spectrum THH(F_p), the topological Hochschild S^1-spectrum. This computation, which extends a partial result of Hesselholt and Madsen, provides the first example of the R(S^1)-graded TR-groups of a ring. These groups arise in algebraic K-theory computations, and are particularly important to the understanding of the algebraic K-theory of non-regular schemes.",Mathematics
In this paper we study the problem of adaptive estimation of a multivariate function satisfying some structural assumption. We propose a novel estimation procedure that adapts simultaneously to unknown structure and smoothness of the underlying function. The problem of structural adaptation is stated as the problem of selection from a given collection of estimators. We develop a general selection rule and establish for it global oracle inequalities under arbitrary $\rL_p$--losses. These results are applied for adaptive estimation in the additive multi--index model.,Mathematics
"We establish a phase transition for permutation classes (downsets of permutations under the permutation containment order): there is an algebraic number $\kappa$, approximately 2.20557, for which there are only countably many permutation classes of growth rate (Stanley-Wilf limit) less than $\kappa$ but uncountably many permutation classes of growth rate $\kappa$, answering a question of Klazar. We go on to completely characterize the possible sub-$\kappa$ growth rates of permutation classes, answering a question of Kaiser and Klazar. Central to our proofs are the concepts of generalized grid classes (introduced herein), partial well-order, and atomicity (also known as the joint embedding property).",Mathematics
"Divisibility monoids (resp. Garside monoids) are a natural algebraic generalization of Mazurkiewicz trace monoids (resp. spherical Artin monoids), namely monoids in which the distributivity of the underlying lattices (resp. the existence of common multiples) is kept as an hypothesis, but the relations between the generators are not supposed to necessarily be commutations (resp. be of Coxeter type). Here, we show that the quasi-center of these monoids can be studied and described similarly, and then we exhibit the intersection between the two classes of monoids.",Mathematics
"Deheuvels [J. Multivariate Anal. 11 (1981) 102--113] and Genest and R\'{e}millard [Test 13 (2004) 335--369] have shown that powerful rank tests of multivariate independence can be based on combinations of asymptotically independent Cram\'{e}r--von Mises statistics derived from a M\""{o}bius decomposition of the empirical copula process. A result on the large-sample behavior of this process under contiguous sequences of alternatives is used here to give a representation of the limiting distribution of such test statistics and to compute their relative local asymptotic efficiency. Local power curves and asymptotic relative efficiencies are compared under familiar classes of copula alternatives.",Mathematics
"We establish existence and pointwise estimates of fundamental solutions and Green's matrices for divergence form, second order strongly elliptic systems in a domain $\Omega \subseteq \mathbb{R}^n$, $n \geq 3$, under the assumption that solutions of the system satisfy De Giorgi-Nash type local H\""{o}lder continuity estimates. In particular, our results apply to perturbations of diagonal systems, and thus especially to complex perturbations of a single real equation.",Mathematics
"Given a finite set of lattice points, we compare its sumsets and lattice points in its dilated convex hulls. Both of these are known to grow as polynomials. Generally, the former are subsets of the latter. In this paper, we will see that sumsets occupy all the central lattice points in convex hulls, giving us a kind of approximation to lattice points in polytopes.",Mathematics
"Given an orientable weakly self-dual manifold X of rank two, we build a geometric realization of the Lie algebra sl(6,C) as a naturally defined algebra L of endomorphisms of the space of differential forms of X. We provide an explicit description of Serre generators in terms of natural generators of L. This construction gives a bundle on X which is related to the search for a natural Gauge theory on X. We consider this paper as a first step in the study of a rich and interesting algebraic structure.",Mathematics
"Zero-divisors (ZDs) derived by Cayley-Dickson Process (CDP) from N-dimensional hypercomplex numbers (N a power of 2, at least 4) can represent singularities and, as N approaches infinite, fractals -- and thereby,scale-free networks. Any integer greater than 8 and not a power of 2 generates a meta-fractal or ""Sky"" when it is interpreted as the ""strut constant"" (S) of an ensemble of octahedral vertex figures called ""Box-Kites"" (the fundamental building blocks of ZDs). Remarkably simple bit-manipulation rules or ""recipes"" provide tools for transforming one fractal genus into others within the context of Wolfram's Class 4 complexity.",Mathematics
We prove an analog of Siegel's theorem for integral points in the context of Drinfeld modules. The result holds for finitely generated submodules of the additive group over a function field of transcendence dimension 1.,Mathematics
"Several results of large deviations are obtained for distributions that are associated with the Poisson--Dirichlet distribution and the Ewens sampling formula when the parameter $\theta$ approaches infinity. The motivation for these results comes from a desire of understanding the exact meaning of $\theta$ going to infinity. In terms of the law of large numbers and the central limit theorem, the limiting procedure of $\theta$ going to infinity in a Poisson--Dirichlet distribution corresponds to a finite allele model where the mutation rate per individual is fixed and the number of alleles going to infinity. We call this the finite allele approximation. The first main result of this article is concerned with the relation between this finite allele approximation and the Poisson--Dirichlet distribution in terms of large deviations. Large $\theta$ can also be viewed as a limiting procedure of the effective population size going to infinity. In the second result a comparison is done between the sample size and the effective population size based on the Ewens sampling formula.",Mathematics
"We prove a convergence theorem for a sequence of super-Brownian motions moving among hard Poissonian obstacles, when the intensity of the obstacles grows to infinity but their diameters shrink to zero in an appropriate manner. The superprocesses are shown to converge in probability for the law $\mathbf{P}$ of the obstacles, and $\mathbf{P}$-almost surely for a subsequence, towards a superprocess with underlying spatial motion given by Brownian motion and (inhomogeneous) branching mechanism $\psi(u,x)$ of the form $\psi(u,x)= u^2+ \kappa(x)u$, where $\kappa(x)$ depends on the density of the obstacles. This work draws on similar questions for a single Brownian motion. In the course of the proof, we establish precise estimates for integrals of functions over the Wiener sausage, which are of independent interest.",Mathematics
"Let $k > 3$ be an integer and $p$ a prime with $p > 2k-2$. Let $f$ be a newform of weight $2k-2$ and level 1 so that $f$ is ordinary at $p$ and $\bar{\rho}_{f}$ is irreducible. Under some additional hypotheses we prove that $ord_{p}(L_{alg}(k,f)) \leq ord_{p}(# S)$ where $S$ is the Pontryagin dual of the Selmer group associated to $\rho_{f} \otimes \epsilon^{1-k}$ with $\epsilon$ the $p$-adic cyclotomic character. We accomplish this by first constructing a congruence between the Saito-Kurokawa lift of $f$ and a non-CAP Siegel cusp form. Once this congruence is established, we use Galois representations to obtain the lower bound on the Selmer group.",Mathematics
"The article discusses the interrelation between relative Cuntz-Pimsner algebras and partial isometric crossed products, and presents a procedure that reduces any given Hilbert bimodule to the ""smallest"" Hilbert bimodule yielding the same relative Cuntz-Pimsner algebra as the initial one. In the context of crossed products this reduction procedure corresponds to reduction of C*-dynamical systems.",Mathematics
"In this paper we find a closed form of the solution for the factored inhomogeneous linear equation \begin{equation*} \prod_{j=1}^{n}(\frac{\hbox{d}}{\hbox{d}t}-A_{j}) u(t) =f(t). \end{equation*} Under the hypothesis $A_{1},A_{2}, ..., A_{n}$ are infinitesimal generators of mutually commuting strongly continuous semigroups of bounded linear operators on a Banach space $X$. Here we do not assume that $A_{j}$s are distinct and we offer the computational method to get explicit solutions of certain partial differential equations.",Mathematics
The two-dimensional Navier-Stokes equations are rewritten as a system of coupled nonlinear ordinary differential equations. These equations describe the evolution of the moments of an expansion of the vorticity with respect to Hermite functions and of the centers of vorticity concentrations. We prove the convergence of this expansion and show that in the zero viscosity and zero core size limit we formally recover the Helmholtz-Kirchhoff model for the evolution of point-vortices. The present expansion systematically incorporates the effects of both viscosity and finite vortex core size. We also show that a low-order truncation of our expansion leads to the representation of the flow as a system of interacting Gaussian (i.e. Oseen) vortices which previous experimental work has shown to be an accurate approximation to many important physical flows [9].,Mathematics
"We study local and global existence and smoothing properties for the initial value problem associated to a higher order nonlinear Schr\""odinger equation with constant coefficients which appears as a model for propagation of pulse in optical fiber.",Mathematics
"Jet isomorphism theorems for conformal geometry are discussed. A new proof of the jet isomorphism theorem for odd-dimensional conformal geometry is outlined, using an ambient realization of the conformal deformation complex. An infinite order ambient lift for conformal densities in the case in which harmonic extension is obstructed is described. A jet isomorphism theorem for even dimensional conformal geometry is formulated using the inhomogeneous ambient metrics recently introduced by the author and K. Hirachi.",Mathematics
"We classify the (finite and infinite) virtually cyclic subgroups of the pure braid groups $P_{n}(RP^2)$ of the projective plane. The maximal finite subgroups of $P_{n}(RP^2)$ are isomorphic to the quaternion group of order 8 if $n=3$, and to $\Z_{4}$ if $n\geq 4$. Further, for all $n\geq 3$, up to isomorphism, the following groups are the infinite virtually cyclic subgroups of $P_{n}(RP^2)$: $\Z$, $\Z_{2} \times \Z$ and the amalgamated product $\Z_{4} \ast_{\Z_{2}} \Z_{4}$.",Mathematics
"We give a new proof of a polynomial recurrence result due to Bergelson, Furstenberg, and McCutcheon, using idempotent ultrafilters instead of IP-limits.",Mathematics
We prove the existence of a perimeter-minimizing partition of R^n into regions of unit volume. We conclude with a short tribute to the late Manuel A. Fortes.,Mathematics
This note illustrates the strategy of our paper on piecewise affine surface homeomorphisms by giving a new proof of the finite multiplicity of the maximum entropy measure of Anosov diffeomorphisms (here on surfaces). This approach avoids the explicit construction of Markov partitions and will be applied elsewhere to some non-uniformly hyperbolic diffeomorphisms.,Mathematics
"This paper is concerned with the discrete spectrum of the self-adjoint realization of the semi-classical Schr\""odinger operator with constant magnetic field and associated with the de Gennes (Fourier/Robin) boundary condition. We derive an asymptotic expansion of the number of eigenvalues below the essential spectrum (Weyl-type asymptotics). The methods of proof relies on results concerning the asymptotic behavior of the first eigenvalue obtained in a previous work [A. Kachmar, J. Math. Phys. Vol. 47 (7) 072106 (2006)].",Mathematics
"We show that a minimal counter example to the Cherlin-Zilber Algebraicity Conjecture for simple groups of finite Morley rank has Prufer 2-rank at most two. This article covers the signalizer functor theory and identifies the groups of Lie rank at least three; leaving the uniqueness case analysis to previous articles. This result signifies the end of the general methods used to handle large groups; hereafter each individual group PSL$_2$, PSL$_3$, PSp$_4$, and G$_2$ will require its own identification theorem.",Mathematics
"We consider the manifold $Fl_n(\mathbb{H})=Sp(n)/Sp(1)^n$ of all complete flags in $\mathbb{H}^n$, where $\mathbb{H}$ is the skew-field of quaternions. We study its equivariant $K$-theory rings with respect to the action of two groups: $Sp(1)^n$ and a certain canonical subgroup $T:=(S^1)^n\subset Sp(1)^n$ (a maximal torus). For the first group action we obtain a Goresky-Kottwitz-MacPherson type description. For the second one, we describe the ring $K_T(Fl_n(\mathbb{H}))$ as a subring of $K_T(Sp(n)/T)$. This ring is well known, since $Sp(n)/T$ is a complex flag variety.",Mathematics
"In this paper we investigate some consequences of the Gross/Zagier types of formulae which were introduced by Gross and Zagier, and were then generalized in various directions by Hatcher, Zhang, Kudla and several other people. Working in the classical context of central values of L-series of holomorphic forms of prime level, we deduce an exact average formula for suitable twists of such L-values, with a relation to the class number of associated imaginary quadratic fieds, thereby strengthening a result of Duke. One also obtains a stability result, as well as subconvexity (in this setting), and certian non-vanishing assertions. This article is dedicated to the memory of Serge Lang.",Mathematics
"By using a multiscale analysis, we establish quantitative versions of the Besicovitch projection theorem (almost every projection of a purely unrectifiable set in the plane of finite length has measure zero) and a standard companion result, namely that any planar set with at least two projections of measure zero is purely unrectifiable. We illustrate these results by providing an explicit (but weak) upper bound on the average projection of the $n^{th}$ generation of a product Cantor set.",Mathematics
"It is shown that in the units of augmentation one of an integral group ring $\mathbb{Z} G$ of a finite group $G$, a noncyclic subgroup of order $p^{2}$, for some odd prime $p$, exists only if such a subgroup exists in $G$. The corresponding statement for $p=2$ holds by the Brauer--Suzuki theorem, as recently observed by W. Kimmerle.",Mathematics
"Let k_r(n,m) denote the minimum number of r-cliques in graphs with n vertices and m edges. For r=3,4 we give a lower bound on k_r(n,m) that approximates k_r(n,m) with an error smaller than n^r/(n^2-2m). The solution is based on a constraint minimization of certain multilinear forms. In our proof, a combinatorial strategy is coupled with extensive analytical arguments.",Mathematics
"We define Hilbert-Siegel modular forms and Hecke ""operators"" acting on them. As with Hilbert modular forms, these linear transformations are not linear operators until we consider a direct product of spaces of modular forms (with varying groups), modulo natural identifications we can make between certain spaces. With Hilbert-Siegel forms we identify several families of natural identifications between certain spaces of modular forms. We associate the Fourier coefficients of a form in our product space to even integral lattices, independent of a basis and choice of coefficient rings. We then determine the action of the Hecke operators on these Fourier coefficients, paralleling the result of Hafner and Walling for Siegel modular forms (where the number field is the field of rationals).",Mathematics
"We solve the oscillation stability problem for the Urysohn sphere, an analog of the distortion problem for the Hilbert space in the context of the Urysohn universal metric space. This is achieved by solving a purely combinatorial problem involving a family of countable homogeneous metric spaces with finitely many distances.",Mathematics
"In [RS1], we defined q-analogues of alien derivations and stated their basic properties. In this paper, we prove the density theorem and the freeness theorem announced in loc. cit.   [RS1] Ramis J.-P. and Sauloy J., 2007. The q-analogue of the wild fundamental group (I)",Mathematics
"This paper studies multiclass loss systems with two layers of servers, where each server at the first layer is dedicated to a certain customer class, while the servers at the second layer can handle all customer classes. The routing of customers follows an overflow scheme, where arriving customers are preferentially directed to the first layer. Stochastic comparison and coupling techniques are developed for studying how the system is affected by packing of customers, altered service rates, and altered server configurations. This analysis leads to easily computable upper and lower bounds for the performance of the system.",Mathematics
"This is a collection of examples showing how the GAP system can be used to compute information about the probabilistic generation of finite almost simple groups. It includes all examples that were needed for the computational results in the paper ""Probabilistic generation of finite simple groups, II"" by Thomas Breuer, Robert M. Guralnick, and William M. Kantor.   The purpose of this writeup is twofold. On the one hand, the computations are documented this way. On the other hand, the GAP code shown for the examples can be used as test input for automatic checking of the data and the functions used.",Mathematics
"We study properties of the forgotten monoid which appeared in work of Lascoux and Schutzenberger and recently resurfaced in the construction of dual equivalence graphs by Assaf. In particular, we provide an explicit characterization of the forgotten classes in terms of inversion numbers and show that there are n^2-3n+4 forgotten classes in the symmetric group S_n. Each forgotten class contains a canonical element that can be characterized by pattern avoidance. We also show that the sum of Gessel's quasi-symmetric functions over a forgotten class is a 0-1 sum of ribbon-Schur functions.",Mathematics
"Consider a class of skew product transformations consisting of an ergodic or a periodic transformation on a probability space (M, B, m) in the base and a semigroup of transformations on another probability space (W,F,P) in the fibre. Under suitable mixing conditions for the fibre transformation, we show that the properties ergodicity, weakly mixing, and strongly mixing are passed on from the base transformation to the skew product (with respect to the product measure). We derive ergodic theorems with respect to the skew product on the product space. The main aim of this paper is to establish uniform convergence with respect to the base variable for the series of ergodic averages of a function F on the product of the two probability spaces along the orbits of such a skew product. Assuming a certain growth condition for the coupling function, a strong mixing condition on the fibre transformation, and continuity andintegrability conditions for F, we prove uniform convergence in the base and L^p(P)-convergence in the fibre. Under an equicontinuity assumption on F we further show P-almost sure convergence in the fibre. Our work has an application in information theory: It implies convergence of the averages of functions on random fields restricted to parts of stair climbing patterns defined by a direction.",Mathematics
Let $\pi: {\mathbb C}_g \to {\mathbb M}_g$ be the universal family of compact Riemann surfaces of genus $g \geq 1$. We introduce a real-valued function on the moduli space ${\mathbb M}_g$ and compute the first and the second variations of the function. As a consequence we relate the Chern form of the relative tangent bundle $T_{{\mathbb C}_g/{\mathbb M}_g}$ induced by the Arakelov-Green function with differential forms on ${\mathbb C}_g$ induced by a flat connection whose holonomy gives Johnson's homomorphisms on the mapping class group.,Mathematics
"Let S be the variety of irreducible sextics with six cusps as singularities. Let W be one of irreducible components of W. Denoting by M_4 the space of moduli of smooth curves of genus 4, the moduli map of W is the rational map from W to M_4 sending the general point of W, corresponding to a plane curve D, to the point of M_4 parametrizing the normalization curve of D. The number of moduli of W is, by definition the dimension of the image of W with respect to the moduli map. We know that this number is at most equal to seven. In this paper we prove that both irreducible components of S have number of moduli exactly equal to seven.",Mathematics
"Hirota's results given in (Hirota.M.,1981) on the asymptotically stability are generalized to the price-scaled price adjustment process.",Mathematics
"We consider the problem of estimating the unconditional distribution of a post-model-selection estimator. The notion of a post-model-selection estimator here refers to the combined procedure resulting from first selecting a model (e.g., by a model selection criterion like AIC or by a hypothesis testing procedure) and then estimating the parameters in the selected model (e.g., by least-squares or maximum likelihood), all based on the same data set. We show that it is impossible to estimate the unconditional distribution with reasonable accuracy even asymptotically. In particular, we show that no estimator for this distribution can be uniformly consistent (not even locally). This follows as a corollary to (local) minimax lower bounds on the performance of estimators for the distribution; performance is here measured by the probability that the estimation error exceeds a given threshold. These lower bounds are shown to approach 1/2 or even 1 in large samples, depending on the situation considered. Similar impossibility results are also obtained for the distribution of linear functions (e.g., predictors) of the post-model-selection estimator.",Mathematics
"We consider the stability of periodic gravity free-surface water waves traveling downstream at a constant speed over a shear flow of finite depth. In case the free surface is flat, a sharp criterion of linear instability is established for a general class of shear flows with inflection points and the maximal unstable wave number is found. Comparison to the rigid-wall setting testifies that free surface has a destabilizing effect. For a class of unstable shear flows, the bifurcation of nontrivial periodic traveling waves of small-amplitude is demonstrated at any wave number. We show the linear instability of small nontrivial waves bifurcated at an unstable wave number of the background shear flow. The proof uses a new formulation of the linearized water-wave problem and a perturbation argument. An example of the background shear flow of unstable small-amplitude periodic traveling waves is constructed for an arbitrary vorticity strength and for an arbitrary depth, illustrating that vorticity has a subtle influence on the stability of water waves.",Mathematics
"The threshold network model is a type of finite random graphs. In this paper, we introduce a generalized threshold network model. A pair of vertices with random weights is connected by an edge when real-valued functions of the pair of weights belong to given Borel sets. We extend several known limit theorems for the number of prescribed subgraphs to show that the strong law of large numbers can be uniform convergence. We also prove two limit theorems for the local and global clustering coefficients.",Mathematics
"Social groups with widely different music tastes, political convictions, and religious beliefs emerge and disappear on scales from extreme subcultures to mainstream mass-cultures. Both the underlying social structure and the formation of opinions are dynamic and changes in one affect the other. Several positive feedback mechanisms have been proposed to drive the diversity in social and economic systems, but little effort has been devoted to pinpoint the interplay between a dynamically changing social network and the spread and gathering of information on the network. Here we analyze this phenomenon in terms of a social network-model that explicitly simulates the feedback between information assembly and emergence of social structures: changing beliefs are coupled to changing relationships because agents self-organize a dynamic network to facilitate their hunter-gatherer behavior in information space. Our analysis demonstrates that tribal organizations and modular social networks can emerge as a result of contact-seeking agents that reinforce their beliefs among like-minded. We also find that prestigious persons can streamline the social network into hierarchical structures around themselves.",Physics
"We explore the effects of a positive cosmological constant on astrophysical and cosmological configurations described by a polytropic equation of state. We derive the conditions for equilibrium and stability of such configurations and consider some astrophysical examples where our analysis may be relevant. We show that in the presence of the cosmological constant the isothermal sphere is not a viable astrophysical model since the density in this model does not go asymptotically to zero. The cosmological constant implies that, for polytropic index smaller than five, the central density has to exceed a certain minimal value in terms of the vacuum density in order to guarantee the existence of a finite size object. We examine such configurations together with effects of $\Lambda$ in other exotic possibilities, such as neutrino and boson stars, and we compare our results to N-body simulations. The astrophysical properties and configurations found in this article are specific features resulting from the existence of a dark energy component. Hence, if found in nature would be an independent probe of a cosmological constant, complementary to other observations.",Physics
"Using numerical simulations at moderate magnetic Reynolds numbers up to 220 it is shown that in the kinematic regime, isotropic helical turbulence leads to an alpha effect and a turbulent diffusivity whose values are independent of the magnetic Reynolds number, $\Rm$, provided $\Rm$ exceeds unity. These turbulent coefficients are also consistent with expectations from the first order smoothing approximation. For small values of $\Rm$, alpha and turbulent diffusivity are proportional to $\Rm$. Over finite time intervals meaningful values of alpha and turbulent diffusivity can be obtained even when there is small-scale dynamo action that produces strong magnetic fluctuations. This suggests that small-scale dynamo-generated fields do not make a correlated contribution to the mean electromotive force.",Physics
"We discuss double ionization of atoms in strong laser pulses using a reduced dimensionality model. Following the insights obtained from an analysis of the classical mechanics of the process, we confine each electron to move along the lines that point towards the two-particle Stark saddle in the presence of a field. The resulting effective two dimensional model is similar to the aligned electron model, but it enables correlated escape of electrons with equal momenta, as observed experimentally. The time-dependent solution of the Schr\""odinger equation allows us to discuss in detail the time dynamics of the ionization process, the formation of electronic wave packets and the development of the momentum distribution of the outgoing electrons. In particular, we are able to identify the rescattering process, simultaneous direct double ionization during the same field cycle, as well as other double ionization processes. We also use the model to study the phase dependence of the ionization process.",Physics
"The results of IR-studies in quasi-1D carbynoid films produced by dehydrohalogenation of poly(vinilidene fluoride) are in good agreement with the assumption that carbynoid films studied are generalized spin -Peierls conductors, the metal to insulator transition in which can be described in the frame of t-J model. Residual atoms of fluorine, hydrogen and atoms of main technological impurity oxygen in the form of various complexes in interchain space are suggested to be spin - (or joint spin - and electrical) conductivity dopants. Antiferroelectric spin wave resonance (AFESWR) being to be optical analogue of antiferromagnetic spin wave resonance has been identified for the first time. Electric spin-Peierls polaron lattice in C-C -bonds is proposed to be responsible for the observed AFESWR both in starting PWDF films and in carbynoid B-films (the samples with the least impurity content). Electric spin moment with pure imaginary value predicted by Dirac as early as 1928 was identified for the first time. Electric spin-Peierls polarons are proposed to be electric spin moment carriers. It has been established that topological solitons, earlier called spin-Peierls solitons (SPS), are simultaneously active, unlike to topological solitons with nonzero spin in \textit{trans}-polyacetylene, in both optical and magnetic resonance spectra.It is explained in suggestion that SPS possess by both electric and magnetic spin moments which can be considered as two components of complex electromagnetic spin vector as a single whole. SPS proposed to be consisting of two coupled domain walls in both magnetic and electric generalized spin density wave (GSDW), produced by electromagnetic spin-Peierls transition in its generalized form in $\pi$ - and $\sigma$ -subsystems of carbynoids.",Physics
"We present a detailed study of complex dielectric constant and ferroelectric polarization in multiferroic LiCuVO4 as function of temperature and external magnetic field. In zero external magnetic field, spiral spin order with an ab helix and a propagation vector along the crystallographic b direction is established, which induces ferroelectric order with spontaneous polarization parallel to a. The direction of the helix can be reoriented by an external magnetic field and allows switching of the spontaneous polarization. We find a strong dependence of the absolute value of the polarization for different orientations of the spiral plane. Above 7.5 T, LiCuVO4 reveals collinear spin order and remains paraelectric for all field directions. Thus this system is ideally suited to check the symmetry relations for spiral magnets as predicted theoretically. The strong coupling of ferroelectric and magnetic order is documented and the complex (B,T) phase diagram is fully explored.",Physics
"A real-time path integral Monte Carlo approach is developed to study the dynamics in a many-body quantum system until reaching a nonequilibrium stationary state. The approach is based on augmenting an exact reduced equation for the evolution of the system in the interaction picture which is amenable to an efficient path integral (worldline) Monte Carlo approach. Results obtained for a model of inelastic tunneling spectroscopy reveal the applicability of the approach to a wide range of physically important regimes, including high (classical) and low (quantum) temperatures, and weak (perturbative) and strong electron-phonon couplings.",Physics
"Investigation of electrical conduction in polysilicon nanowires (polySiNW) with nanograins (5 to 20nm), based on Monte Carlo (MC) simulations and electrical measurements from 4K to 300K are presented. Some irregular Coulomb Oscillations (CO) are observed at temperatures lower than 200K showing several period widths due to the random distribution in grain size (5-20nm). A remarkable result consists in more effective oscillations observed at intermediate range of temperatures (between 25K and 150K) and high drain voltages. The temperature dependence of COs is explained by the fact that in a multiple asymmetric dot system at low temperature, COs are observed not at the lowest but at an intermediate temperature range, whereas the drain voltage dependence is due to an enhanced non-resonant tunneling. MC simulations have confirmed experimental observations.",Physics
"(Abridged) We study dissipative inflation in the regime where the dissipative term takes a specific form, \Gamma=\Gamma(\phi), analyzing two models in the weak and strong dissipative regimes with a SUSY breaking potential. After developing intuition about the predictions from these models through analytic approximations, we compute the predicted cosmological observables through full numerical evolution of the equations of motion, relating the mass scale and scale of dissipation to the characteristic amplitude and shape of the primordial power spectrum. We then use Markov Chain Monte Carlo techniques to constrain a subset of the models with cosmological data from the cosmic microwave background (WMAP three-year data) and large scale structure (SDSS Luminous Red Galaxy power spectrum). We find that the posterior distributions of the dissipative parameters are highly non-Gaussian and their allowed ranges agree well with the expectations obtained using analytic approximations. In the weak regime, only the mass scale is tightly constrained; conversely, in the strong regime, only the dissipative coefficient is tightly constrained. A lower limit is seen on the inflation scale: a sub-Planckian inflaton is disfavoured by the data. In both weak and strong regimes, we reconstruct the limits on the primordial power spectrum and show that these models prefer a {\it red} spectrum, with no significant running of the index. We calculate the reheat temperature and show that the gravitino problem can be overcome with large dissipation, which in turn leads to large levels of non-Gaussianity: if dissipative inflation is to evade the gravitino problem, the predicted level of non-Gaussianity might be seen by the Planck satellite.",Physics
"We have used Suprime-Cam on the Subaru Telescope to conduct a V- and I-band imaging survey of fields sampling the spheroid of the Andromeda galaxy along its south-east minor axis. Our photometric data are deep enough to resolve stars down to the red clump. Based on a large and reliable sample of red giant stars available from this deep wide-field imager, we have derived metallicity distributions vs. radius and a surface brightness profile over projected distances of R=23-66 kpc from the galaxy's center. The metallicity distributions across this region shows a clear high mean metallicity and a broad distribution ([Fe/H] ~ -0.6 +/- 0.5), and indicates no metallicity gradient within our observed range. The surface brightness profile at R>40 kpc is found to be flatter than previously thought. It is conceivable that this part of the halo samples as yet unidentified, metal-rich substructure.",Physics
"We investigate the relationship between several previously identified Galactic halo stellar structures in the direction of Virgo using imaging and spectroscopic observations of F turnoff stars and blue horizontal branch stars from the Sloan Digital Sky Survey (SDSS) and the Sloan Extension for Galactic Understanding and Exploration (SEGUE). We show that the Sagittarius dwarf leading tidal tail does not pass through the solar neighborhood; it misses the Sun by more than 15 kpc, passing through the Galactic plane outside the Solar Circle. It also is not spatially coincident with the large stellar overdensity S297+63-20.5 in the Virgo constellation. S297+63-20.5 has a distinct turnoff color and kinematics. Faint (g ~ 20.3) turnoff stars in S297+63-20.5 have line-of-sight, Galactic standard of rest velocities V(GSR)= 130 +/- 10 km/s, opposite in sign to infalling Sgr tail stars. The path of the Sgr leading tidal tail is also inconsistent with the positions of some of the nearer stars with which it has been associated, and whose velocities have favored models with prolate Milky Way potentials. We additionally show that the number densities of brighter (g ~ 19.8) F turnoff stars are not symmetric about the Galactic center, and that this discrepancy is not primarily due to the S297+63-20.5 moving group. Either the spheroid is asymmetric about the Galactic center, or there are additional substructures that conspire to be on the same side of the Galaxy as S297+63-20.5. The S297+63-20.5 overdensity in Virgo is likely associated with two other previously identified Virgo substructures: the Virgo Stellar Stream (VSS) and the Virgo Overdensity (VOD). However, the velocity difference between the VSS and S297+63-20.5 and the difference in distance estimates between the VOD and S297+63-20.5 must be reconciled.",Physics
"Using strong-disorder renormalization group, numerical exact diagonalization, and quantum Monte Carlo methods, we revisit the random antiferromagnetic XXZ spin-1/2 chain focusing on the long-length and ground-state behavior of the average time-independent spin-spin correlation function C(l)=\upsilon l^{-\eta}. In addition to the well-known universal (disorder-independent) power-law exponent \eta=2, we find interesting universal features displayed by the prefactor \upsilon=\upsilon_o/3, if l is odd, and \upsilon=\upsilon_e/3, otherwise. Although \upsilon_o and \upsilon_e are nonuniversal (disorder dependent) and distinct in magnitude, the combination \upsilon_o + \upsilon_e = -1/4 is universal if C is computed along the symmetric (longitudinal) axis. The origin of the nonuniversalities of the prefactors is discussed in the renormalization-group framework where a solvable toy model is considered. Moreover, we relate the average correlation function with the average entanglement entropy, whose amplitude has been recently shown to be universal. The nonuniversalities of the prefactors are shown to contribute only to surface terms of the entropy. Finally, we discuss the experimental relevance of our results by computing the structure factor whose scaling properties, interestingly, depend on the correlation prefactors.",Physics
"We present new evolutionary models for Type Ia supernova (SN Ia) progenitors, introducing mass-stripping effect on a main-sequence (MS) or slightly evolved companion star by winds from a mass-accreting white dwarf (WD). The mass-stripping attenuates the rate of mass transfer from the companion to the WD. As a result, quite a massive MS companion can avoid forming a common envelope and increase the WD mass up to the SN Ia explosion. Including the mass-stripping effect, we follow binary evolutions of various WD + MS systems and obtain the parameter region in the initial donor mass - orbital period plane where SNe Ia occur. The newly obtained SN Ia region extends to donor masses of 6-7 M_\sun, although its extension depends on the efficiency of mass-stripping effect. The stripped matter would mainly be distributed on the orbital plane and form very massive circumstellar matter (CSM) around the SN Ia progenitor. It can explain massive CSM around SNe Ia/IIn(IIa) 2002ic and 2005gj as well as tenuous CSM around normal SN Ia 2006X. Our new model suggests the presence of very young (\lesssim 10^8 yr) populations of SNe Ia, being consistent with recent observational indications of young population SNe Ia.",Physics
"We analyze the competing effects of moderate to strong Coulomb electron-electron interactions and weak quenched disorder in graphene. Using a one-loop renormalization group calculation controlled within the large-N approximation, we demonstrate that, at successively lower energy (temperature or chemical potential) scales, a type of non-Abelian vector potential disorder always asserts itself as the dominant elastic scattering mechanism for generic short-ranged microscopic defect distributions. Vector potential disorder is tied to both elastic lattice deformations (""ripples"") and topological lattice defects. We identify several well-defined scaling regimes, for which we provide scaling predictions for the electrical conductivity and thermopower, valid when the inelastic lifetime due to interactions exceeds the elastic lifetime due to disorder. Coulomb interaction effects should figure strongly into the physics of suspended graphene films, where rs > 1; we expect vector potential disorder to play an important role in the description of transport in such films.",Physics
"From event-driven simulations of a gravity-driven channel flow of inelastic hard-disks, we show that the velocity distribution function remains close to a Gaussian for a wide range densities (even when the Knudsen number is of order one) if the walls are smooth and the particle collisions are nearly elastic. For dense flows, a transition from a Gaussian to a power-law distribution for the high velocity tails occurs with increasing dissipation in the center of the channel, irrespective of wall-roughness. For a rough wall, the near-wall distribution functions are distinctly different from those in the bulk even in the quasielastic limit.",Physics
"We present measurements of the frequency and electric field dependent conductivity of single walled carbon nanotube(SWCNT) networks of various densities. The ac conductivity as a function of frequency is consistent with the extended pair approximation model and increases with frequency above an onset frequency $\omega_0$ which varies over seven decades with a range of film thickness from sub-monolayer to 200 nm. The nonlinear electric field-dependent DC conductivity shows strong dependence on film thickness as well. Measurement of the electric field dependence of the resistance R(E) allows for the determination of a length scale $L_{E}$ possibly characterizing the distance between tube contacts, which is found to systematically decrease with increasing film thickness. The onset frequency $\omega_0$ of ac conductivity and the length scale $L_{E}$ of SWCNT networks are found to be correlated, and a physically reasonable empirical formula relating them has been proposed. Such studies will help the understanding of transport properties and benefit the applications of this material system.",Physics
"Passive spiral galaxies, despite their spiral morphological appearance, do not have any emission lines indicative of ongoing star formation in their optical spectra. Previous studies have suggested that passive spiral galaxies preferentially exist in infall regions of galaxy clusters, suggesting that the cluster environment is likely to be responsible for creating these galaxies. By carrying out spatially resolved long-slit spectroscopy on four nearby passive spiral galaxies with the Apache Point Observatory 3.5-m telescope, we investigated the stellar populations of passive spiral galaxies separately for their inner and outer regions. In the two unambiguously passive spiral galaxies among the four observed galaxies, H$\delta$ absorption lines are more prominent in the outer regions of the galaxies, whereas the 4000-{\AA} breaks (D$_{4000}$) are strongest in the inner regions of the galaxies. A comparison with a simple stellar population model for the two passive spiral galaxies indicates that the outer regions of the galaxies tend to harbour younger populations of stars. The strong H$\delta$ absorption observed in the outer regions of the sample galaxies is consistent with that of galaxies whose star formation ceased a few Gyrs ago. Because of the large uncertainty in the absorption indices in our samples, further observations are needed in order to place constraints on the mechanisms that quench star formation in passive spiral galaxies.",Physics
"We have realized a two dimensional permanent magnetic lattice of Ioffe-Pritchard microtraps for ultracold atoms. The lattice is formed by a single 300 nm magnetized layer of FePt, patterned using optical lithography. Our magnetic lattice consists of more than 15000 tightly confining microtraps with a density of 1250 traps/mm$^2$. Simple analytical approximations for the magnetic fields produced by the lattice are used to derive relevant trap parameters. We load ultracold atoms into at least 30 lattice sites at a distance of approximately 10 $\mu$m from the film surface. The present result is an important first step towards quantum information processing with neutral atoms in magnetic lattice potentials.",Physics
"Gravitational lenses with anomalous flux ratios are often cited as possible evidence for dark matter satellites predicted by simulations of hierarchical merging in cold dark matter cosmogonies. We show that the fraction of quads with anomalous flux ratios depends primarily on the total mass and spatial extent of the satellites, and the characteristic lengthscale R of their distribution. If R is 100 kpc, then for a moderately elliptical galaxy with a line-of-sight velocity dispersion of 250 km/s, a mass of 3 x 10^9 solar masses in highly-concentrated (Plummer model) satellites is needed for 20% of quadruplets to show anomalous flux ratios, rising to 1.25 x 10^10 solar masses for 50%. Several times these masses are required if the satellites have more extended Hernquist profiles. Compared to a typical elliptical, the flux ratios of quads formed by typical edge-on disc galaxies with maximum discs are significantly less susceptible to changes through substructure -- three times the mass in satellite galaxies is needed to affect 50% of the systems. In many of the lens systems with anomalous flux ratios, there is evidence for visible satellites (e.g., B2045+265 or MG0414+0534). We show that optically identified substructure should not be preponderant among lens systems with anomalies. There are two possible resolutions of this difficulty. First, in some cases, visible substructure may be projected within or close to the Einstein radius and wrongly ascribed as the culprit, whereas dark matter substructure is causing the flux anomaly. Second, bright satellites, in which baryon cooling and condensation has taken place, may have higher central densities than dark satellites, rendering them more efficient at causing flux anomalies.",Physics
"The Landau-Lifshitz equation reliably describes magnetization dynamics using a phenomenological treatment of damping. This paper presents first-principles calculations of the damping parameters for Fe, Co, and Ni that quantitatively agree with existing ferromagnetic resonance measurements. This agreement establishes the dominant damping mechanism for these systems and takes a significant step toward predicting and tailoring the damping constants of new materials.",Physics
"We present new multicolor photo-polarimetry of stars behind the Southern Coalsack. Analyzed together with multiband polarization data from the literature, probing the Chamaeleon I, Musca, rho Opiuchus, R CrA and Taurus clouds, we show that the wavelength of maximum polarization (lambda_max) is linearly correlated with the radiation environment of the grains. Using Far-Infrared emission data, we show that the large scatter seen in previous studies of lambda_max as a function of A_V is primarily due to line of sight effects causing some A_V measurements to not be a good tracer of the extinction (radiation field strength) seen by the grains being probed. The derived slopes in lambda_max vs. A_V, for the individual clouds, are consistent with a common value, while the zero intercepts scale with the average values of the ratios of total-to-selective extinction (R_V) for the individual clouds. Within each cloud we do not find direct correlations between lambda_max and R_V. The positive slope in consistent with recent developments in theory and indicating alignment driven by the radiation field. The present data cannot conclusively differentiate between direct radiative torques and alignment driven by H_2 formation. However, the small values of lambda_max(A_V=0), seen in several clouds, suggest a role for the latter, at least at the cloud surfaces. The scatter in the lambda_max vs. A_V relation is found to be associated with the characteristics of the embedded Young Stellar Objects (YSO) in the clouds. We propose that this is partially due to locally increased plasma damping of the grain rotation caused by X-rays from the YSOs.",Physics
"General relativity allows solutions exhibiting closed timelike curves. Time travel generates paradoxes and quantum mechanics generalizations were proposed to solve those paradoxes. The implications of self-consistent interactions on acausal region of space-time are investigated. If the correspondence principle is true, then all generalizations of quantum mechanics on acausal manifolds are not renormalizable. Therefore quantum mechanics can only be defined on global hyperbolic manifolds and all general relativity solutions exhibiting time travel are unphysical.",Physics
"Some aspects of disk-halo interactions for models of in and out of equilibrium disk galaxies are reviewed. Specifically, we focus on disk-halo resonant interaction without and in the presence of a gas component. Another issue is the disk growth within an assembling triaxial dark matter halo. We argue that while the triaxiality is the result of the merger process and the radial orbit instability, it is the developing chaos that damps the first generation of bars and washes out the halo prolateness. This chaos is triggered by the gravitational quadrupole interaction(s) in the system and supported by a number of other processes which are characteristic of baryons.",Physics
"Using a Gibbs sampling algorithm for joint CMB estimation and component separation, we compute the large-scale CMB and foreground posteriors of the 3-yr WMAP temperature data. Our parametric data model includes the cosmological CMB signal and instrumental noise, a single power law foreground component with free amplitude and spectral index for each pixel, a thermal dust template with a single free overall amplitude, and free monopoles and dipoles at each frequency. This simple model yields a surprisingly good fit to the data over the full frequency range from 23 to 94 GHz. We obtain a new estimate of the CMB sky signal and power spectrum, and a new foreground model, including a measurement of the effective spectral index over the high-latitude sky. A particularly significant result is the detection of a common spurious offset in all frequency bands of ~ -13muK, as well as a dipole in the V-band data. Correcting for these is essential when determining the effective spectral index of the foregrounds. We find that our new foreground model is in good agreement with template-based model presented by the WMAP team, but not with their MEM reconstruction. We believe the latter may be at least partially compromised by the residual offsets and dipoles in the data. Fortunately, the CMB power spectrum is not significantly affected by these issues, as our new spectrum is in excellent agreement with that published by the WMAP team. The corresponding cosmological parameters are also virtually unchanged.",Physics
"Elongated Bose-Einstein condensates (BECs) exhibit strong spatial phase fluctuations even well below the BEC transition temperature. We demonstrate that atom interferometers using such condensates are robust against phase fluctuations, i.e. the relative phase of the split condensate is reproducible despite axial phase fluctuations. However, larger phase fluctuations limit the coherence time, especially in the presence of some asymmetries in the two wells of the interferometer.",Physics
"Packing problems have been of great interest in many diverse contexts for many centuries. The optimal packing of identical objects has been often invoked to understand the nature of low temperature phases of matter. In celebrated work, Kepler conjectured that the densest packing of spheres is realized by stacking variants of the face-centered cubic lattice and has a packing fraction of $\pi/(3\sqrt{2}) \sim 0.7405$. Much more recently, an unusually high density packing of approximately 0.770732 was achieved for congruent ellipsoids. Such studies are relevant for understanding the structure of crystals, glasses, the storage and jamming of granular materials, ceramics, and the assembly of viral capsid structures. Here we carry out analytical studies of the stacking of close-packed planar layers of systems made up of truncated cones possessing uniaxial symmetry. We present examples of high density packing whose order is characterized by a {\em broken symmetry} arising from the shape of the constituent objects. We find a biaxial arrangement of solid cones with a packing fraction of $\pi/4$. For truncated cones, there are two distinct regimes, characterized by different packing arrangements, depending on the ratio $c$ of the base radii of the truncated cones with a transition at $c^*=\sqrt{2}-1$.",Physics
"We study the growth of networks from a set of isolated ground nodes by the addition of one new node per time step and also of a fixed number of directed edges leading from the new node to randomly selected nodes already in the network. A fixed-width time window is used so that, in general, only nodes that entered the network within the latest window may receive new incoming edges. The resulting directed network is acyclic at all times and allows some of the ground nodes, then called sinks, to be reached from some of the non-ground nodes. We regard such networks as representative of abstract systems of partially ordered constituents, for example in some of the domains related to technological evolution. Two properties of interest are the number of sinks that can be reached from a randomly chosen non-ground node (its reach) and, for a fixed sink, the number of nonoverlapping directed paths through which the sink can be reached, at a given time, from some of the latest nodes to have entered the network. We demonstrate, by means of simulations and also of analytic characterizations, that reaches are distributed according to a power law and that the desired directed paths are expected to occur in very small numbers, perhaps indicating that recovering sinks late in the process of network growth is strongly sensitive to accidental path disruptions.",Physics
"Numerical simulations suggest that active galactic nuclei (AGNs) play an important role in the formation of early-type galaxies by expelling gas and dust in powerful galactic winds and quenching star formation. However, the existence of AGN feedback capable of halting galaxy-wide star formation has yet to be observationally confirmed. To investigate this question, we have obtained spectra of 14 post-starburst galaxies at z~0.6 to search for evidence of galactic winds. In 10/14 galaxies we detect Mg II 2796,2803 absorption lines which are blueshifted by 490 - 2020 km/s with respect to the stars. The median blueshift is 1140 km/s. We hypothesize that the outflowing gas represents a fossil galactic wind launched near the peak of the galaxy's activity, a few 100 Myr ago. The velocities we measure are intermediate between those of luminous starbursts and broad absorption line quasars, which suggests that feedback from an AGN may have played a role in expelling cool gas and shutting down star formation.",Physics
"Violet Lander (VL) (C108H104) is a large organic molecule that when deposited on Cu (110) exhibited lock-and-key like behavior (Otero et al., Nature Mater. 3, 779 (2004)). In this work we report on a detailed fully atomistic molecular dynamics study of this phenomenon. Our results show that it has its physical basis in the interplay of the molecular hydrogens and the Cu(110) atomic spacing, which is a direct consequence of an accidental commensurability between molecule and surface dimensions. This knowledge could be used to engineer new molecules capable of displaying lock-and-key behavior with new potential applications in nanotechology.",Physics
"We consider grains with superparamagnetic inclusions and report two new condensed matter effects that can enhance the internal relaxation of the energy of a wobbling grain, namely, superparamagnetic Barnett relaxation, as well as, an increase of frequencies for which nuclear relaxation becomes important. This findings extends the range of grain sizes for which grains are thermally trapped, i.e. rotate thermally, in spite of the presence of uncompensated pinwheel torques. In addition, we show that the alignment of dust grains by radiative torques gets modified for superparamagnetic grains, with grains obtaining perfect alignment with respect to magnetic fields as soon as the grain gaseous randomization time gets larger than that of paramagnetic relaxation. The same conclusion is valid for the mechanical alignment of helical grains. If observations confirm that the degrees of alignment are higher than radiative torques can produce alone, this may be a proof of the presence of superparamagentic inclusions.",Physics
"A theoretical analysis of the earthquake prediction problem in space-time is presented. We find an explicit structure of the optimal strategy and its relation to the generalized error diagram. This study is a generalization of the theoretical results for time prediction. The possibility and simplicity of this extension is due to the choice of the class of goal functions. We also discuss issues in forecasting versus prediction, scaling laws versus predictability, and measure of prediction efficiency at the research stage.",Physics
"The electronic structure and properties of PuO$_{2}$ and Pu$_{2}$O$_{3}$ have been studied from first principles by the all-electron projector-augmented-wave (PAW) method. The local density approximation (LDA)+$U$ and the generalized gradient approximation (GGA)+$U$ formalism have been used to account for the strong on-site Coulomb repulsion among the localized Pu $5f$ electrons. We discuss how the properties of PuO$_{2}$ and Pu$_{2}$O$_{3}$ are affected by the choice of $U$ as well as the choice of exchange-correlation potential. Also, oxidation reaction of Pu$_{2}$O$_{3}$, leading to formation of PuO$_{2}$, and its dependence on $U$ and exchange-correlation potential have been studied. Our results show that by choosing an appropriate $U$ it is promising to correctly and consistently describe structural, electronic, and thermodynamic properties of PuO$_{2}$ and Pu$_{2}$O$_{3}$, which enables it possible the modeling of redox process involving Pu-based materials.",Physics
"Dynamics of molecular motors that move along linear lattices and interact with them via reversible destruction of specific lattice bonds is investigated theoretically by analyzing exactly solvable discrete-state ``burnt-bridge'' models. Molecular motors are viewed as diffusing particles that can asymmetrically break or rebuild periodically distributed weak links when passing over them. Our explicit calculations of dynamic properties show that coupling the transport of the unbiased molecular motor with the bridge-burning mechanism leads to a directed motion that lowers fluctuations and produces a dynamic transition in the limit of low concentration of weak links. Interaction between the backward biased molecular motor and the bridge-burning mechanism yields a complex dynamic behavior. For the reversible dissociation the backward motion of the molecular motor is slowed down. There is a change in the direction of the molecular motor's motion for some range of parameters. The molecular motor also experiences non-monotonic fluctuations due to the action of two opposing mechanisms: the reduced activity after the burned sites and locking of large fluctuations. Large spatial fluctuations are observed when two mechanisms are comparable. The properties of the molecular motor are different for the irreversible burning of bridges where the velocity and fluctuations are suppressed for some concentration range, and the dynamic transition is also observed. Dynamics of the system is discussed in terms of the effective driving forces and transitions between different diffusional regimes.",Physics
"UV observations of some massive globular clusters uncovered a significant population of very hot stars below the hot end of the horizontal branch (HB), the so-called blue hook stars. This feature might be explained either as results of the late hot flasher scenario where stars experience the helium flash while on the white dwarf cooling curve or by the progeny of the helium-enriched sub-population recently postulated to exist in some clusters. Moderately high resolution spectra of stars at the hot end of the blue HB in omega Cen were analysed for atmospheric parameters and abundances using LTE and Non-LTE model atmospheres. In the temperature range 30,000K to 50,000K we find that 35% of our stars are helium-poor (log(n_He/n_H) < -2), 51% have solar helium abundance within a factor of 3 (-1.5 <= log(n_He/n_H) <= -0.5) and 14% are helium-rich (log(n_He/n_H)> -0.4). We also find carbon enrichment in step with helium enrichment, with a maximum carbon enrichment of 3% by mass. At least 14% of the hottest HB stars in omega Cen show helium abundances well above the highest predictions from the helium enrichment scenario (Y = 0.42 corresponding to log(n_He/n_H) ~ -0.74). In addition, the most helium-rich stars show strong carbon enrichment as predicted by the late hot flasher scenario. We conclude that the helium-rich HB stars in omega Cen cannot be explained solely by the helium-enrichment scenario invoked to explain the blue main sequence. (Abridged)",Physics
"A theory is proposed which allows explaining the observed flat galaxy rotation curves, without needing to invoke dark matter. Whereas other theories have been proposed in the past which realize the same, the present theory rests on basic physical principles, in contrast to for instance the MOND theory. The key to arrive at this new theory is to consider from the start the energy density of the vacuum. The way to calculate the effect of the corresponding vacuum pressure on a mass has previously been laid down by Van Nieuwenhove (1992). We obtain a modification of Newton's law of gravitation with some peculiar properties such as the occurrence of regions of repulsive gravity. Based on a newly derived equation of state of the vacuum, the Tully-Fisher relation is derived. The theory can make detailed predictions about galaxy rotation curves and is also able to explain to the Pioneer anomaly, the foamy distribution of galaxies and the observed accelerated expansion of the universe. A relativistic extension of the theory is included as well.",Physics
"We present two-dimensional gas-kinematic maps of the central region in Centaurus A. The adaptive optics (AO) assisted SINFONI data from the VLT have a resolution of 0.12"" in K-band. The ionized gas species (Br_gamma, [FeII], [SiVI]) show a rotational pattern that is increasingly overlaid by non-rotational motion for higher excitation lines in direction of Cen A's radio jet. The emission lines of molecular hydrogen (H_2) show regular rotation and no distortion due to the jet. The molecular gas seems to be well settled in the gravitational potential of the stars and the central supermassive black hole and we thus use it as a tracer to model the mass in the central +/-1.5"". These are the first AO integral-field observations on the nucleus of Cen A, enabling us to study the regularity of the rotation around the black hole, well inside the radius of influence, and to determine the inclination angle of the gas disk in a robust way. The gas kinematics are best modeled through a tilted-ring model that describes the warped gas disk; its mean inclination angle is ~34deg and the mean position angle of the major axis is ~155deg. The best-fit black hole mass is M_BH~4.5x10^7 Msolar, based on a ""kinematically hot"" disk model where the velocity dispersion is included through the Jeans equation. This black hole mass estimate is somewhat lower than, but consistent with the mass values previously derived from ionized gas kinematics. It is also consistent with the stellar dynamical measurement from the same AO observations, which we present in a separate paper. It brings Cen A in agreement with the M_BH-sigma relation.",Physics
"We report on interferometric and radial-velocity observations of the double-lined 51-d period binary (A) component of the quadruple pre-main sequence (PMS) system V773 Tau. With these observations we have estimated preliminary visual and physical orbits of the V773 Tau A subsystem. Among other parameters, our orbit model includes an inclination of 66.0 $\pm$ 2.4 deg, and allows us to infer the component dynamical masses and system distance. In particular we find component masses of 1.54 $\pm$ 0.14 and 1.332 $\pm$ 0.097 M$_{\sun}$ for the Aa (primary) and Ab (secondary) components respectively.   Our modeling of the subsystem component spectral energy distributions finds temperatures and luminosities consistent with previous studies, and coupled with the component mass estimates allows for comparison with PMS stellar models in the intermediate-mass range. We compare V773 Tau A component properties with several popular solar-composition models for intermediate-mass PMS stars. All models predict masses consistent to within 2-sigma of the dynamically determined values, though some models predict values that are more consistent than others.",Physics
"The fluorescence detection of ultra high energy cosmic rays requires a detailed knowledge of the fluorescence light emission from nitrogen molecules over a wide range of atmospheric parameters, corresponding to altitudes typical of the cosmic ray shower development in the atmosphere. We have studied the temperature and humidity dependence of the fluorescence light spectrum excited by MeV electrons in air. Results for the 313.6 nm, 337.1 nm, 353.7 nm and 391.4 nm bands are reported in this paper. We found that the temperature and humidity dependence of the quenching process changes the fluorescence yield by a sizeable amount (up to 20%) and its effect must be included for a precise estimation of the energy of ultra high energy cosmic rays.",Physics
"We study the interaction of a low-mass planet with a protoplanetary disk with a realistic treatment of the energy balance by doing radiation-hydrodynamical simulations. We look at accretion and migration rates and compare them to isothermal studies. We used a three-dimensional version of the hydrodynamical method RODEO, together with radiative transport in the flux-limited diffusion approach. The accretion rate, as well as the torque on the planet, depend critically on the ability of the disk to cool efficiently. For densities appropriate to 5 AU in the solar nebula, the accretion rate drops by more than an order of magnitude compared to isothermal models, while at the same time the torque on the planet is positive, indicating outward migration. It is necessary to lower the density by a factor of 2 to recover inward migration and more than 2 orders of magnitude to recover the usual Type I migration. The torque appears to be proportional to the radial entropy gradient in the unperturbed disk. These findings are critical for the survival of protoplanets, and they should ultimately find their way into population synthesis models.",Physics
"The shear flow and the dielectric alpha-process in molecular glass formers is modeled in terms of local structural rearrangements which reverse a strong local shear. Using Eshelby's solution of the corresponding elasticity theory problem (J. D. Eshelby, Proc. Roy. Soc. A241, 376 (1957)), one can calculate the recoverable compliance and estimate the lifetime of the symmetric double-well potential characterizing such a structural rearrangement. A full modeling of the shear relaxation spectra requires an additional parametrization of the barrier density of these structural rearrangements. The dielectric relaxation spectrum can be described as a folding of these relaxations with the Debye process.",Physics
We consider a non-spherical colloidal particle immersed in a fluid close to its critical point. The temperature dependence of the corresponding order parameter profile is calculated explicitly. We perform a systematic expansion of the order parameter profile in powers of the local curvatures of the surface of the colloidal particle. This curvature expansion reduces to the short distance expansion of the order parameter profile in the case that the solvent is at the critical composition.,Physics
"The detection of exolife is one of the goals of very ambitious future space missions that aim to take direct images of Earth-like planets. While associations of simple molecules present in the planet's atmosphere ($O_2$, $O_3$, $CO_2$ etc.) have been identified as possible global biomarkers, we review here the detectability of a signature of life from the planet's surface, i.e. the green vegetation. The vegetation reflectance has indeed a specific spectrum, with a sharp edge around 700 nm, known as the ""Vegetation Red Edge"" (VRE). Moreover vegetation covers a large surface of emerged lands, from tropical evergreen forest to shrub tundra. Thus considering it as a potential global biomarker is relevant. Earthshine allows to observe the Earth as a distant planet, i.e. without spatial resolution. Since 2001, Earthshine observations have been used by several authors to test and quantify the detectability of the VRE in the Earth spectrum. The egetation spectral signature is detected as a small 'positive shift' of a few percents above the continuum, starting at 700 nm. This signature appears in most spectra, and its strength is correlated with the Earth's phase (visible land versus visible ocean). The observations show that detecting the VRE on Earth requires a photometric relative accuracy of 1% or better. Detecting something equivalent on an Earth-like planet will therefore remain challenging, moreover considering the possibility of mineral artifacts and the question of 'red edge' universality in the Universe.",Physics
"We demonstrate fully tunable single and double quantum dots in a one-dimensional hole system based on undoped Ge/Si core-shell nanowire heterostructures. The local hole density along the nanowire is controlled by applying voltages to five top gate electrodes with a periodicity of 80 nm, insulated from the wire by a 20 nm-thick HfO_2 dielectric film. Low-temperature transport measurements were used to investigate the magnetic field dependence of Coulomb blockade peaks in a single quantum dot and indicate a strongly anisotropic g-factor with |g_para| = 0.60 +/- 0.03 and |g_perp| < 0.12.",Physics
"Using scaled-particle theory for binary mixtures of two-dimensional hard particles with rotational freedom, we analyse the stability of nematic phases and the demixing phase behaviour of a variety of mixtures, focussing on cases where at least one of the components consists of hard rectangles or hard squares. A pure fluid of hard rectangles may exhibit, aside from the usual uniaxial nematic phase, an additional (tetratic) oriented phase, possessing two directors, which is the analogue of the biaxial or cubatic phases in three- dimensional fluids. There is computer simulation evidence that the tetratic phase might be stable with respect to phases with spatial order for rectangles with low aspect ratios. As hard rectangles are mixed with other particles not possessing stable tetratic order by themselves, the tetratic phase is destabilised, via a first- or second-order phase transition, to uniaxial nematic or isotropic phases; for hard rectangles of low aspect ratio tetratic order persists in a relatively large range of volume fractions. The order of these transitions depends on the particle geometry, dimensions and thermodynamic conditions of the mixture. The second component of the mixture has been chosen to be hard discs or disco-rectangles, the geometry of which is different from that of rectangles, leading to packing frustration and demixing behaviour, or simply rectangles of different aspect ratio. These mixtures may be good candidates for observing thermodynamically stable tetratic phases in monolayers of hard particles. Finally, demixing between fluid (isotropic--tetratic or tetratic--tetratic) phases is seen to occur in mixtures of hard squares of different sizes when the size ratio is sufficiently large.",Physics
"Many models of gamma-ray bursts suggest a common central engine: a black hole of several solar masses accreting matter from a disk at an accretion rate from 0.01 to 10 M_\sun / s. The inner region of the disk is cooled by neutrino emission and large amounts of its binding energy were liberated, which could trigger the fireball. We improve the neutrino-dominated accreting flows by considering the effects of the magnetic fields, and find that more than half of the liberating energy can be extracted directly by the large-scale magnetic fields on the disk. And it turns out that the temperature of the disk is a bit lower than the neutrino-dominated accreting flows without magnetic field. Therefore, The outflows are magneticallydominated rather than neutrino dominated. In our model, neutrino mechanism can fuel some GRBs (not the brightest ones), but cannot fuel X-ray flares. However, the magnetic processes (both BZ and electromagnetic luminosity from a disk) are viable mechanisms for most of GRBs and the following X-ray flares.",Physics
"Spin transport equations in a non-homogeneous ferromagnet are derived in the limit where the sd exchange coupling between the electrons in the conduction band and those in the d band is dominant. It is shown that spin diffusion in ferromagnets assumes a tensor form. The diagonal terms are renormalized with respect to that in normal metals and enhances the dissipation in the magnetic system while the off-diagonal terms renormalize the precessional frequency of the conduction electrons and enhances the non-adiabatic spin torque. To demonstrate the new physics in our theory, we show that self-consistent solutions of the spin diffusion equations and the Landau-Lifshitz equations in the presence of a current lead to a an increase in the terminal velocity of a domain wall which becomes strongly dependent on its width. We also provide a simplified equation that predicts damping due to the conduction electrons.",Physics
"State of the art nanomechanical resonators present quality factors Q ~ 10^3 - 10^5, which are much lower than those that can be naively extrapolated from the behavior of micromechanical resonators. We analyze the dissipation mechanism that arises in nanomechanical beam-structures due to the tunneling of mesoscopic phonons between the beam and its supports (known as clamping losses). We derive the environmental force spectral density that determines the quantum Brownian motion of a given resonance. Our treatment is valid for low frequencies and provides the leading contribution in the aspect ratio. This yields fundamental limits for the Q-values which are described by simple scaling laws and are relevant for state of the art experimental structures. In this context, for resonant frequencies in the 0.1-1GHz range, while this dissipation mechanism can limit flexural resonators it is found to be negligible for torsional ones. In the case of structureless 3D supports the corresponding environmental spectral densities are Ohmic for flexural resonators and super-Ohmic for torsional ones, while for 2D slab supports they yield 1/f noise. Furthermore analogous results are established for the case of suspended semiconducting single-walled carbon nanotubes. Finally, we provide a general expression for the spectral density that allows to extend our treatment to other geometries and illustrate its use by applying it to a microtoroid. Our analysis is relevant for applications in high precision measurements and for the prospects of probing quantum effects in a macroscopic mechanical degree of freedom.",Physics
"The success of new scientific areas can be assessed by their potential for contributing to new theoretical approaches and in applications to real-world problems. Complex networks have fared extremely well in both of these aspects, with their sound theoretical basis developed over the years and with a variety of applications. In this survey, we analyze the applications of complex networks to real-world problems and data, with emphasis in representation, analysis and modeling, after an introduction to the main concepts and models. A diversity of phenomena are surveyed, which may be classified into no less than 22 areas, providing a clear indication of the impact of the field of complex networks.",Physics
"We compare the performance of two alternative algorithms which aim to construct a force-free magnetic field given suitable boundary conditions. For this comparison, we have implemented both algorithms on the same finite element grid which uses Whitney forms to describe the fields within the grid cells. The additional use of conjugate gradient and multigrid iterations result in quite effective codes. The Grad-Rubin and Wheatland-Sturrock-Roumeliotis algorithms both perform well for the reconstruction of a known analytic force-free field. For more arbitrary boundary conditions the Wheatland-Sturrock-Roumeliotis approach has some difficulties because it requires overdetermined boundary information which may include inconsistencies. The Grad-Rubin code on the other hand loses convergence for strong current densities. For the example we have investigated, however, the maximum possible current density seems to be not far from the limit beyond which a force free field cannot exist anymore for a given normal magnetic field intensity on the boundary.",Physics
"We consider interaction effects in quantum point contacts on the first quantization plateau, taking into account all non momentum-conserving processes. We compute low-temperature linear and non-linear conductance, shot noise, and thermopower by perturbation theory, and show that they are consistent with experimental observations on the so-called ""0.7 anomaly"". The full temperature-dependent conductance is obtained from self-consistent second-order perturbation theory and approaches ~ e^2/h at higher temperatures, but still smaller than the Fermi temperature.",Physics
"Whithin the framework of the Planck satellite polarisation calibration, we present a study of the Crab Nebula spectral energy distribution (SED) over more than 6 decades in frequency ranging from 1 to $\rm 10^6 GHz$. The Planck satellite mission observes the sky from 30 to 857 GHz and therefore we focus on the millimetre region. We use radio and submillimetre data from the WMAP satellite between 23 and 94 GHz (from 13 to 3.18 mm) and from the Archeops balloon experiment between 143 (2.1 mm) and 545 GHz (0.55 mm), and a compendium of other Crab Nebula observations. The Crab SED is compared to models including three main components : synchrotron which is responsible for the emission at low and at high frequencies, dust which explains the excess of flux observed by the IRAS satellite and an extra component on the millimetre regime. From this analysis we conclude that the unpolarised emission of the Crab Nebula at microwave and millimetre wavelengths is the same synchrotron emission that the one observed in the radio domain. Therefore, we expect the millimetre emission of the Crab nebula to be polarised with the same degree of polarisation and orientation than the radio emission. We set upper limits on the possible errors induced by any millimetre extra component on the reconstruction of the degree and angle of polarisation at the percent level as a maximum. This result strongly supports the choice by the Planck collaboration of the Crab nebula emission for performing polarisation cross-checks in the range 30 (299 mm) to 353 GHz (0.849 mm).",Physics
We present Suzaku X-ray observations of the recurrent nova T CrB in quiescence. T CrB is the first recurrent nova to be detected in the hard-X-ray band (E ~ 40.0 keV) during quiescence. The X-ray spectrum is consistent with cooling-flow emission emanating from an optically thin region in the boundary layer of an accretion disk around the white dwarf. The detection of strong stochastic flux variations in the light curve supports the interpretation of the hard X-ray emission as emanating from a boundary layer.,Physics
"When averaged over large scales, star formation in galaxies is observed to follow the empirical Kennicutt-Schmidt (KS) law for surface densities above a constant threshold. While the observed law involves surface densities, theoretical models and simulations generally work with volume density laws (i.e. Schmidt laws). We derive analytic relations between star formation laws expressed in terms of surface densities, volume densities, and pressures and we show how these relations depend on parameters such as the effective equation of state of the multiphase interstellar medium. Our analytic relations enable us to implement observed surface density laws into simulations. Because the parameters of our prescription for star formation are observables, we are not free to tune them to match the observations. We test our theoretical framework using high-resolution simulations of isolated disc galaxies that assume an effective equation of state for the multiphase interstellar medium. We are able to reproduce the star formation threshold and both the slope and the normalisation of arbitrary input KS laws without tuning any parameters and with very little scatter, even for unstable galaxies and even if we use poor numerical resolution. Moreover, we can do so for arbitrary effective equations of state. Our prescription therefore enables simulations of galaxies to bypass our current inability to simulate the formation of stars. On the other hand, the fact that we can reproduce arbitrary input thresholds and KS laws, rather than just the particular ones picked out by nature, indicates that simulations that lack the physics and/or resolution to simulate the multiphase interstellar medium can only provide limited insight into the origin of the observed star formation laws.",Physics
"We present Spitzer/IRS mid-infrared spectra for 15 gravitationally lensed, 24 micron--selected galaxies, and combine the results with 4 additional very faint galaxies with IRS spectra in the literature. The median intrinsic 24 micron flux density of the sample is 130 microJy, enabling a systematic survey of the spectral properties of the very faint 24 micron sources that dominate the number counts of Spitzer cosmological surveys. Six of the 19 galaxy spectra (32%) show the strong mid-IR continuua expected of AGN; X-ray detections confirm the presence of AGN in three of these cases, and reveal AGNs in two other galaxies. These results suggest that nuclear accretion may contribute more flux to faint 24 micron--selected samples than previously assumed. Almost all the spectra show some aromatic (PAH) emission features; the measured aromatic flux ratios do not show evolution from z=0. In particular, the high S/N mid-IR spectrum of SMM J163554.2+661225 agrees remarkably well with low--redshift, lower--luminosity templates. We compare the rest-frame 8 micron and total infrared luminosities of star--forming galaxies, and find that the behavior of this ratio with total IR luminosity has evolved modestly from z=2 to z=0. Since the high aromatic--to--continuum flux ratios in these galaxies rule out a dominant contribution by AGN, this finding implies systematic evolution in the structure and/or metallicity of infrared sources with redshift. It also has implications for the estimates of star forming rates inferred from 24 micron measurements, in the sense that at z ~2, a given observed frame 24 micron luminosity corresponds to a lower bolometric luminosity than would be inferred from low-redshift templates of similar luminosity at the corresponding rest wavelength.",Physics
"We study the effect of an imposed magnetic field on the motion of charged dust particles in magnetically active regions of a protoplanetary disc. Assuming a power law structure for the vertical and the toroidal components of the magnetic field for the regions beyond magnetically dead region of the disc, the radial and the vertical velocities of the charged particles, in the asymptotic case of small particles, are calculated analytically. While grains with radii smaller than a critical radius significantly are affected by the magnetic force, motion of the particles with larger radii is independent of the magnetic field. The critical radius depends on the magnetic geometry and the charge of the grains. Assuming that a grain particle has one elementary charge and the physical properties of the disc correspond to a minimum-mass solar nebula, we show that only micron-sized grains are affected by the magnetic force. Also, charge polarity determines direction of the radial velocity. For such small particles, both the radial and the vertical velocities increase due to the magnetic force.",Physics
"We propose that the strong millisecond extragalactic radio burst (mERB) discovered by Lorimer et al. (2007) may be related to a hyperflare from an extragalactic soft gamma-ray repeater. The expected rate of such hyperflares, $\sim$ 20 - 100 d$^{-1}$ Gpc$^{-3}$, is in good correspondence with the value estimated by Lorimer et al. The possible mechanism of radio emission can be related to the tearing mode instability in the magnetar magnetosphere as discussed by Lyutikov (2002), and can produce the radio flux corresponding to the observed $\sim$ 30 Jy from the mERB using a simple scaling of the burst energy.",Physics
"Distribution and kinematics of molecular gas in the central region of the barred spiral galaxy Maffei 2 were investigated using a data set of 12CO(1-0), 12CO(2-1), CS(2-1) lines and 103 GHz continuum. We found that the offset ridges along the kpc-scale bar continue to the central spiral structure embedded in the weak oval structure which is regarded as x2 orbit in the bar potential. The spiral structure continues toward the center diverging from the oval structure. The size of these structures is less than R ~ 100 pc. The mass concentration within R = 35 pc is estimated to be 2 X 10^8 Mo. The high mass concentration is consistent with theoretical predictions concerning the creation of such a nuclear spiral structure. A comparison with the tracers of dense gas and star-forming region suggests that the dense molecular gas traced by CS(2-1) line is formed at the crossing points of x1 and x2 orbits and the star-forming region appears after 2 X 10^5 yr which is comparable with the free-fall time of the dense gas traced by the CS line (~ 10^5 cm^-3).",Physics
The absorption of electromagnetic radiation of an anisotropic quantum dot is theoretically investigated taking into account the processes associated with simultaneous scattering from ionized impurities. It is shown that the scattering of electrons by impurities leads to the resonance absorption even if we have only one impurity in the quantum dot. Explicit formula is derived for the absorption coefficient. The positions of the resonances peaks are found. The effects of external magnetic field on the resonance absorption are studied.,Physics
"A correlated random walk approach to diffusion is applied to the disordered nonoverlapping Lorentz gas. By invoking the Lu-Torquato theory for chord-length distributions in random media [J. Chem. Phys. 98, 6472 (1993)], an analytic expression for the diffusion constant in arbitrary number of dimensions d is obtained. The result corresponds to an Enskog-like correction to the Boltzmann prediction, being exact in the dilute limit, and better or nearly exact in comparison to renormalized kinetic theory predictions for all allowed densities in d=2,3. Extensive numerical simulations were also performed to elucidate the role of the approximations involved.",Physics
An approximation of the density of states for the Ising and Potts models based on the high- and low-temperature series are developed.,Physics
"In this work we use a sample of 318 radio-quiet quasars (RQQ) to investigate the dependence of the ratio of optical/UV flux to X-ray flux, alpha_ox, and the X-ray photon index, Gamma_X, on black hole mass, UV luminosity relative to Eddington, and X-ray luminosity relative to Eddington. Our sample is drawn from the SDSS, with X-ray data from ROSAT and Chandra, and optical data mostly from the SDSS; 153 of these sources have estimates of Gamma_X from Chandra. We estimate M_BH using standard estimates derived from the Hbeta, Mg II, and C IV broad emission lines. Our sample spans a broad range in black hole mass (10^6 < M_BH / M_Sun < 10^10) and redshift (z < 4.8). We find that alpha_ox increases with increasing M_BH and L_UV / L_Edd, and decreases with increasing L_X / L_Edd. In addition, we confirm the correlation seen in previous studies between Gamma_X and M_BH and both L_UV / L_Edd and L_X / L_Edd; however, we also find evidence that the dependence of Gamma_X of these quantities is not monotonic, changing sign at M_BH ~ 3 x 10^8 M_Sun. We argue that the alpha_ox correlations imply that the fraction of bolometric luminosity emitted by the accretion disk, as compared to the corona, increases with increasing accretion rate relative to Eddington. In addition, we argue that the Gamma_X trends are caused by a dependence of X-ray spectral index on accretion rate. We discuss our results within the context of accretion models with comptonizing corona, and discuss the implications of the alpha_ox correlations for quasar feedback. To date, this is the largest study of the dependence of RQQ X-ray parameters on black hole mass and related quantities, and the first to attempt to correct for the large statistical uncertainty in the broad line mass estimates.",Physics
"The behavior of the relative magnesium abundances in the thin-disk stars versus their orbital radii suggests that the star formation rate in the thin disk decreases with increasing Galactocentric distance, and there was no star formation for some time outside the solar circle while this process was continuous within the solar circle. The decrease in the star formation rate with increasing Galactocentric distance is responsible for the existence of a negative radial metallicity gradient in the thin disk. At the same time the relative magnesium abundance exhibits no radial gradient. It is in detail considered the influence of selective effects on the form of both age - metallicity and age - relative magnesium abundance diagrams. It is shown that the first several billion years of the formation of the thin disk interstellar medium in it was on the average sufficiently rich in heavy elements (<[Fe/H]> = -0.22), badly mixed (\sigma_[Fe/H] = 0.21), and the average relative magnesium abundance was comparatively high (<[Mg/Fe]> = 0.10). Approximately 5 billion years ago average metallicity began to systematically increase, and its dispersion and the average relative magnesium abundance - to decrease. These properties may be explained by an increase in star formation rate with the simultaneous intensification of the processes of mixing the interstellar medium in the thin disk, provoke possible by interaction the Galaxy with the completely massive by satellite galaxy.",Physics
"The physical characteristics of the Lyman-alpha forest cloud systems are combined with observations on the baryonic mass density of the Universe and constraints from primordial nucleosynthesis to set boundary conditions on the Intergalactic Medium (IGM) at the epoch of z=2.5. The Universe is considered a closed system and allowed to expand adiabatically from the epoch when QSOs first ionized the IGM (5 <= z_on <= 20). The average kinetic energy of a gas is calculated in the region where the gas transitions from relativistic to non-relativistic behavior. All of the above measurements are then used to determine the thermal history of the IGM in the redshift range 2.5 <= z <= z_on. The hot IGM is assumed to inverse Compton scatter photons from the Cosmic Microwave Background (CMBR) and consequently distort the CMBR as seen at the present epoch. The temperature of the IGM at z=2.5 and the epoch z_on are adjusted, within the constraints defined above, to give the best overall agreement with published data on the temperature of the IGM. We find that the model of the IGM proposed here does not grossly distort the CMBR, and in fact agrees quite closely with the preliminary results from the Cosmic Background Explorer (COBE) satellite. However, our model of the IGM cannot explain the observed cosmic x ray background.   This paper was originally written in 1990. It was never submitted for publication.",Physics
"Luminous X-ray outbursts with variability amplitudes as high as ~1000 have been detected from a small number of galactic nuclei. These events are likely associated with transient fueling of nuclear supermassive black holes. In this paper, we constrain X-ray outbursts with harder spectra, higher redshifts, and lower luminosities than have been studied previously. We performed a systematic survey of 24668 optical galaxies in the Chandra Deep Fields to search for such X-ray outbursts; the median redshift of these galaxies is ~0.8. The survey spans 798 days for the Chandra Deep Field-North, and 1828 days for the Chandra Deep Field-South. No outbursts were found, and thus we set upper limits on the rate of such events in the Universe, which depend upon the adopted outburst X-ray luminosity. For an outburst with X-ray luminosity $\ga 10^{43}$ ergs/s and a duration of 6 months, the upper limit on its event rate is ~10^{-4} /galaxy/yr, roughly consistent with theoretical predictions. Compared to previous survey results, our harder-band and deeper survey suggests that the outburst rate may increase by a maximum factor of 10 when considering both obscured X-ray outbursts and redshift evolution from z~0 to z~0.8. Our results also suggest that the X-ray luminosity function for moderate-luminosity active galactic nuclei is not primarily due to stellar tidal disruptions.",Physics
"Recent Spitzer observations have revealed a substantial population of z~2 ULIRGs with deep silicate absorption (\tau_{9.7}>1). This paper reports a 20cm radio study of such a sample to elucidate their physical nature. We discover that a substantial fraction (40%) of deep silicate absorption ULIRGs at z~2 are moderately radio-loud with L_{1.4GHz}=10^{25}--10^{26}WHz^{-1}. This is in strong contrast with z<1 radio galaxies and radio-loud quasars where none of the sources with available IRS spectra have \tau_{9.7}>1. In addition, we observe radio jets in two of our sources where one has a double lobe structure ~200kpc in extent, and another shows a one-sided jet extending ~90kpc from the nucleus. The likely high inclination of the latter, coupled with its deep silicate absorption, implies the mid-IR obscuration does not share an axis with the radio jets. These sources are highly obscured quasars, observed in the transition stage after the birth of the radio source, but before feedback effects dispel the ISM and halt the black hole accretion and starburst activity.",Physics
"Precise determinations of the chemical composition in early B-type stars consitute fundamental observational constraints on stellar and galactochemical evolution. Carbon is one of the most abundant metals in the Universe but analyses in early-type stars show inconclusive results, like large discrepancies between analyses of different lines in C II, a failure to establish the C II/III ionization balance and the derivation of systematically lower abundances than from other objects. We present a comprehensive and robust C II/III/IV model for non-LTE line-formation calculations based on carefully selected atomic data. The model is calibrated with high-S/N spectra of six apparently slow-rotating early B-type dwarfs and giants, which cover a wide parameter range and are randomly distributed in the solar neighbourhood. A self-consistent quantitative spectrum analysis is performed using an extensive iteration scheme to determine stellar atmospheric parameters and to select the appropriate atomic data used for the derivation of chemical abundances. We establish the carbon ionization balance for all sample stars based on a unique set of input atomic data, achieving consistency for all modelled lines. Highly accurate atmospheric parameters and a homogeneous carbon abundance with reduced systematic errors are derived. This results in a present-day stellar carbon abundance in the solar neighbourhood, which is in good agreement with recent determinations of the solar value and with the gas-phase abundance of the Orion H II region. The homogeneous present-day carbon abundance also conforms with predictions of chemical-evolution models for the Galaxy. The present approach allows us to constrain the effects of systematic errors on fundamental parameters and abundances. (abridged)",Physics
"Reducing the complexity of large systems described as complex networks is key to understand them and a crucial issue is to know which properties of the initial system are preserved in the reduced one. Here we use random walks to design a coarse-graining scheme for complex networks. By construction the coarse-graining preserves the slow modes of the walk, while reducing significantly the size and the complexity of the network. In this sense our coarse-graining allows to approximate large networks by smaller ones, keeping most of their relevant spectral properties.",Physics
"We use particle image velocimetry to measure the sedimentation dynamics of a semi-dilute suspension of non-Brownian spheres at Reynolds numbers, $0.001\le Re\le 2.3$, extending from the Stokes to the moderately inertial regime. We find that the onset of inertial corrections to Stokes sedimentation occurs when the inertial screening length $l=a/Re$ becomes similar to the Stokes sedimentation length $\xi_0$, at $Re_c= a/\xi_0\approx 0.05$. For $Re>Re_c$, inertial screening significantly reduces both the magnitude and spatial extent of the particle velocity fluctuations. A modified Hinch force balance model connects the fluctuation magnitudes $\sigma_V/V$ to the correlation sizes $\xi$.",Physics
"We have studied the temperature dependence of the photoemission spectra of Pr$_{1-x}$Ca$_x$MnO$_3$ (PCMO) with $x=0.25$, 0.3 and 0.5. For $x=0.3$ and 0.5, we observed a gap in the low-temperature CE-type charge-ordered (CO) phase and a pseudogap with a finite intensity at the Fermi level ($E_F$) in the high-temperature paramagnetic insulating (PI) phase. Within the CO phase, the spectral intensity near $E_F$ gradually increased with temperature. These observations are consistent with the results of Monte Carlo simulations on a model including charge ordering and ferromagnetic fluctuations [H. Aliaga {\it et al.} Phys. Rev. B {\bf 68}, 104405 (2003)]. For $x=0.25$, on the other hand, little temperature dependence was observed within the low-temperature ferromagnetic insulating (FI) phase and the intensity at $E_F$ remained low in the high-temperature PI phase. We attribute the difference in the temperature dependence near $E_F$ between the CO and FI phases to the different correlation lengths of orbital order between both phases. Furthermore, we observed a chemical potential shift with temperature due to the opening of the gap in the FI and CO phases. The doping dependent chemical potential shift was recovered at low temperatures, corresponding to the disappearance of the doping dependent change of the modulation wave vector. Spectral weight transfer with hole concentration was clearly observed at high temperatures but was suppressed at low temperatures. We attribute this observation to the fixed periodicity with hole doping in PCMO at low temperatures.",Physics
"We use optical tweezers to perform stretching experiments on DNA molecules when interacting with the drugs daunomycin and ethidium bromide, which intercalate the DNA molecule. These experiments are performed in the low-force regime from zero up to 2 pN. Our results show that the persistence length of the DNA-drug complexes increases strongly as the drug concentration increases up to some critical value. Above this critical value, the persistence length decreases abruptly and remains practically constant for larger drug concentrations. The contour length of the molecules increases monotonically and saturates as drugs concentration increases. Measured in- tercalants critical concentrations for the persistence length transition coincide with reported values for the helix-coil transition of DNA-drug complexes, obtained from sedimentation experiments.",Physics
"Ettore Majorana was a member of Enrico Fermi's research group in Rome, Italy. Fermi did regard Majorana as much brihter than himself as far as theoretical physics was concerned (more information can be found particularly in the arXives' e-print physics/9810023, in Italian, and refs therein, and also in the recent multilanguage arXiv:0708.2855v1 [physics.hist-ph]). In 1937 Majorana partecipated in the national Italian competition, for a chair in theoretical phyics, requested by Emilio Segre' at that time at Palermo University: Other competitors being GC.Wick, G.Racah, and G.Gentile jr. After a proposal of the judging Commette, chaired by E.Fermi, Majorana got a full-professorship at Naples University, for exceptional scientific merits, outside the competition normal procedures. In this e-print we make known the notes prepared by Majorana for his Inaugural Lecture (and discovered long ago, in 1973, by one of the present editors (ER)),together with some comments of ours: everything being both in English (first article) and in Italian (second article, with a short Bibliography at its end). The present articles have been prepared on the occasion of the Centenary (2006) of Majorana's birth. The preliminary notes for his Inaugural Lecture reveal Majorana's interest not only for scientific research, but also for the best didactical methods to be followed in order to teach classical and quantum physics in the most effective way (while his approach to Special Relativity is known to us from his lecture notes, published elesewhere). P.S.: Il Riassunto in Italiano appare all'inizio della versione italiana.",Physics
"We present deep, wide-field g and r photometry of the transition type dwarf galaxy Leo T, obtained with the blue arm of the Large Binocular Telescope. The data confirm the presence of both very young (<1 Gyr) as well as much older (>5 Gyr) stars. We study the structural properties of the old and young stellar populations by preferentially selecting either population based on their color and magnitude. The young population is significantly more concentrated than the old population, with half-light radii of 104+-8 and 148+-16 pc respectively, and their centers are slightly offset. Approximately 10% of the total stellar mass is estimated to be represented by the young stellar population. Comparison of the color-magnitude diagram (CMD) with theoretical isochrones as well as numerical CMD-fitting suggest that star formation began over 10 Gyr ago and continued in recent times until at least a few hundred Myr ago. The CMD-fitting results are indicative of two distinct star formation bursts, with a quiescent period around 3 Gyr ago, albeit at low significance. The results are consistent with no metallicity evolution and [Fe/H] ~ -1.5 over the entire age of the system. Finally, the data show little if any sign of tidal distortion of Leo T.",Physics
We present a detailed study of the spectral properties of a locally correlated site embedded in a BCS superconducting medium. To this end the Anderson impurity model with superconducting bath is analysed by numerical renormalisation group (NRG) calculations. We calculate one and two-particle dynamic response function to elucidate the spectral excitation and the nature of the ground state for different parameter regimes with and without particle-hole symmetry. The position and weight of the Andreev bound states is given for all relevant parameters. We also present phase diagrams for the different ground state parameter regimes. This work is also relevant for dynamical mean field theory extensions with superconducting symmetry breaking.,Physics
"In cold dark matter cosmological models, the first stars to form are believed to do so within small protogalaxies. We wish to understand how the evolution of these early protogalaxies changes once the gas forming them has been enriched with small quantities of heavy elements, which are produced and dispersed into the intergalactic medium by the first supernovae. Our initial conditions represent protogalaxies forming within a fossil H II region, a previously ionized region that has not yet had time to cool and recombine. We study the influence of low levels of metal enrichment on the cooling and collapse of ionized gas in small protogalactic halos using three-dimensional, smoothed particle hydrodynamics (SPH) simulations that incorporate the effects of the appropriate chemical and thermal processes. Our previous simulations demonstrated that for metallicities Z < 0.001 Z_sun, metal line cooling alters the density and temperature evolution of the gas by less than 1% compared to the metal-free case at densities below 1 cm-3) and temperatures above 2000 K. Here, we present the results of high-resolution simulations using particle splitting to improve resolution in regions of interest. These simulations allow us to address the question of whether there is a critical metallicity above which fine structure cooling from metals allows efficient fragmentation to occur, producing an initial mass function (IMF) resembling the local Salpeter IMF, rather than only high-mass stars.",Physics
"Sub-gap conductance at a large area junction with a rough interface of a ferromagnet and a high-T$_{C}$ superconductor is superimposed by multiple peaks which is not expected from an ideal point contact Andreev reflection process. We demonstrate this phenomenon by measuring resistance as a function of bias voltage of a Co/Y$_{1}$Ba$_{2}$Cu$_{3}$O$_{7-\delta}$ junction with contact area 50 x 70 $\mu$ $m^{2}$ at various temperatures. In order to analyze such Andreev reflection data, the interface is assumed to have random potentials which can create local electric fields. The Blonder-Tinkham-Klapwijk theory is modified with the inclusion of a broadening parameter due to finite life time effects of quasi particles. An additional voltage drop due to local electric fields at the rough interface has been included in terms of an extra energy shift which may be related to the asymmetry of normalized resistance data. Spin polarization has been introduced for the ferromagnet. The presented model explains the multi-peak nature and asymmetry of Andreev reflection data experimentally observed at large area junctions. Extension of the model also interprets the experimentally observed anomalous enhancement of resistance peaks in the sub-gap region which may result from crossing the critical current limit across the junction.",Physics
"We have used the Australia Telescope Compact Array (ATCA) at 95GHz to carry out continuum observations of 130 extragalactic radio sources selected from the Australia Telescope 20GHz (AT20G) survey. Over 90% of these sources are detected at 95 GHz, and we use a triple-correlation method to measure simultaneous 20 and 95 GHz flux densities. We show that the ATCA can measure 95GHz flux densities to ~10% accuracy in a few minutes for sources above ~50mJy.   The median 20-95GHz spectral index does not vary significantly with flux density for extragalactic sources with S20>150 mJy. This allows us to estimate the extragalactic radio source counts at 95GHz by combining our observed 20-95GHz spectral-index distribution with the accurate 20GHz source counts measured in the AT20G survey. The resulting 95GHz source counts down to 80 mJy are significantly lower than those found by several previous studies. The main reason is that most radio sources with flat or rising spectra in the frequency range 5-20GHz show a spectral turnover between 20 and 95 GHz. As a result, there are fewer 95GHz sources (by almost a factor of two at 0.1 Jy) than would be predicted on the basis of extrapolation from the source populations seen in lower-frequency surveys. We also derive the predicted confusion noise in CMB surveys at 95GHz and find a value 20-30% lower than previous estimates.   The 95GHz source population at the flux levels probed by this study is dominated by QSOs with a median redshift z~1. We find a correlation between optical magnitude and 95GHz flux density which suggests that many of the brightest 95 GHz sources are relativistically beamed, with both the optical and millimetre continuum significantly brightened by Doppler boosting.",Physics
"We report a serendipitous detection of an intense X-ray flare from the Tycho reference source HD 161084 during a Suzaku observation of the Galactic Center region for 20 ks. The X-ray Imaging Spectrometer (XIS) recorded a flare from this A1-type dwarf or subgiant star with a flux of 1.4x10^{-12} erg s^{-1} cm^{-2} (0.5--10 keV) and a decay time scale of 0.5 hr. The spectrum is hard with a prominent Fe XXV K alpha emission line at 6.7 keV, which is explained by a 5 keV thin-thermal plasma model attenuated by a 1.4x10^{21} cm^{-2} extinction. The low extinction, which is consistent with the optical reddening, indicates that the source is a foreground star toward the Galactic Center region. Based on the spectroscopic parallax distance of 530 pc, the peak X-ray luminosity amounts to 1x10^{32} erg s^{-1} (0.5--10 keV). This is much larger than the X-ray luminosity of ordinary late-type main-sequence stars, and the X-ray emission is unattributable to a hidden late-type companion that comprises a wide binary system with the A-star. We discuss possible natures of HD 161084 and suggest that it is most likely an interacting binary with elevated magnetic activity in the companion such as the Algol-type system. The flux detected by Suzaku during the burst is 100 times larger than the quiescent level measured using the archived XMM-Newton and Chandra data. The large flux amplification makes this star a unique example among sources of this class.",Physics
"We present a set of four Gemini-North GMOS/IFU observations of the central disturbed regions of the dwarf irregular starburst galaxy NGC 1569, surrounding the well-known super star clusters A and B. This continues on directly from a companion paper, in which we describe the data reduction and analysis techniques employed and present the analysis of one of the IFU pointings. By decomposing the emission line profiles across the IFU fields, we map out the properties of each individual component identified and identify a number of relationships and correlations that allow us to investigate in detail the state of the ionized ISM. Our observations support and expand on the main findings from the analysis of the first IFU position, where we conclude that a broad (< 400 km/s) component underlying the bright nebular emission lines is produced in a turbulent mixing layer on the surface of cool gas knots, set up by the impact of the fast-flowing cluster winds. We discuss the kinematic, electron density and excitation maps of each region in detail and compare our results to previous studies. Our analysis reveals a very complex environment with many overlapping and superimposed components, including dissolving gas knots, rapidly expanding shocked shells and embedded ionizing sources, but no evidence for organised bulk motions. We conclude that the four IFU positions presented here lie well within the starburst region where energy is injected, and, from the lack of substantial ordered gas flows, within the quasi-hydrostatic zone of the wind interior to the sonic point. The net outflow occurs at radii beyond 100-200 pc, but our data imply that mass-loading of the hot ISM is active even at the roots of the wind.",Physics
"We study the spreading of an infection within an SIS epidemiological model on a network. Susceptible agents are given the opportunity of breaking their links with infected agents, and reconnecting those links with the rest of the population. Thus, the network coevolves with the population as the infection progresses. We show that a moderate reconnection frequency is enough to completely suppress the infection. A partial, rather weak isolation of infected agents suffices to eliminate the endemic state.",Physics
"High resolution measurements of the dynamic magnetic susceptibility are reported for ferromagnetic re-entrant superconductor, ErRh$_{4}$B$_{4}$. Detailed investigation of the coexisting regime reveals unusual temperature-asymmetric and magnetically anisotropic behavior. The superconducting phase appears via a series of discontinuous steps upon warming from the ferromagnetic normal phase, whereas the ferromagnetic phase develops via a gradual transition. A model based on local field inhomogeneity is proposed to explain the observations.",Physics
"Radial tidal forces can be compressive instead of disruptive, a possibility that is frequently overlooked in high level physics courses. For example, radial tidal compression can emerge in extended stellar systems containing a smaller stellar cluster. For particular conditions the tidal field produced by this extended mass distribution can exert on the cluster it contains compressive effects instead of the common disruptive forces. This interesting aspect of gravity can be derived from standard relations given in many textbooks and introductory courses in astronomy and can serve as an opportunity to look closer at some aspects of gravitational physics, stellar dynamics, and differential geometry. The existence of compressive tides at the center of huge stellar systems might suggest new evolutionary scenarios for the formation of stars and primordial galactic formation processes.",Physics
"We used multiwavelength data (HI, FUV, NUV, R) to search for evidence of star formation in the intragroup medium of the Hickson Compact Group 100. We find that young star-forming regions are located in the intergalactic HI clouds of the compact group which extend to over 130 kpc away from the main galaxies. A tidal dwarf galaxy candidate is located in the densest region of the HI tail, 61 kpc from the brightest group member and its age is estimated to be only 3.3 Myr. Fifteen other intragroup HII regions and TDG candidates are detected in the GALEX FUV image and within a field 10'x10' encompassing the HI tail. They have ages <200 Myr, HI masses of 10^(9.2-10.4) Msun, 0.001< SFR <0.01 Msun yr^-1, and stellar masses 10^4.3--10^6.5 Msun. The HI clouds to which many of them are associated have column densities about one order of magnitude lower than N(HI)~10^21 cm^-2.",Physics
"A toroidal trap combined with external time-dependent electric field can be used for implementing different dynamical regimes of matter waves. In particular, we show that dynamical and stochastic acceleration, localization and implementation of the Kapitza pendulum can be originated by means of proper choice of the external force.",Physics
"Dark energy dominates the energy density of our Universe, yet we know very little about its nature and origin. Although strong evidence in support of dark energy is provided by the cosmic microwave background, the relic radiation of the Big Bang, in conjunction with either observations of supernovae or of the large scale structure of the Universe, the verification of dark energy by independent physical phenomena is of considerable interest. We review works that, through a wavelet analysis on the sphere, independently verify the existence of dark energy by detecting the integrated Sachs-Wolfe effect. The effectiveness of a wavelet analysis on the sphere is demonstrated by the highly statistically significant detections of dark energy that are made. Moreover, the detection is used to constrain properties of dark energy. A coherent picture of dark energy is obtained, adding further support to the now well established cosmological concordance model that describes our Universe.",Physics
"Different computational methods are employed to evaluate elastic (rotationally summed) integral and differential cross sections for low energy (below about 10 eV) positron scattering off gas-phase C$_2$H$_2$ molecules. The computations are carried out at the static and static-plus-polarization levels for describing the interaction forces and the correlation-polarization contributions are found to be an essential component for the correct description of low-energy cross section behavior. The local model potentials derived from density functional theory (DFT) and from the distributed positron model (DPM) are found to produce very high-quality agreement with existing measurements. On the other hand, the less satisfactory agreement between the R-matrix (RM) results and measured data shows the effects of the slow convergence rate of configuration-interaction (CI) expansion methods with respect to the size of the CI-expansion. To contrast the positron scattering findings, results for electron-C$_2$H$_2$ integral and differential cross sections, calculated with both a DFT model potential and the R-matrix method, are compared and analysed around the shape resonance energy region and found to produce better internal agreement.",Physics
"The Atacama Large Millimeter Array (ALMA) will consist of up to 64 state-of-the-art sub-mm telescopes, subject to stringent performance specifications which will push the boundaries of the technology, and makes testing of antenna performance a likewise challenging task. Two antenna prototypes were evaluated at the ALMA Test Facility at the Very Large Array site in New Mexico, USA. The dynamic behaviour of the antennas under operational conditions was investigated with the help of an accelerometer system capable of measuring rigid body motion of the elevation structure of the antenna, as well as a few low-order deformation modes, resulting in dynamic performance numbers for pointing stability, reflector surface stability, path length stability, and structure flexure. Special emphasis was given to wind effects, one of the major factors affecting performance on timescales of seconds to tens of minutes. This paper describes the accelerometer system, its capabilities and limitations, and presents the dynamic performance results of the two prototype antennas investigated.",Physics
"The 2006 meeting in Xi'an on the Central Engine of Active Galactic Nuclei covered the enormous and continuously expanding area of AGN research, from theory to the most sophisticated observations and from gamma-ray energies to long radio wavelengths. This short summary gives some, but definitely not all, highlights and new results presented by the participants.",Physics
"The interaction of accretion disks with the magnetospheres of young stars can produce X-winds and funnel flows. With the assumption of axial symmetry and steady state flow, the problem can be formulated in terms of quantities that are conserved along streamlines, such as the Bernoulli integral (BI), plus a partial differential equation (PDE), called the Grad-Shafranov equation (GSE), that governs the distribution of streamlines in the meridional plane. The GSE plus BI yields a PDE of mixed type, elliptic before critical surfaces where the flow speed equals certain characteristic wave speeds are crossed and hyperbolic afterward. The computational difficulties are exacerbated by the locations of the critical surfaces not being known in advance. To overcome these obstacles, we consider a variational principle by which the GSE can be attacked by extremizing an action integral, with all other conserved quantities of the problem explicitly included as part of the overall formulation. To simplify actual applications we adopt the cold limit of a negligibly small ratio of the sound speed to the speed of Keplerian rotation in the disk where the X-wind is launched. We also ignore the obstructing effects of any magnetic fields that might thread a disk approximated to be infinitesimally thin. We then introduce trial functions with adjustable coefficients to minimize the variations that give the GSE. We tabulate the resulting coefficients so that other workers can have analytic forms to reconstruct X-wind solutions for various astronomical, cosmochemical, and meteoritical applications.",Physics
"We present Hubble Space Telescope NICMOS H-band imaging of 33 Ultraluminous Infrared Galaxies (ULIRGs) at z~2 that were selected from the 24 micron catalog of the Spitzer Extragalactic First Look Survey. The images reveal that at least 17 of the 33 objects are associated with interactions. Up to one fifth of the sources in our sample could be minor mergers whereas only 2 systems are merging binaries with luminosity ratio <=3:1, which is characteristic of local ULIRGs. The rest-frame optical luminosities of the sources are of the order 10^10-10^11 L_sun and their effective radii range from 1.4 to 4.9 kpc. The most compact sources are either those with a strong active nucleus continuum or those with a heavy obscuration in the mid-infrared regime, as determined from Spitzer Infra-Red Spectrograph data. The luminosity of the 7.7 micron feature produced by polycyclic aromatic hydrocarbon molecules varies significantly among compact systems whereas it is typically large for extended systems. A bulge-to-disk decomposition performed for the 6 brightest (m_H<20) sources in our sample indicates that they are best fit by disk-like profiles with small or negligible bulges, unlike the bulge-dominated remnants of local ULIRGs. Our results provide evidence that the interactions associated with ultraluminous infrared activity at z~2 can differ from those at z~0.",Physics
"We consider dense rapid shear flow of inelastically colliding hard disks. Navier-Stokes granular hydrodynamics is applied accounting for the recent finding \cite{Luding,Khain} that shear viscosity diverges at a lower density than the rest of constitutive relations. New interpolation formulas for constitutive relations between dilute and dense cases are proposed and justified in molecular dynamics (MD) simulations. A linear stability analysis of the uniform shear flow is performed and the full phase diagram is presented. It is shown that when the inelasticity of particle collision becomes large enough, the uniform sheared flow gives way to a two-phase flow, where a dense ""solid-like"" striped cluster is surrounded by two fluid layers. The results of the analysis are verified in event-driven MD simulations, and a good agreement is observed.",Physics
"We have performed high-resolution cosmological N-body simulations of a concordance LCDM model to study the evolution of virialized, dark matter haloes in the presence of primordial non-Gaussianity. Following a standard procedure, departures from Gaussianity are modeled through a quadratic Gaussian term in the primordial gravitational potential, characterized by a dimensionless non-linearity strength parameter f_NL. We find that the halo mass function and its redshift evolution closely follow the analytic predictions of Matarrese et al.(2000). The existence of precise analytic predictions makes the observation of rare, massive objects at large redshift an even more attractive test to detect primordial non-Gaussian features in the large scale structure of the universe.",Physics
"A new scanning Fabry-Perot system will soon be available at the Nasmyth focus of the 4,2m William Hershell Telescope (WHT). It has been designed by the Laboratoire d'Astrophysique Experimentale (LAE) in Montreal and is being built in collaboration with astronomers at the Instituto de Astrofisica de Canarias (IAC). The instrument will see first light at the beginning of July 2007.",Physics
"We present high resolution N-body/SPH simulations of the interacting cluster 1E0657-56. The main and the sub-cluster are modeled using extended cuspy LCDM dark matter halos and isothermal beta-profiles for the collisional component. The hot gas is initially in hydrostatic equilibrium inside the global potential of the clusters. We investigate the X-ray morphology and derive the most likely impact parameters, mass ratios and initial relative velocities. We find that the observed displacement between the X-ray peaks and the associated mass distribution, the morphology of the bow shock, the surface brightness and projected temperature profiles across the shock discontinuity can be well reproduced by offset 1:6 encounters where the sub-cluster has initial velocity (in the rest frame of the main cluster) close to 2 times the virial velocity of the main cluster dark matter halo. A model with the same mass ratio and lower velocity (1.5 times the main cluster virial velocity) matches quite well most of the observations. However, it does not reproduce the morphology of the main cluster peak. Dynamical friction strongly affects the kinematics of the sub-cluster so that the low velocity bullet is actually bound to the main system at the end of the simulation. We find that a relatively high concentration (c=6) of the main cluster dark matter halo is necessary in order to prevent the disruption of the associated X-ray peak. For a selected sub-sample of runs we perform a detailed three dimensional analysis following the past, present and future evolution of the interacting systems. In particular, we investigate the kinematics of the gas and dark matter components as well as the changes in the density profiles and the motion of the system in the L_X-T diagram.",Physics
"Based on Landau-Devonshire (LD) phenomenological theory, phase diagram of epitaxial BST50/50 thin films on anisotropic in-plane strains is investigated. Different from BaTiO3 thin films, the paraelectric phase appears under the anisotropic misfit strains on BST50/50 thin films at the room temperature. The pyroelectric property of the BST films is also calculated, we find that the position of pyroelectric peak greatly depends on anisotropic misfit strains. Keywords: anisotropic in-plane strains; BST thin films; phase diagram",Physics
"Our previous point-contact Andreev reflection studies of the heavy-fermion superconductor CeCoIn$_5$ using Au tips have shown two clear features: reduced Andreev signal and asymmetric background conductance [1]. To explore their physical origins, we have extended our measurements to point-contact junctions between single crystalline heavy-fermion metals and superconducting Nb tips. Differential conductance spectra are taken on junctions with three heavy-fermion metals, CeCoIn$_5$, CeRhIn$_5$, and YbAl$_3$, each with different electron mass. In contrast with Au/CeCoIn$_5$ junctions, Andreev signal is not reduced and no dependence on effective mass is observed. A possible explanation based on a two-fluid picture for heavy fermions is proposed. [1] W. K. Park et al., Phys. Rev. B 72 052509 (2005); W. K. Park et al., Proc. SPIE-Int. Soc. Opt. Eng. 5932 59321Q (2005); W. K. Park et al., Physica C (in press) (cond-mat/0606535).",Physics
"We present data from high-resolution numerical simulations of the Navier-Stokes-$\alpha$ and the Leray-$\alpha$ models for two-dimensional turbulence. It was shown previously (Lunasin et al., J. Turbulence, 8, (2007), 751-778), that for wavenumbers $k$ such that $k\alpha\gg 1$, the energy spectrum of the smoothed velocity field for the two-dimensional Navier-Stokes-$\alpha$ (NS-$\alpha$) model scales as $k^{-7}$. This result is in agreement with the scaling deduced by dimensional analysis of the flux of the conserved enstrophy using its characteristic time scale. We therefore hypothesize that the spectral scaling of any $\alpha$-model in the sub-$\alpha$ spatial scales must depend only on the characteristic time scale and dynamics of the dominant cascading quantity in that regime of scales. The data presented here, from simulations of the two-dimensional Leray-$\alpha$ model, confirm our hypothesis. We show that for $k\alpha\gg 1$, the energy spectrum for the two-dimensional Leray-$\alpha$ scales as $k^{-5}$, as expected by the characteristic time scale for the flux of the conserved enstrophy of the Leray-$\alpha$ model. These results lead to our conclusion that the dominant directly cascading quantity of the model equations must determine the scaling of the energy spectrum.",Physics
"Magnetic x-ray diffraction combined with x-ray focusing optics is used to image individual antiferromagnetic spin density wave domains in a chromium single crystal at the micron scale. The cross section for non-resonant magnetic x-ray scattering depends on the antiferromagnetic modulation vector and spin polarization direction and allows these quantities to be extracted independently. The technique is used to show that the broadening of the nominally first order ""spin-flip"" transition at 123 K, at which the spins rotate by 90 deg., originates at the walls between domains with orthogonal modulation vectors. During cooling the transition begins at these walls and progresses inwards. The modulation-vector domains are themselves unchanged.",Physics
"Two dimensional suspensions of spherical colloids subject to periodic external fields exhibit a rich variety of molecular crystalline phases. We study in simulations the ground state configurations of dimeric and trimeric systems, that are realized on square and triangular lattices, when either two or three macroions are trapped in each external potential minimum. Bipartite orders of the checkerboard or stripe types are reported together with more complex quadripartite orderings, and the shortcomings of envisioning the colloids gathered in a single potential minimum as a composite rigid object are discussed. This work also sheds light on simplifying assumptions underlying previous theoretical treatments and that made possible the mapping onto spin models.",Physics
"Water ice and spin ice are important model systems in which theory can directly account for zero point entropy associated with quenched configurational disorder. Spin ice differs from water ice in the important respect that its fundamental constituents, the spins of the magnetic ions, can be removed through replacement with non-magnetic ions while keeping the lattice structure intact. In order to investigate the interplay of frustrated interactions and quenched disorder, we have performed systematic heat capacity measurements on spin ice materials which have been thus diluted up to 90%. Investigations of both Ho and Dy spin ices reveal that the zero point entropy depends non-monotonically on dilution and approaches the value of Rln2 in the limit of high dilution. The data are in good agreement with a generalization of Pauling's theory for the entropy of ice.",Physics
"We consider the voltage structure in the open-field circuit and outer magnetosphere of a magnetar. The standard polar-cap model for radio pulsars is modified significantly when the polar magnetic field exceeds 1.8x10^{14} G. Pairs are created by accelerated particles via resonant scattering of thermal X-rays, followed by the nearly instantaneous conversion of the scattered photon to a pair. A surface gap is then efficiently screened by e+- creation, which regulates the voltage in the inner part of the circuit to ~10^9 V. We also examine the electrostatic gap structure that can form when the magnetic field is somewhat weaker, and deduce a voltage 10-30 times larger over a range of surface temperatures. We examine carefully how the flow of charge back to the star above the gap depends on the magnitude of the current that is extracted from the surface of the star, on the curvature of the magnetic field lines, and on resonant drag. The rates of different channels of pair creation are determined self-consistently, including the non-resonant scattering of X-rays, and collisions between gamma rays and X-rays. We find that the electrostatic gap solution has too small a voltage to sustain the observed pulsed radio output of magnetars unless i) the magnetic axis is nearly aligned with the rotation axis and the light of sight; or ii) the gap is present on the closed as well as the open magnetic field lines. Several properties of the radio magnetars -- their rapid variability, broad pulses, and unusually hard radio spectra -- are consistent with a third possibility, that the current in the outer magnetosphere is strongly variable, and a very high rate of pair creation is sustained by a turbulent cascade.",Physics
"We presents the main physical properties of very young stellar populations seen with FUSE in 24 individual starbursts. These characteristics have been obtained using the evolutionary spectral synthesis technique in the far-ultraviolet range with the LavalSB code. For each starburst, quantitative values for age, metallicity, initial mass function slope, stellar mass, and internal extinction have been obtained and discussed in details. Limits of the code have been tested. One main conclusion is that most starbursts (and probably all of them) cannot be represented by any continuous star formation burst in the far-ultraviolet. Also, quantitative values of various optical diagnostics related to these stellar populations have been predicted. Underlying stellar populations, dominated by B-type stars, have been detected in NGC 1140, NGC 4449, and possibly NGC 3991. We characterized the young stellar populations of less than 5 Myr in Seyfert 2 nuclei.",Physics
"We report the observation of spin-glass-like behavior and strong magnetic anisotropy in extremely smooth (~1-3 \AA) roughness) epitaxial (110) and (010) SrRuO3 thin films. The easy axis of magnetization is always perpendicular to the plane of the film (unidirectional) irrespective of crystallographic orientation. An attempt has been made to understand the nature and origin of spin-glass behavior, which fits well with Heisenberg model.",Physics
"Recent experiments by Y. Gambin et al. [PNAS 103, 2098 (2006)] have called into question the applicability of the Saffman-Delbruck diffusivity for proteins embedded in the lipid bilayers. We present a simple argument to account for this observation that should be generically valid for a large class of transmembrane and membrane bound proteins. Whenever the protein-lipid interactions locally deform the membrane, that deformation generates new hydrodynamic stresses on the protein-membrane complex leading to a suppression of its mobility. We show that this suppression depends on the protein size in a manner consistent with the work of Y. Gambin et al.",Physics
"We study electromagnetic properties of periodic composite structures, such as photonic crystals, involving lossy components. We show that in many cases a properly designed periodic structure can dramatically suppress the losses associated with the absorptive component, while preserving or even enhancing its useful functionality. As an example, we consider magnetic photonic crystals, in which the lossy magnetic component provides nonreciprocal Faraday rotation. We show that the electromagnetic losses in the composite structure can be reduced by up to two orders of magnitude, compared to those of the uniform magnetic sample made of the same lossy magnetic material. Importantly, the dramatic absorption reduction is not a resonance effect and occurs over a broad frequency range covering a significant portion of photonic frequency band.",Physics
"Membrane organization is essential for cellular functions such as signal transduction and membrane trafficking. A major challenge is to understand the lateral heterogeneous structures in membranes and membrane fluidity in the presence of inclusions. Based on a considerable amount of experimental evidence for lateral organization of lipid membranes which share astonishingly similar features in the presence of different inclusions, we first present a general model system of bilayer membranes embedded by nanosized inclusions, and explain experimental findings. Here, the hydrophobic inclusions are simple models of intrinsic membrane proteins, cholesterol embedded in the membrane, hydrophobic drugs, or other nanoparticles for bio-medical applications. It is found that lipid/inclusion-rich raft domains are formed at moderate inclusion concentrations, and disappear with the increase of inclusions. At high inclusion content, chaining of inclusions occurs due to the effective attraction between inclusions mediated by lipids. Meanwhile, increasing inclusions can also cause thickening of the membrane, and the distribution of inclusions undergoes a layering transition from one-layer located in the bilayer midplane to two-layer structure arranged into the two leaflets of a bilayer. Our theoretical predictions address the complex interactions between membranes and inclusions, suggesting a unifying mechanism which reflects the competition between the conformational entropy of lipids favoring the formation of lipid-rich rafts and the steric repulsion of inclusions leading to the uniform dispersion.",Physics
We demonstrate the functionality of spin-wave logic XNOR and NAND gates based on a Mach-Zehnder type interferometer which has arms implemented as sections of ferrite film spin-wave waveguides. Logical input signals are applied to the gates by varying either the phase or the amplitude of the spin waves in the interferometer arms. This phase or amplitude variation is produced by Oersted fields of dc current pulses through conductors placed on the surface of the magnetic films.,Physics
"We examine the conditions necessary for the presence of localized magnetic moments on adatoms with inner shell electrons in graphene. We show that the low density of states at the Dirac point, and the anomalous broadening of the adatom electronic level,lead to the formation of magnetic moments for arbitrarily small local charging energy. As a result, we obtain an anomalous scaling of the boundary separating magnetic and non-magnetic states. We show that, unlike any other material, the formation of magnetic moments can be controlled by an electric field effect.",Physics
"The MAGIC Collaboration is building a second telescope, MAGIC II, improving the design of the current MAGIC Telescope. MAGIC II is being built at 85 m of distance from MAGIC I, and will also feature a huge reflecting surface of ~240 m$^2$ of area. One of the improvement is the design for the mirror of MAGIC II, that are lighter and larger, being square of 1 m of side and weighting around 15 kg. For the development and production of the new mirrors, two different techniques, both reliable and affordable in price, were selected: the diamond milling of aluminium surfaces and the cold slumping of thin glass panes. As tests for the second one are still ongoing, we present a description of the diamond milling technique, and its application and performance to the produced mirrors.",Physics
"We present experimental and theoretical results showing the improved beam quality and reduced divergence of an atom laser produced by an optical Raman transition, compared to one produced by an RF transition. We show that Raman outcoupling can eliminate the diverging lens effect that the condensate has on the outcoupled atoms. This substantially improves the beam quality of the atom laser, and the improvement may be greater than a factor of ten for experiments with tight trapping potentials. We show that Raman outcoupling can produce atom lasers whose quality is only limited by the wavefunction shape of the condensate that produces them, typically a factor of 1.3 above the Heisenberg limit.",Physics
"Spectroscopic observations of the 2006 outburst of the recurrent nova RS Ophiuchi at both infrared (IR) and X-ray wavelengths have shown that the blast wave has decelerated at a higher rate than predicted by the standard test-particle adiabatic shock-wave model. Here we show that the observed evolution of the nova remnant can be explained by the diffusive shock acceleration of particles at the blast wave and the subsequent escape of the highest energy ions from the shock region. Nonlinear particle acceleration can also account for the difference of shock velocities deduced from the IR and X-ray data. The maximum energy that accelerated electrons and protons can have achieved in few days after outburst is found to be as high as a few TeV. Using the semi-analytic model of nonlinear diffusive shock acceleration developed by Berezhko & Ellison, we show that the postshock temperature of the shocked gas measured with RXTE/PCA and Swift/XRT imply a relatively moderate acceleration efficiency.",Physics
"The recent discovery of apparent cosmic acceleration has highlighted the depth of our ignorance of the fundamental properties of nature. It is commonly assumed that the explanation for acceleration must come from a new form of energy dominating the cosmos - dark energy - or a modification of Einstein's theory of Relativity. It is often overlooked, however, that a currently viable alternative explanation of the data is radial inhomogeneity which alters the Hubble diagram without any acceleration. This explanation is often ignored for two reasons: radial inhomogeneity significantly complicates analysis and predictions, and so the full details have not been investigated; and it is a philosophically highly controversial idea, revoking as it does the long-held Copernican Principle. To date, there has not been a general way of determining the validity if the Copernican Principle -- that we live at a typical position in the universe -- significantly weakening the foundations of cosmology as a scientific endeavour. Here we present an observational test for the Copernican assumption which can be automatically implemented while we search for dark energy in the coming decade. Our test is entirely independent of any model for dark energy or theory of gravity and thereby represents a model-independent test of the Copernican Principle.",Physics
"It has been hypothesized that the sustained narrowness observed in the asymptotic cylindrical region of bipolar outflows from Young Stellar Objects (YSO) indicates that these jets are magnetically collimated. The j cross B force observed in z-pinch plasmas is a possible explanation for these observations. However, z-pinch plasmas are subject to current driven instabilities (CDI). The interest in using z-pinches for controlled nuclear fusion has lead to an extensive theory of the stability of magnetically confined plasmas. Analytical, numerical, and experimental evidence from this field suggest that sheared flow in magnetized plasmas can reduce the growth rates of the sausage and kink instabilities. Here we propose the hypothesis that sheared helical flow can exert a similar stabilizing influence on CDI in YSO jets.",Physics
"One of the most surprising discoveries of extrasolar planets is the detection of planets in moderately close binary star systems. The Jovian-type planets in the two binaries of Gamma Cephei and GJ 86 have brought to the forefront questions on the formation of giant planets and the possibility of the existence of smaller bodies in such dynamically complex environments. The diverse dynamical characteristics of these objects have made scientists wonder to what extent the current theories of planet formation can be applied to binaries and multiple star systems. At present, the sensitivity of the detection techniques does not allow routine discovery of Earth-sized bodies in binary systems. However, with the advancement of new techniques, and with the recent launch of CoRoT and the launch of Kepler in late 2008, the detection of more planets (possibly terrestrial-class objects) in such systems is on the horizon. Theoretical studies and numerical modeling of terrestrial and habitable planet formation are, therefore, necessary to gain fundamental insights into the prospects for life in such systems and have great strategic impact on NASA science and missions.",Physics
"We explore the rich internal structure of Cs_2 Feshbach molecules. Pure ultracold molecular samples are prepared in a CO_2-laser trap, and a multitude of weakly bound states is populated by elaborate magnetic-field ramping techniques. Our methods use different Feshbach resonances as input ports and various internal level crossings for controlled state transfer. We populate higher partial-wave states of up to eight units of rotational angular momentum (l-wave states). We investigate the molecular structure by measurements of the magnetic moments for various states. Avoided level crossings between different molecular states are characterized through the changes in magnetic moment and by a Landau-Zener tunneling method. Based on microwave spectroscopy, we present a precise measurement of the magnetic-field dependent binding energy of the weakly bound s-wave state that is responsible for the large background scattering length of Cs. This state is of particular interest because of its quantum-halo character.",Physics
"We study entanglement generation between two charge qubits due to the strong coupling with a common bosonic environment (Ohmic bath). The coupling to the boson bath is a source of both quantum noise (leading to decoherence) and an indirect interaction between qubits. As a result, two effects compete as a function of the coupling strength with the bath: entanglement generation and charge localization induced by the bath. These two competing effects lead to a non-monotonic behavior of the concurrence as a function of the coupling strength with the bath. As an application, we present results for charge qubits based on double quantum dots.",Physics
"The shock-acceleration theory predicts a power-law energy spectrum in the test particle approximation, and there are two ways to calculate a power-law index, Peacock's approximation and Vietri's formulation. In Peacock's approximation, it is assumed that particles cross a shock front many times and energy-gains for each step are fully uncorrelated. On the other hand, correlation of the distribution of an energy-gain factor for a particle is considered in Vietri's formulation. We examine how Peacock's approximation differs from Vietri's formulation. It is useful to know when we can use Peacock's approximation because Peacock's approximation is simple to derive the power-law index. In addition, we focus on how the variance of the energy-gain factor has an influence on the difference between Vietri's formulation and Peacock's approximation. The effect of the variance has not been examined well until now. For demonstration, we consider two cases for the scattering in the upstream: the large-angle scattering (model A) and the regular deflection by large-scale magnetic fields (model B). Especially there is no correlation among the distribution of an energy-gain factor for every step in model A. In this model, we see the power-law index derived from Peacock's approximation differs from the one derived from Vietri's formulation when we consider the mildly-relativistic shock, and the variance of the energy-gain factor affects this difference. We can use Peacock's approximation for a non-relativistic shock and a highly-relativistic shock because the effect of the variance is hidden. In model B, we see the difference of the power-law converging along the shock velocity.",Physics
We argue that the apparent failure of the work-Hamiltonian connection for free energy calculations reported by Vilar and Rubi' (cond-mat arXiv:0704.0761v2) stems from their incorrect expression for the work.,Physics
"Electric current and spacial displacement due to trembling motion [Zitterbewegung (ZB)] of electrons in graphene in the presence of an external magnetic field are described. Contributions of both inequivalent $K$ points in the Brillouin zone of graphene are considered. It is shown that, when the electrons are prepared in the form of wave packets, the presence of a quantizing magnetic field $B$ has very important effects on ZB. (1) For $B\neq 0$ the ZB oscillations are permanent, for B=0 they are transient. (2) For $B\neq 0$ many ZB frequencies appear, for B=0 only one frequency is at work. (3) For $B\neq 0$ both interband and intraband (cyclotron) frequencies contribute to ZB, for B=0 there are no intraband frequencies. (4) Magnetic field intensity changes not only the ZB frequencies but the entire character of ZB spectrum. An emission of electromagnetic dipole radiation by the trembling electrons is proposed and described. It is argued that graphene in a magnetic field is a promising system for an experimental observation of Zitterbewegung.",Physics
"We present numerical simulations of the growth and saturation of the Kelvin-Helmholtz instability in a compressible fluid layer with and without a weak magnetic field. In the absence of a magnetic field, the instability generates a single eddy which flattens the velocity profile, stabilizing it against further perturbations. Adding a weak magnetic field - weak in the sense that it has almost no effect on the linear instability - leads to a complex flow morphology driven by MHD forces and to enhanced broadening of the layer, due to Maxwell stresses. We corroborate earlier studies which showed that magnetic fields destroy the large scale eddy structure through periodic cycles of windup and resistive decay, but we show that the rate of decay decreases with decreasing plasma resistivity, at least within the range of resistivity accessible to our simulations. Magnetization increases the efficiency of momentum transport, and the transport increases with decreasing resistivity.",Physics
"In this paper, it is shown that the cosmological model that was introduced in a sequence of three earlier papers under the title, A Dust Universe Solution to the Dark Energy Problem, can be used to resolve the problem of the great mismatch of numerical values between dark energy from cosmology and zero point energy from quantum theory. It is shown that, if the zero point energies for the cosmic microwave background and for all the rest of the universe that is not cosmic microwave background are introduced into this model as two entities, their separate values appear within this theory in the form of a numerical difference. It is this difference that gives the numerical value for the zero point value of Einstein's dark energy density. Consequently, although the two zero point energies may be large, their difference can give the known small dark energy value from cosmology for dark energy density. Issues relating to interpretation, calculation and measurement associated with this result and an interpretation of dark energy as a measure of polarisation of the vacuum are discussed. In the first appendix to this paper, problems associated with the standard model of cosmology are solved by redefining temperature in the dust universe model. In the second appendix of this paper, an examination of the dark matter problem in relation to a general relativistic generalisation of Newton's inverse square law is undertaken. In the third appendix to this paper, the formalism is used to derive a formula that gives a possible value for the mass of the universe in terms of Newton's gravitation constant, Einstein's Lambda and the velocity of light. All three appendices have their own detailed abstracts.",Physics
"The method of nonequilibrium Greens functions allows for a spatial and energetical resolution of the electron current in Quantum Cascade Lasers. While scattering does not change the spatial position of carriers, the entire spatial evolution of charge can be attributed to coherent transport by complex wave functions. We discuss the hierarchy of transport models and derive the density matrix equations as well as the hopping model starting from the nonequilibrium Greens functions approach.",Physics
"We study experimentally the lasing regime of a GaAs based microcavity sample under strong optical pumping. The very same sample exhibits the strong coupling regime at low excitation power with a Rabi splitting as large as 15 meV. We show that some features which may be considered as experimental evidence of polariton Bose Einstein condensation are also observed in the weak coupling regime when the cavity is behaving as a regular photon laser. In particular, the emission pattern in the lasing regime displays a sharp peak near the energy minimum followed by a Boltzmann distribution at higher energies.",Physics
We consider universal statistical properties of systems that are characterized by phase states with macroscopic degeneracy of the ground state. A possible topological order in such systems is described by non-linear discrete equations. We focus on the discrete equations which take place in the case of generalized exclusion principle statistics. We show that their exact solutions are quantum dimensions of the irreducible representations of certain quantum group. These solutions provide an example of the point where the generalized exclusion principle statistics and braid statistics meet each other. We propose a procedure to construct the quantum dimer models by means of projection of the knotted field configurations that involved braiding features of one-dimensional topology.,Physics
"We report the observation of a Bose Einstein condensate in a bosonic isotope of ytterbium (170Yb). More than 10^6 atoms are trapped in a crossed optical dipole trap and cooled by evaporation. Condensates of approximately 10^4 atoms have been obtained. From an expansion of the condensate, we have extracted the scattering length a=3.6(9) nm.",Physics
"We study in detail the photometric redshift requirements needed for tomographic weak gravitational lensing in order to measure accurately the Dark Energy equation of state. In particular, we examine how ground-based photometry (u,g,r,i,z,y) can be complemented by space-based near-infrared (IR) photometry (J,H), e.g. on board the planned DUNE satellite. Using realistic photometric redshift simulations and an artificial neural network photo-z method we evaluate the Figure of Merit for the Dark Energy parameters $(w_0, w_a)$. We consider a DUNE-like broad optical filter supplemented with ground-based multi-band optical data from surveys like the Dark Energy Survey, Pan-STARRS and LSST. We show that the Dark Energy Figure of Merit would improved by a factor of 1.3 to 1.7 if IR filters are added on board DUNE. Furthermore we show that with IR data catastrophic photo-z outliers can be removed effectively. There is an interplay between the choice of filters, the magnitude limits and the removal of outliers. We draw attention to the dependence of the results on the galaxy formation scenarios encoded into the mock galaxies, e.g the galaxy reddening. For example, deep u band data could be as effective as the IR. We also find that about $10^5-10^6$ spectroscopic redshifts are needed for calibration of the full survey.",Physics
"We consider the effect of magnetic impurities, modeled by classical spins, in a conventional superconductor. We study their effect on the quasiparticles, specifically on the spin density and local density of states (LDOS). As previously emphasized, the impurities induce multiple scatterings of the quasiparticle wave functions leading to complex interference phenomena. Also, the impurities induce quantum phase transitions in the many-body system. Previous authors studied the effect of either a small number of impurities (from one to three) or a finite concentration of impurities, typically in a disordered distribution. In this work we assume a regular set of spins distributed inside the superconductor in such a way that the spins are oriented, forming different types of domain walls, assumed stable. This situation may be particularly interesting in the context of spin transfer due to polarized currents traversing the material.",Physics
"Motivated by recent inelastic neutron scattering (INS) experiments on La-based cuprates and based on the fermiology theories, we study the spin susceptibility for La-based (e.g., La$_{2-x}$Sr$_x$CuO$_4$) and Y-based (e.g., YBa$_2$Cu$_3$O$_y$) cuprates, respectively. The spin excitation in YBa$_2$Cu$_3$O$_y$ is dominated by a sharp resonance peak at the frequency 40 meV in the superconducting state. Below and above the resonance frequency, the incommensurate (IC) peaks develop and the intensity of the peaks decreases dramatically. In the normal state, the resonant excitation does not occur and the IC peaks are merged into commensurate ones. The spin excitation of La$_{2-x}$Sr$_x$CuO$_4$ is significantly different from that of Y-based ones, namely, the resonance peak does not exist due to the decreasing of the superconducting gap and the presence of the possible spin-stripe order. The spectra are only enhanced at the expected resonance frequency (about 18 meV) while it is still incommensurate. On the other hand, another frequency scale at the frequency 55 meV is also revealed, namely the spectra are commensurate and local maximum at this frequency. We elaborate all the results based on the Fermi surface topology and the d-wave superconductivity, and suggest that the spin-stripe order be also important in determining the spin excitation of La-based cuprates. A coherent picture for the spin excitations is presented for Y-based and La-based cuprates.",Physics
In the present paper the realization of the obtained results in relation to the dense high- temperature plasma of multivalent ions including experimental data interpretation is discussed.,Physics
"We discuss the collective behavior of a network of individuals that receive, process and forward to each other tasks. Given costs they store those tasks in buffers, choosing optimally the frequency at which to check and process the buffer. The individual optimizing strategy of each node determines the aggregate behavior of the network. We find that, under general assumptions, the whole system exhibits coexistence of equilibria and hysteresis.",Physics
"This paper is concerned with the theoretical properties of high contrast coronagraphic images in the context of exoplanet searches. We derive and analyze the statistical properties of the residual starlight in coronagraphic images, and describe the effect of a coronagraph on the speckle and photon noise. Current observations with coronagraphic instruments have shown that the main limitations to high contrast imaging are due to residual quasi-static speckles. We tackle this problem in this paper, and propose a generalization of our statistical model to include the description of static, quasi-static and fast residual atmospheric speckles. The results provide insight into the effects on the dynamic range of wavefront control, coronagraphy, active speckle reduction, and differential speckle calibration. The study is focused on ground-based imaging with extreme adaptive optics, but the approach is general enough to be applicable to space, with different parameters.",Physics
"We show that finite angular momentum pairing chiral superconductors on the triangular lattice have point zeroes in the complex gap function. A topological quantum phase transition takes place through a nodal superconducting state at a specific carrier density $x_c$ where the normal state Fermi surface crosses the isolated zeros. For spin singlet pairing, we show that the second nearest neighbor $d+id$-wave pairing can be the dominant pairing channel. The gapless critical state at $x_c\simeq0.25$ has six Dirac points and is topologically nontrivial with a $T^3$ spin relaxation rate below $T_c$. This picture provides a possible explanation for the unconventional superconducting state of Na$_x$CoO$_2\cdot y$H$_2$O. Analyzing a pairing model with strong correlation using the Gutzwiller projection and symmetry arguments, we study these topological phases and phase transitions as a function of Na doping.",Physics
"We track the motion of a horizontally vibrated amorphous assembly of bidisperse hard disks, for densities ranging across the jamming transition. We derive on very general grounds a bound on the dynamical susceptibility in terms of the response of the dynamics to a change in density. This generalizes a similar bound recently derived for equilibrium liquids. We find that in our experimental system the bound is tight and reproduces the non-monotonic behavior of the dynamical susceptibility both in time and density across the jamming transition. The underlying scaling behavior reveals an intimate connection between anomalous diffusion and dynamical heterogeneity.",Physics
"We propose that high frequency quasi-periodic oscillations (HFQPOs) can be produced from randomly-formed X-ray bursts (flashes) by plasma interior to the ergosphere of a rapidly-rotating black hole. We show by direct computation of their orbits that the photons comprising the observed X-ray light curves, if due to a multitude of such flashes, are affected significantly by the black hole's dragging of inertial frames; the photons of each such burst arrive to an observer at infinity in multiple (double or triple), distinct ""bunches"" separated by a roughly constant time lag of t/M~14, regardless of the bursts' azimuthal position. We argue that every other such ""bunch"" represents photons that follow trajectories with an additional orbit around the black hole at the photon circular orbit radius (a photon ""echo""). The presence of this constant lag in the response function of the system leads to a QPO feature in its power density spectra, even though the corresponding light curve consists of a totally stochastic signal. This effect is by and large due to the black hole spin and is shown to gradually diminish as the spin parameter a decreases or the radial position of the burst moves outside the static limit surface (ergosphere). Our calculations indicate that for a black hole with Kerr parameter of a/M=0.99 and mass of M=10*Msun the QPO is expected at a frequency of ~ 1.3-1.4 kHz. We discuss the plausibility and observational implications of our model/results as well as its limitations.",Physics
"When a chiral isotropic elastomer is brought to low temperature cholesteric phase, the nematic degree of freedom tends to order and form a helix. Due to the nemato-elastic coupling, this also leads to elastic deformation of the polymer network that is locally coaxial with the nematic order. However, the helical structure of nematic order is incompatible with the energetically preferred elastic deformation. The system is therefore frustrated and appropriate compromise has to be achieved between the nematic ordering and the elastic deformation. For a strongly chiral elastomer whose pitch is much smaller than the system size, this problem has been studied by Pelcotivs and Meyer, as well as by Warner. In this work, we study the isotropic-cholesteric transition in the weak chirality limit, where the pitch is comparable or much larger than system size. We compare two possible solutions: a helical state as well as a double twist state. We find that the double twist state very efficiently minimizes both the elastic free energy and the chiral nematic free energy. On the other hand, the pitch of the helical state is strongly affected by the nemato-elastic coupling. As a result this state is not efficient in minimizing the chiral nematic free energy.",Physics
"Electroosmotic pumping through uncharged hydrogels can be achieved by embedding the polymer network with charged colloidal inclusions. Matos and co-workers (2006) recently used the concept to enhance the diffusion-limited flux of uncharged molecules across polyacrylamide hydrogel membraness for the purpose of improving the performance of biosensors. This paper seeks to link their reported macroscale diagnostics to physicochemical characteristics of the composite microstructure. A mathematical model for the bulk electroosmotically enhanced tracer flux is proposed, which is combined with the electrokinetic model to ascertain the electroosmotic pumping velocity from measured flux enhancements. Because the experiments are performed with a known current density, but unknown bulk conductivity and electric field strength, theoretical estimates of the bulk electrical conductivity are adopted. These account for nano-particle polarization, added counterions, and non-specific adsorption. Theoretical predictions of the flux enhancement, achieved without any fitting parameters, are within a factor of two of the experiments. Alternatively, if the Brinkman screening length of the polymer skeleton is treated as a fitting parameter, then the best-fit values are bounded by the range 0.9-1.6 nm, depending on the inclusion size and volume fraction. Independent pressure-driven flow experiments reported in the literature for polyacrylamide gels without inclusions suggest 0.4 or 0.8 nm. The comparison can be improved by allowing for hindered ion migration, while uncertainties regarding the inclusion surface charge are demonstrated to have a negligible influence on the electroosmotic flow.",Physics
"We report observations of stable bound pairs in very dilute deionized aqueous suspensions of highly charged polystyrene colloidal particles, with monovalent counterions, using a confocal laser scanning microscope. Through an analysis of several thousands of time series of confocal images recorded deep inside the bulk suspension, we find that the measured pair-potential, U(r) has a long-range attractive component with well depths larger than the thermal energy. These observations provide a direct and unequivocal evidence for the existence of long-range attraction in U(r) of like-charged colloidal particles.",Physics
"The interior of neutron stars contains nuclear matter at very high density for numerous subatomic particles compete with each other. Therefore, confirming the components and properties there is our significant task. Here we summarize the possible methods especial the way of r-mode instability to probe into the neutron star and show our some results. The KHz pulsar in XTE J1739-285 may give a significant implication",Physics
"Strong evidence for the presence of a warped Keplerian accretion disc in NGC4258 (M 106) has been inferred from the kinematics of water masers detected at sub-parsec scales. Assuming a power-law accretion disc and using constraints on the disc parameters derived from observational data, we have analyzed the relativistic Bardeen-Petterson effect driven by a Kerr black hole as the potential physical mechanism responsible for the disc warping. We found that the Bardeen-Petterson radius is comparable to or smaller than the inner radius of the maser disc (independent of the allowed value for the black hole spin parameter). Numerical simulations for a wide range of physical conditions have shown that the evolution of a misaligned disc due to the Bardeen-Petterson torques usually produces an inner flat disc and a warped transition region with a smooth gradient in the tilt and twist angles. Since this structure is similar to that seen in NGC 4258, we propose that the Bardeen-Petterson effect may be responsible for the disc warping in this galaxy. We estimated the time-scale necessary for the disc inside of the Bardeen-Petterson radius to align with the black hole's equator, as a function of the black hole spin. Our results show that the Bardeen-Petterson effect can align the disc within a few billion years in the case of NGC 4258. Finally, we show that if the observed curvature of the outer anomalous arms in the galactic disc of NGC 4258 is associated with the precession of its radio jet/counterjet, then the Bardeen-Petterson effect can provide the required precession period.",Physics
"Angular momentum in protostellar discs can be transported either radially, through turbulence induced by the magnetorotational instability (MRI), or vertically, through the torque exerted by a large-scale magnetic field. We present a model of steady-state discs where these two mechanisms operate at the same radius and derive approximate criteria for their occurrence in an ambipolar diffusion dominated disc. We obtain ""weak field'' solutions - which we associate with the MRI channel modes in a stratified disc - and transform them into accretion solutions with predominantly radial angular-momentum transport by implementing a turbulent-stress prescription based on published results of numerical simulations. We also analyze ""intermediate field strength'' solutions in which both radial and vertical transport operate at the same radial location. Our results suggest, however, that this overlap is unlikely to occur in real discs.",Physics
"We present a detailed analysis of the Galaxy Stellar Mass Function of galaxies up to z=2.5 as obtained from the VVDS. We estimate the stellar mass from broad-band photometry using 2 different assumptions on the galaxy star formation history and show that the addition of secondary bursts to a continuous star formation history produces systematically higher (up to 40%) stellar masses. At low redshift (z=0.2) we find a substantial population of low-mass galaxies (<10^9 Msun) composed by faint blue galaxies (M_I-M_K=0.3). In general the stellar mass function evolves slowly up to z=0.9 and more significantly above this redshift. Conversely, a massive tail is present up to z=2.5 and have extremely red colours (M_I-M_K=0.7-0.8). We find a decline with redshift of the overall number density of galaxies for all masses (59+-5% for M>10^8 Msun at z=1), and a mild mass-dependent average evolution (`mass-downsizing'). In particular our data are consistent with mild/negligible (<30%) evolution up to z=0.7 for massive galaxies (>6x10^10 Msun). For less massive systems the no-evolution scenario is excluded. A large fraction (>=50%) of massive galaxies have been already assembled and converted most of their gas into stars at z=1, ruling out the `dry mergers' as the major mechanism of their assembly history below z=1. This fraction decreases to 33% at z=2. Low-mass systems have decreased continuously in number and mass density (by a factor up to 4) from the present age to z=2, consistently with a prolonged mass assembly also at z<1.",Physics
"We present a study of the lensing properties of two-dimensional (2-D) photonic quasicrystal (PQC) slabs made of dielectric cylinders arranged according to a 12-fold-symmetric square-triangle aperiodic tiling. Our full-wave numerical analysis confirms the results recently emerged in the technical literature and, in particular, the possibility of achieving focusing effects within several frequency regions. However, contrary to the original interpretation, such focusing effects turn out to be critically associated to local symmetry points in the PQC slab, and strongly dependent on its thickness and termination. Nevertheless, our study reveals the presence of some peculiar properties, like the ability to focus the light even for slabs with a reduced lateral width, or beaming effects, which render PQC slabs potentially interesting and worth of deeper investigation. Key words: Photonic quasicrystals; negative refraction; superlensing.",Physics
"We have examined superfluid properties of $^4$He confined to a nano-porous Gelsil glass that has nanopores 2.5 nm in diameter. The pressure-temperature phase diagram was determined by torsional oscillator, heat capacity and pressure studies. The superfluid transition temperature $T_{\mathrm c}$ approaches zero at 3.4 MPa, indicating a novel ""quantum"" superfluid transition. By heat capacity measurements, the nonsuperfluid phase adjacent to the superfluid and solid phases is identified to be a nanometer-scale, localized Bose condensation state, in which global phase coherence is destroyed. At high pressures, the superfluid density has a $T$-linear term, and $T_{\mathrm c}$ is proportional to the zero-temperature superfluid density. These results strongly suggest that phase fluctuations in the superfluid order parameter play a dominant role on the phase diagram and superfluid properties.",Physics
"The persistent current of correlated electrons in a continuous one-dimensional ring with a single scatterer is calculated by solving the many-body Schrodinger equation for several tens of electrons interacting via the electron-electron (e-e) interaction of finite range. The problem is solved by the configuration-interaction (CI) and diffusion Monte Carlo (DMC) methods. The CI and DMC results are in good agreement. In both cases, the persistent current $I$ as a function of the ring length $L$ exhibits the asymptotic dependence $I \propto L^{-1-\alpha}$ typical of the Luttinger liquid, where the power $\alpha$ depends only on the e-e interaction. The numerical values of $\alpha$ agree with the known formula of the renormalisation-group theory.",Physics
"Utilizing an eigenfunction decomposition, we study the growth and spectra of energy in the vortical and wave modes of a 3D rotating stratified fluid as a function of $\epsilon = f/N$. Working in regimes characterized by moderate Burger numbers, i.e. $Bu = 1/\epsilon^2 < 1$ or $Bu \ge 1$, our results indicate profound change in the character of vortical and wave mode interactions with respect to $Bu = 1$. As with the reference state of $\epsilon=1$, for $\epsilon < 1$ the wave mode energy saturates quite quickly and the ensuing forward cascade continues to act as an efficient means of dissipating ageostrophic energy. Further, these saturated spectra steepen as $\epsilon$ decreases: we see a shift from $k^{-1}$ to $k^{-5/3}$ scaling for $k_f < k < k_d$ (where $k_f$ and $k_d$ are the forcing and dissipation scales, respectively). On the other hand, when $\epsilon > 1$ the wave mode energy never saturates and comes to dominate the total energy in the system. In fact, in a sense the wave modes behave in an asymmetric manner about $\epsilon = 1$. With regard to the vortical modes, for $\epsilon \le 1$, the signatures of 3D quasigeostrophy are clearly evident. Specifically, we see a $k^{-3}$ scaling for $k_f < k < k_d$ and, in accord with an inverse transfer of energy, the vortical mode energy never saturates but rather increases for all $k < k_f$. In contrast, for $\epsilon > 1$ and increasing, the vortical modes contain a progressively smaller fraction of the total energy indicating that the 3D quasigeostrophic subsystem plays an energetically smaller role in the overall dynamics.",Physics
"While the completion of the Pierre Auger Observatory (or simply ``Auger'') is still underway, the 5165 km^2.sr.yr integrated acceptance accumulated since the January 1st, 2004 is now significantly larger than what was gathered by the previous experiments dedicated to the detection of ultra-high-energy cosmic rays (UHECRs). We report on the development status of Auger and present some results related to the cosmic-ray energy spectrum, composition and anisotropies, and the photon fraction at ultra-high energy. We briefly discuss the importance of the ankle region to understand the overall phenomenology of cosmic-rays, and mention future enhancements of Auger focusing on this energy range.",Physics
"A phenomenological two-fluid model of the (time-reversible) spectrally-truncated 3D Euler equation is proposed. The thermalized small scales are first shown to be quasi-normal. The effective viscosity and thermal diffusion are then determined, using EDQNM closure and Monte-Carlo numerical computations. Finally, the model is validated by comparing its dynamics with that of the original truncated Euler equation.",Physics
"The wetting behavior of thin films of 4'-n-octyl-4-cyanobiphenyl (8CB) on Si is investigated via optical and x-ray reflectivity measurement. An experimental phase diagram is obtained showing a broad thick-thin coexistence region spanning the bulk isotropic-to-nematic ($T_{IN}$) and the nematic-to-smectic-A ($T_{NA}$) temperatures. For Si surfaces with coverages between 47 and $72\pm3$ nm, reentrant wetting behavior is observed twice as we increase the temperature, with separate coexistence behaviors near $T_{IN}$ and $T_{NA}$. For coverages less than 47 nm, however, the two coexistence behaviors merge into a single coexistence region. The observed thin-thick coexistence near the second-order NA transition is not anticipated by any previous theory or experiment. Nevertheless, the behavior of the thin and thick phases within the coexistence regions is consistent with this being an equilibrium phenomenon.",Physics
"The diffractive nature of light has limited optics and photonics to operate at scales much larger than the wavelength of light. The major challenge in scaling-down integrated photonics is how to mold the light flow below diffraction-limit in all three dimensions. A high index solid immersion lens can improve the spatial resolution by increasing the medium refractive index, but only to few times higher than in air. Photonic crystals can guide light in three dimensions, however, the guided beam width is around a wavelength. Surface plasmons has a potential to reach the sub-wavelength scales; nevertheless, it is confined in the two-dimensional interface between metals and dielectrics. Here, we present a new approach for molding the light flow at the deep sub-wavelength scale, using metamaterials with uniquely designed dispersion. We develop a design methodology for realizing sub-wavelength ray optics, and demonstrate lambda/10 width light beams flow through three-dimensional space.",Physics
"A scanning SQUID microscope was used to image vortex trapping as a function of the magnetic induction during cooling in thin-film YBCO strips for strip widths W from 2 to 50 um. We found that vortices were excluded from the strips when the induction Ba was below a critical induction Bc. We present a simple model for the vortex exclusion process which takes into account the vortex - antivortex pair production energy as well as the vortex Meissner and self-energies. This model predicts that the real density n of trapped vortices is given by n=(Ba-BK)/Phi0 with BK = 1.65Phi0/W^2 and Phi0 = h/2e the superconducting flux quantum. This prediction is in good agreement with our experiments on YBCO, as well as with previous experiments on thin-film strips of niobium. We also report on the positions of the trapped vortices. We found that at low densities the vortices were trapped in a single row near the centers of the strips, with the relative intervortex spacing distribution width decreasing as the vortex density increased, a sign of longitudinal ordering. The critical induction for two rows forming in the 35 um wide strip was (2.89 + 1.91-0.93)Bc, consistent with a numerical prediction.",Physics
"Precision measurement of the scalar perturbation spectral index, n_s, from the Wilkinson Microwave Anisotropy Probe temperature angular power spectrum requires the subtraction of unresolved point source power. Here we reconsider this issue. First, we note a peculiarity in the WMAP temperature likelihood's response to the source correction: Cosmological parameters do not respond to increased source errors. An alternative and more direct method for treating this error term acts more sensibly, and also shifts n_s by ~0.3 sigma closer to unity. Second, we re-examine the source fit used to correct the power spectrum. This fit depends strongly on the galactic cut and the weighting of the map, indicating that either the source population or masking procedure is not isotropic. Jackknife tests appear inconsistent, causing us to assign large uncertainties to account for possible systematics. Third, we note that the WMAP team's spectrum was computed with two different weighting schemes: uniform weights transition to inverse noise variance weights at l = 500. The fit depends on such weighting schemes, so different corrections apply to each multipole range. For the Kp2 mask used in cosmological analysis, we prefer source corrections A = 0.012 +/- 0.005 muK^2 for uniform weighting and A = 0.015 +/- 0.005 muK^2 for N_obs weighting. Correcting WMAP's spectrum correspondingly, we compute cosmological parameters with our alternative likelihood, finding n_s = 0.970 +/- 0.017 and sigma_8 = 0.778 +/- 0.045 . This n_s is only 1.8 sigma from unity, compared to the ~2.6 sigma WMAP 3-year result. Finally, an anomalous feature in the source spectrum at l<200 remains, most strongly associated with W-band.",Physics
"We investigate the mechanism of growth of nanocrystals from solution using the case of ZnO. Spanning a wide range of values of the parameters, such as the temperature and the reactant concentration, that control the growth, our results establish a qualitative departure from the widely accepted diffusion controlled coarsening (Ostwald ripening) process quantified in terms of the Lifshitz-Slyozov-Wagner theory. Further, we show that these experimental observations can be qualitatively and quantitatively understood within a growth mechanism that is intermediate between the two well-defined limits of diffusion control and kinetic control.",Physics
"Forced packing of a long metallic wire injected into a two-dimensional cavity leads to crushed structures involving a hierarchical cascade of loops with varying curvature radii. We study the distribution of elastic energy stored in such systems from experiments, and high-resolution digital techniques. It is found that the set where the elastic energy of curvature is concentrated has dimension $D_\mathcal{S} = 1.0 \pm 0.1$, while the set where the mass is distributed, has dimension $D =1.9 \pm 0.1$.",Physics
"The annihilation of dark matter (DM) in the Galaxy could produce specific imprints on the spectra of antimatter species in Galactic cosmic rays, which could be detected by upcoming experiments such as PAMELA and AMS02. Recent studies show that the presence of substructures can enhance the annihilation signal by a ""boost factor"" that not only depends on energy, but that is intrinsically a statistical property of the distribution of DM substructures inside the Milky Way. We investigate a scenario in which substructures consist of $\sim 100$ ""mini-spikes"" around intermediate-mass black holes. Focusing on primary positrons and antiprotons, we find large boost factors, up to a few thousand, that exhibit a large variance at high energy in the case of positrons and at low energy in the case of antiprotons. As a consequence, an estimate of the DM particle mass based on the observed cut-off in the positron spectrum could lead to a substantial underestimate of its actual value.",Physics
"We present experimental magnetotunneling results and atomistic pseudopotential calculations of quasiparticle electron and hole wave functions of self-assembled InAs/GaAs quantum dots. The combination of a predictive theory along with the experimental results allows us to gain direct insight into the quantum states. We monitor the effects of (i) correlations, (ii) atomistic symmetry and (iii) piezoelectricity on the confined carriers and (iv) observe a peculiar charging sequence of holes that violates the Aufbau principle.",Physics
The magneto-gyrotropic photogalvanic and spin-galvanic effects are observed in (0001)-oriented GaN/AlGaN heterojunctions excited by terahertz radiation. We show that free-carrier absorption of linearly or circularly polarized terahertz radiation in low-dimensional structures causes an electric photocurrent in the presence of an in-plane magnetic field. Microscopic mechanisms of these photocurrents based on spin-related phenomena are discussed. Properties of the magneto-gyrotropic and spin-galvanic effects specific for hexagonal heterostructures are analyzed.,Physics
"We report diffusion quantum Monte Carlo calculations of three-dimensional Wigner crystals in the density range r_s=100-150. We have tested different types of orbital for use in the approximate wave functions but none improve upon the simple Gaussian form. The Gaussian exponents are optimized by directly minimizing the diffusion quantum Monte Carlo energy. We have carefully investigated and sought to minimize the potential biases in our Monte Carlo results. We conclude that the uniform electron gas undergoes a transition from a ferromagnetic fluid to a body-centered-cubic Wigner crystal at r_s=106+/-1. The diffusion quantum Monte Carlo results are compared with those from Hartree-Fock and Hartree theory in order to understand the role played by exchange and correlation in Wigner crystals. We also study ""floating"" Wigner crystals and give results for their pair-correlation functions.",Physics
"We present deep optical and infrared observations of the short duration GRB 050906. Although no X-ray or optical/IR afterglow was discovered to deep limits, the error circle of the GRB (as derived from the Swift BAT) is unusual incontaining the relatively local starburst galaxy IC328. This makes GRB 050906 a candidate burst from a soft-gamma repeater, similar to the giant flare from SGR 1806-20. The probability of chance alignment of a given BAT position with such a galaxy is small (<1%), although the size of the error circle (2.6 arcminute radius) is such that a higher-z origin can't be ruled out. Indeed, the error circle also includes a moderately rich galaxy cluster at z=0.43, which is a plausible location for the burst given the apparent preference that short GRBs have for regions of high mass density. No residual optical or infrared emission has been observed, either in the form of an afterglow or later time emission from any associated supernova-like event. We discuss the constraints these limits place on the progenitor of GRB 050906 based on the expected optical signatures from both SGRs and merging compact object systems.",Physics
"The spiral galaxy NGC 6946 was observed in total intensity and linear polarization in five radio bands between 3cm and 21cm. At the inner edge of the inner gas spiral arm the ordered magnetic field is only mildly compressed and turns smoothly, to become aligned along the gas arm. Hence the field is not shocked and is probably connected to the warm, diffuse gas. At larger radii, two bright magnetic arms between the optical arms are visible in polarized intensity. The field in the northern magnetic arm is almost totally aligned. Faraday rotation measures (RM) in these arms are consistent with the superposition of two low azimuthal dynamo modes. Three more magnetic arms are discovered in the outer galaxy, located between HI arms. Due to strong Faraday depolarization the galaxy is not transparent to polarized waves at 18cm and 20cm. The large-scale asymmetry in depolarization with respect to the major axis may be another indication of large-scale helical fields. Three depolarization rings of almost zero polarization seen at 20cm are probably generated by differential Faraday rotation in HII complexes in NGC 6946 of 300-500 pc size. - In the gas/optical spiral arms, the total (mostly turbulent) magnetic field is amplified to \simeq 20\muG. Its energy density is \simeq 10 times larger than that of the ionized gas and is similar to that of the turbulent gas motions in the inner galaxy. The magnetic energy exceeds that of the turbulent energy in the outer galaxy.",Physics
"We present and describe a catalog of galaxy photometric redshifts (photo-z's) for the Sloan Digital Sky Survey (SDSS) Data Release 6 (DR6). We use the Artificial Neural Network (ANN) technique to calculate photo-z's and the Nearest Neighbor Error (NNE) method to estimate photo-z errors for ~ 77 million objects classified as galaxies in DR6 with r < 22. The photo-z and photo-z error estimators are trained and validated on a sample of ~ 640,000 galaxies that have SDSS photometry and spectroscopic redshifts measured by SDSS, 2SLAQ, CFRS, CNOC2, TKRS, DEEP, and DEEP2. For the two best ANN methods we have tried, we find that 68% of the galaxies in the validation set have a photo-z error smaller than sigma_{68} =0.021 or $0.024. After presenting our results and quality tests, we provide a short guide for users accessing the public data.",Physics
"To identify the superconducting gap structure in URu2Si2 we perform field-angle-dependent specific heat measurements for the two principal orientations in addition to field rotations, and theoretical analysis based on microscopic calculations. The Sommerfeld coefficient \gamma(H)'s in the mixed state exhibit distinctively different field-dependence. This comes from point nodes and substantial Pauli paramagnetic effect of URu2Si2. These two features combined give rise to a consistent picture of superconducting properties, including a possible first order transition of Hc2 at low temperatures.",Physics
"We have tested a relative spectral lag (RSL) method suggested earlier as a luminosity/redshift (or distance) estimator, using the generalized method by Schaefer & Collazzi. We find the derivations from the luminosity/redshift-RSL (L/R-RSL) relation are comparable with the corresponding observations. Applying the luminosity-RSL relation to two different GRB samples, we find that there exist no violators from the generalized test, namely the Nakar & Piran test and Li test. We also find that about 36 per cent of Schaefer's sample are outliers for the L/R-RSL relation within 1$\sigma$ confidence level, but no violators at 3$\sigma$ level within the current precision of L/R-RSL relation. An analysis of several potential outliers for other luminosity relations shows they can match the L/R-RSL relation well within an acceptable uncertainty. All the coincident results seem to suggest that this relation could be a potential tool for cosmological study.",Physics
In this paper we present a framework for fast quantum conductance calculations of carbon nanotube-based sensing devices targeting aromatic amino acids within a tight binding approximation. The method begins by a novel parameterization procedure based on isospectral matrix flows. With the properly parameterized Hamiltonian we employ a linearly scaling algorithm to compute the quantum conductance in the coherent transport regime. A few conclusions are presented regarding the suitability of carbon nanotubes in aromatic amino acid detection.,Physics
"Optical and near-infrared spectroscopy of the newly discovered peculiar L dwarf 2MASS J11263991-5003550 are presented. Folkes et al. identified this source as a high proper motion L9+/-1 dwarf based on its strong H2O absorption at 1.4 micron. We find that the optical spectrum of 2MASS J1126-5003 is in fact consistent with that of a normal L4.5 dwarf with notably enhanced FeH absorption at 9896 A. However, its near-infrared spectrum is unusually blue, with strong H2O and weak CO bands similar in character to several recently identified ``blue L dwarfs''. Using 2MASS J1126-5003 as a case study, and guided by trends in the condensate cloud models of Burrows et al. and Marley et al., we find that the observed spectral peculiarities of these sources can be adequately explained by the presence of thin and/or large-grained condensate clouds as compared to normal field L dwarfs. Atypical surface gravities or metallicities alone cannot reproduce the observed peculiarities, although they may be partly responsible for the unusual condensate properties. We also rule out unresolved multiplicity as a cause for the spectral peculiarities of 2MASS J1126-5003. Our analysis is supported by examination of Spitzer mid-infrared spectral data from Cushing et al. which show that bluer L dwarfs tend to have weaker 10 micron absorption, a feature tentatively associated with silicate oxide grains. With their unique spectral properties, blue L dwarfs like 2MASS J1126-5003 should prove useful in studying the formation and properties of condensates and condensate clouds in low temperature atmospheres.",Physics
"We study the zero temperature mean-field phase diagram of the Bose-Hubbard model in the presence of local coupling between the bosons and an external bath. We consider a coupling that conserves the on-site occupation number, preserving the robustness of the Mott and superfluid phases. We show that the coupling to the bath renormalizes the chemical potential and the interaction between the bosons and reduces the size of the superfluid regions between the insulating lobes. For strong enough coupling, a finite value of hopping is required to obtain superfluidity around the degeneracy points where Mott phases with different occupation numbers coexist. We discuss the role that such a bath coupling may play in experiments that probe the formation of the insulator-superfluid shell structure in systems of trapped atoms.",Physics
"We present a detailed reduction of a mid-infrared 12um (LW10 filter) ISOCAM open time observation performed on the ESO-Sculptor Survey field (Arnouts et al. 1997). A complete catalogue of 142 sources (120 galaxies and 22 stars), detected with high significance (equivalent to 5sigma), is presented above an integrated flux density of 0.24mJy. Star/galaxy separation is performed by a detailed study of colour-colour diagrams. The catalogue is complete to 1mJy and below this flux density the incompleteness is corrected using two independent methods. The first method uses stars and the second uses optical counterparts of the ISOCAM galaxies; these methods yield consistent results. We also apply an empirical flux density calibration using stars in the field. For each star, the 12um flux density is derived by fitting optical colours from a multi-band chi^2 to stellar templates (BaSel-2.0) and using empirical optical-IR colour-colour relations. This article is a companion analysis to Rocca-Volmerange 2007 et al. where the 12um faint galaxy counts are presented and analysed by galaxy type with the evolutionary code PEGASE.3.",Physics
"We introduce an agent-based model for the spreading of technological developments in socio-economic systems where the technology is mainly used for the collaboration/interaction of agents. Agents use products of different technologies to collaborate with each other which induce costs proportional to the difference of technological levels. Additional costs arise when technologies of different providers are used. Agents can adopt technologies and providers of their interacting partners in order to reduce their costs leading to microscopic rearrangements of the system. Analytical calculations and computer simulations revealed that starting from a random configuration of different technological levels a complex time evolution emerges where the spreading of advanced technologies and the overall technological progress of the system are determined by the amount of advantages more advanced technologies provide, and by the structure of the social environment of agents. We show that agents tend to form clusters of identical technological level with a power law size distribution. When technological progress arises, the spreading of technologies in the system can be described by extreme order statistics.",Physics
"We observe a sequence of the anchoring transitions in nematic liquid crystals (NLC) sandwiched between the hydrophobic polyimide substrates treated with the plasma beam. There is a pronounced continuous transition from homeotropic to low tilted (nearly planar) alignment with the easy axis parallel to the incidence plane of the plasma beam (the zenithal transition) that takes place as the exposure dose increases. In NLC with positive dielectric anisotropy, a further increase in the exposure dose results in in-plane reorientation of the easy axis by 90 degrees (the azimuthal transition). This transition occurs through the two-fold degenerated alignment characteristic for the second order anchoring transitions. In contrast to critical behavior of anchoring, the contact angle of NLC and water on the treated substrates monotonically declines with the exposure dose. It follows that the surface concentration of hydrophobic chains decreases continuously. The anchoring transitions under consideration are qualitatively interpreted by using a simple phenomenological model of competing easy axes which is studied by analyzing anchoring diagrams of the generalized polar and non-polar anchoring models.",Physics
"Using analytical methods of statistical mechanics, we analyse the typical behaviour of a multiple-input multiple-output (MIMO) Gaussian channel with binary inputs under LDPC network coding and joint decoding. The saddle point equations for the replica symmetric solution are found in particular realizations of this channel, including a small and large number of transmitters and receivers. In particular, we examine the cases of a single transmitter, a single receiver and the symmetric and asymmetric interference channels. Both dynamical and thermodynamical transitions from the ferromagnetic solution of perfect decoding to a non-ferromagnetic solution are identified for the cases considered, marking the practical and theoretical limits of the system under the current coding scheme. Numerical results are provided, showing the typical level of improvement/deterioration achieved with respect to the single transmitter/receiver result, for the various cases.",Physics
"We present the results of a search for molecular gas emission via the CO line in the far outer disk of the nearby spiral, NGC 6946. The positions targeted were chosen to lie on or near previously-identified outer disk HII regions. Molecular gas was clearly detected out to 1.3 R$_{25}$, with a further tentative detection at 1.4 R$_{25}$. The CO detections show excellent agreement with the HI velocities and imply beam-averaged column densities of $0.3-9\times 10^{20}$ cm$^{-2}$ and molecular gas masses of (2-70)$\times 10^{5}$ M$_{\sun}$ per 21$''$ beam (560pc). We find evidence for an abrupt decrease in the molecular fraction at the edge of the optical disk, similar to that seen previously in the azimuthally-averaged areal star formation rate. Our observations provide new constraints on the factors that determine the presence and detectability of molecular gas in the outskirts of galaxies, and suggest that neither the HI column, the metallicity or the local heating rate alone plays a dominant role.",Physics
"We study a model of hard-core bosons on the kagome lattice with short-range hopping ($t$) and repulsive interactions ($V$). This model directly maps on to an easy-axis $S=1/2$ XXZ model on the kagome lattice and is also related, at large $V/t$, to a quantum dimer model on the triangular lattice. Using quantum Monte Carlo (QMC) numerics, we map out the phase diagram of this model at half-filling. At T=0, we show that this model exhibits a superfluid phase at small $V/t$ and an insulating phase at large $V/t$, separated by a continuous quantum phase transition at $V_c/t \approx 19.8$. The insulating phase at T=0 appears to have no conventional broken symmetries, and is thus a uniform Mott insulator (a `spin liquid' in magnetic language). We characterize this insulating phase as a uniform $Z_2$ fractionalized insulator from the topological order in the ground state and estimate its vison gap. Consistent with this identification, there is no apparent thermal phase transition upon heating the insulator. The insulating phase instead smoothly crosses over into the high temperature paramagnet via an intermediate cooperative paramagnetic regime. We also study the superfluid-to-normal thermal transition for $V < V_c$. We find that this is a Kosterlitz-Thouless transition at small $V/t$ but changes to a first order transition for $V$ closer to $V_c$. We argue that this first order thermal transition is consistent with the presence of a nearby $Z_2$ insulating ground state obtained from the superfluid ground state by condensing double vortices.",Physics
"We report the rectifying effect of a constant-wave radio frequency (RF) current by a magnetic domain wall (DW) on a single-layered ferromagnetic wire. A direct-current (DC) voltage is generated by the spin torque diode effect, which is a consequence of magnetoresistance oscillation due to the resonant spin wave excitation induced by the spin-polarized RF current. The DC voltage spectrum strongly depends on the internal spin structure in the DW, which corresponds to the magnetic fingerprint of the spin structure in the ferromagnetic wire.",Physics
"We design an efficient coupler to transmit light from a strip waveguide into the flatband slow mode of a photonic crystal waveguide with ring-shaped holes. The coupler is a section of a photonic crystal waveguide with a higher group velocity, obtained by different ring dimensions. We demonstrate coupling efficiency in excess of 95% over the 8 nm wavelength range where the photonic crystal waveguide exhibits a quasi constant group velocity vg = c/37. An analysis based on the small Fabry-P\'erot resonances in the simulated transmission spectra is introduced and used for studying the effect of the coupler length and for evaluating the coupling efficiency in different parts of the coupler. The mode conversion efficiency within the coupler is more than 99.7% over the wavelength range of interest. The parasitic reflectance in the coupler, which depends on the propagation constant mismatch between the slow mode and the coupler mode, is lower than 0.6% within this wavelength range.",Physics
"Determinations of beryllium abundance in stars, together with lithium, provide a key tool to investigate the so far poorly understood extra-mixing processes at work in stellar interiors. We measured Be in three open clusters,complementing existing Be surveys, and aiming at gathering a more complete empirical scenario of the evolution of Be as a function of stellar age and temperature. Specifically, we analyzed VLT/UVES spectra of members of NGC 2516, the Hyades, and M 67 to determine their Be and Li abundances. In the first two clusters we focused on stars cooler than 5400 K, while the M 67 sample includes stars warmer than 6150 K, as well as two subgiants and two blue stragglers. We also computed the evolution of Be for a 0.9 Mo star based on standard evolutionary models. We find different emprical behaviours for stars in different temperature bins and ages. Stars warmer than 6150 K show Be depletion and follow a Be vs. Li correlation while Be is undepleted in stars in the ~6150-5600 K range. NGC 2516 members cooler than 5400 K have not depleted any Be, but older Hyades of similar temperature do show some depletion. Be is severely depleted in the subgiants and blue stragglers. The results for warm stars are in agreement with previous studies, supporting the hypothesis that mixing in this temperature regime is driven by rotation. The same holds for the two subgiants that have evolved from the ""Li gap"". This mechanism is instead not the dominant one for solar-type stars. We show that Be depletion of cool Hyades cannot simply be explained by the effect of increasing depth of the convective zone. Finally, the different Be content of the two blue stragglers suggests that they have formed by two different processes (i.e., collisions vs. binary merging).",Physics
"We investigate the signal from supernova relic neutrinos in future large scale observatories, such as MEMPHYS (UNO, Hyper-K), LENA and GLACIER, at present under study. We discuss that complementary information might be gained from the observation of supernova relic electron anti-neutrinos and neutrinos using the scattering on protons on one hand, and on nuclei such as oxygen, carbon or argon on the other hand. When determining the relic neutrino fluxes we also include, for the first time, the coupling of the neutrino magnetic moment to magnetic fields within the core-collapse supernova. We present numerical results on both the relic electron neutrino and anti-neutrino fluxes and on the number of events for electron neutrinos on carbon, oxygen and argon, as well as electron anti-neutrinos on protons, for various oscillation scenarios. The observation of supernova relic neutrinos might provide us with unique information on core-collapse supernova explosions, on the star formation history and on neutrino properties, that still remain unknown.",Physics
"We suggest a theory of internal coherent tunneling in the pseudogap region, when the applied voltage U is below the free electron gap 2Delta_0. We address quasi 1D systems, where the gap is originated by spontaneous lattice distortions of the Incommensurate Charge Density Wave (ICDW) type. Results can be adjusted also to quasi-1D superconductors. The instanton approach allows to calculate the interchain tunneling current both in single electron (amplitude solitons, i.e. spinons) and bi-electron (phase slips) channels. Transition rates are governed by a dissipative dynamics originated by emission of gapless phase excitations in the course of the instanton process. We find that the single-electron tunneling is allowed below the nominal gap 2Delta_0 down to the true pair-breaking threshold at 2W_as<2Delta, where W_as=2Delta/pi is the amplitude soliton energy. Most importantly, the bi-electronic tunneling stretches down to U=0 (in the 1D regime). In both cases, the threshold behavior is given by power laws J (U-U_c)^beta, where the exponent beta v_F/u is large as the ratio of the Fermi velocity v_F and the phase one u. In the 2D or 3D ordered phases, at temperature T<T_c, the one-electron tunneling current does not vanish at the threshold U_c anymore, but saturates above it at U-U_c T_c<<Delta. Also the bi-particle channel acquires a finite threshold U_c=W_ph T_c<<Delta at the energy W_ph of the 2\pi phase soliton.",Physics
"Using high-quality gas phase electron scattering calculations and multiple scattering theory, we attempt to gain insights on the radiation damage to DNA induced by secondary low-energy electrons in the condensed phase, and to bridge the existing gap with the gas phase theory and experiments. The origin of different resonant features (arising from single molecules or diffraction) is discussed and the calculations are compared to existing experiments in thin films.",Physics
"We present a study of the Nernst effect in amorphous 2D superconductor InO$_x$, whose low carrier density implies low phase rigidity and strong superconducting phase fluctuations. Instead of presenting the abrupt jump expected at a BCS transition, the Nernst signal evolves continuously through the superconducting transition as previously observed in underdoped cuprates. This contrasts with the case of Nb$_{0.15}$Si$_{0.85}$, where the Nernst signal due to vortices below T$_{c}$ and by Gaussian fluctuations above are clearly distinct. The behavior of the ghost critical field in InO$_x$ points to a correlation length which does not diverge at $T_c$, a temperature below which the amplitude fluctuations freeze, but phase fluctuations survive.",Physics
"We review recent results from the X-ray timing of accreting millisecond pulsars in Low Mass X-ray Binaries. This is the first time a timing analysis is performed on accreting millisecond pulsars, and for the first time we can obtain information on the behavior of a very fast pulsar subject to accretion torques. We find both spin-up and spin-down behaviors, from which, using available models for the accretion torques, we derive information on the mass accretion rate and magnetic field of the neutron star in these systems. We also find that the phase delays behavior as a function of time in these sources is sometimes quite complex and difficult to interpret, since phase shifts, most probably driven by variations of the X-ray flux, are sometimes present.",Physics
"We use the GEANT4 Monte Carlo framework to calculate the gamma-ray albedo of the Moon due to interactions of cosmic ray (CR) nuclei with moon rock. Our calculation of the albedo spectrum agrees with the EGRET data. We show that the spectrum of gamma rays from the Moon is very steep with an effective cutoff around 3-4 GeV (600 MeV for the inner part of the Moon disk) and exhibits a narrow pion-decay line at 67.5 MeV, perhaps unique in astrophysics. Apart from other astrophysical sources, the albedo spectrum of the Moon is well understood, including its absolute normalisation; this makes it a useful ""standard candle"" for gamma-ray telescopes. The steep albedo spectrum also provides a unique opportunity for energy calibration of gamma-ray telescopes, such as the forthcoming Gamma Ray Large Area Space Telescope (GLAST). Since the albedo flux depends on the incident CR spectrum which changes over the solar cycle, it is possible to monitor the CR spectrum using the albedo gamma-ray flux. Simultaneous measurements of CR proton and helium spectra by the Payload for Antimatter-Matter Exploration and Light-nuclei Astrophysics (PAMELA), and observations of the albedo gamma rays by the GLAST Large Area Telescope (LAT), can be used to test the model predictions and will enable the LAT to monitor the CR spectrum near the Earth beyond the lifetime of the PAMELA.",Physics
"Six of the eight double neutron stars known in the Galactic disk have low orbital eccentricities (< 0.27) indicating that their second-born neutron stars received only very small velocity kicks at birth. This is similar to the case of the B-emission X-ray binaries, where a sizable fraction of the neutron stars received hardly any velocity kick at birth (Pfahl et al. 2002). The masses of the second-born neutron stars in five of the six low-eccentricity double neutron stars are remarkably low (between 1.18 and 1.30 Msun). It is argued that these low-mass, low-kick neutron stars were formed by the electron-capture collapse of the degenerate O-Ne-Mg cores of helium stars less massive than about 3.5 Msun, whereas the higher-mass, higher kick-velocity neutron stars were formed by the collapses of the iron cores of higher initial mass. The absence of low-velocity single young radio pulsars (Hobbs et al. 2005) is consistent with the model proposed by Podsiadlowski et al. (2004), in which the electron-capture collapse of degenerate O-Ne-Mg cores can only occur in binary systems, and not in single stars.",Physics
"We report low-temperature specific heat studies on single-crystalline ternary-iron silicide superconductor Lu$_{2}$Fe$_{3}$Si$_{5}$ with$T_c$ = 6.1 K down to $\sim T_c/20$. We confirm a reduced normalized jump in specific heat at $T_c$, and find that the specific heat divided by temperature $C/T$ shows sudden drop at $\sim T_c/5$ and goes to zero with further decreasing temperature. These results indicate the presence of two distinct superconducting gaps in Lu$_{2}$Fe$_{3}$Si$_{5}$, similar to a typical two-gap superconductor MgB$_{2}$. We also report Hall coefficients, band structure calculation, and the anisotropy of upper critical fields for Lu$_{2}$Fe$_{3}$Si$_{5}$, which support the anisotropic multiband nature and reinforce the existence of two superconducting gaps in Lu$_{2}$Fe$_{3}$Si$_{5}$.",Physics
"We report CO-induced lifting of the hexagonal surface reconstruction on Au (001). Using in-situ surface x-ray scattering, we determined a pressure-temperature phase diagram for the reconstruction and measured the dynamical evolution of the surface structure in real time. Our observations provide evidence that, under certain conditions, even macroscopic Au surfaces, much larger than catalytic Au nanoparticles [M. Haruta, Catal. Today 36, 153 (1997)], can exhibit some of the reactive properties and surface transitions observed in systems known to be catalytically active such as Pt (001).",Physics
"The Landau levels of cold atomic gases in non-Abelian gauge fields are analyzed. In particular we identify effects on the energy spectrum and density distribution which are purely due to the non-Abelian character of the fields. We investigate in detail non-Abelian generalizations of both the Landau and the symmetric gauge. Finally, we discuss how these non-Abelian Landau and symmetric gauges may be generated by means of realistically feasible lasers in a tripod scheme.",Physics
We study and develop constraint preserving boundary conditions for the Newtonian magnetohydrodynamic equations and analyze the behavior of the numerical solution upon considering different possible options.,Physics
"We review the information that planetary nebulae and their immediate progenitors, the post-AGB objects, can provide to probe the nucleosynthesis and mixing in low and intermediate mass stars. We emphasize new approaches based on high signal-to-noise spectroscopy of planetary nebulae and of their central stars. We mention some of the problems still to overcome. We emphasize that, as found by several authors, planetary nebulae in low metallicity environments cannot be used to probe the oxygen abundance in the interstellar medium out of which their progenitors were formed, because of abundance modification during stellar evolution.",Physics
"In this paper we present axisymmetric nonlinear simulations of magnetized Ekman and Stewartson layers in a magnetized Taylor-Couette flow with a centrifugally stable angular-momemtum profile and with a magnetic Reynolds number below the threshold of magnetorotational instability. The magnetic field is found to inhibit the Ekman suction. The width of the Ekman layer is reduced with increased magnetic field normal to the end plate. A uniformly-rotating region forms near the outer cylinder. A strong magnetic field leads to a steady Stewartson layer emanating from the junction between differentially rotating rings at the endcaps. The Stewartson layer becomes thinner with larger Reynolds number and penetrates deeper into the bulk flow with stronger magnetic field and larger Reynolds number. However, at Reynolds number larger than a critical value $\sim 600$, axisymmetric, and perhaps also nonaxisymmetric, instabilities occur and result in a less prominent Stewartson layer that extends less far from the boundary.",Physics
"We have explored the nonlinear dynamics of an optomechanical system consisting of an illuminated Fabry-Perot cavity, one of whose end-mirrors is attached to a vibrating cantilever. Such a system can experience negative light-induced damping and enter a regime of self-induced oscillations. We present a systematic experimental and theoretical study of the ensuing attractor diagram describing the nonlinear dynamics, in an experimental setup where the oscillation amplitude becomes large, and the mirror motion is influenced by several optical modes. A theory has been developed that yields detailed quantitative agreement with experimental results. This includes the observation of a regime where two mechanical modes of the cantilever are excited simultaneously.",Physics
"Detailed models are compared to recent infrared observations of the nearby extrasolar planet, HD 189733b. It is demonstrated that atmospheric water is present and that the planet's day side has a non-isothermal structure down to gas pressures of ~ 0.1 bars. Furthermore, model spectra with different amounts of CO are compared to the observations and an atmosphere absent of CO is excluded at roughly 2-sigma. Constraining the CO concentration beyond that is unfortunately not possible with the current Spitzer photometry. However, radically enhanced (or depleted) metal abundances are unlikely and the basic composition of this planet is probably similar to that of its host star. When combined with Spitzer observations, a recent ground-based upper limit for the K-band day side flux allows one to estimate the day-to-night energy redistribution efficiency to be ~ 43%.",Physics
"We consider the quantum Hall effect of two-dimensional electrons with a periodic potential and study the time dependence of the Hall and longitudinal currents when the electric field is applied abruptly. We find that the currents oscillate in time with very large frequencies because of quantum fluctuation and the oscillations eventually vanish, for their amplitudes decay as 1/t.",Physics
"A laser-based angle resolved photoemission (APRES) system utilizing 6 eV photons from the fourth harmonic of a mode-locked Ti:sapphire oscillator is described. This light source greatly increases the momentum resolution and photoelectron count rate, while reducing extrinsic background and surface sensitivity relative to higher energy light sources. In this review, the optical system is described, and special experimental considerations for low-energy ARPES are discussed. The calibration of the hemispherical electron analyzer for good low-energy angle-mode performance is also described. Finally, data from the heavily studied high T_c superconductor Bi2Sr2CaCu2O8+\delta (Bi2212) is compared to the results from higher photon energies.",Physics
"Aims. Taking account of steady flow in solar prominences, we study its effects on spatial damping of small-amplitude non-adiabatic magnetoacoustic waves in a homogeneous, isothermal, and unbounded prominence plasma. Methods. We model the typical feature of observed damped oscillatory motion in prominences, removing the adiabaticity assumption through thermal conduction, radiation and heating. Invoking steady flow in MHD equations, we linearise them under small-amplitude approximation and obtain a new general dispersion relation for linear non-adiabatic magnetoacoustic waves in prominences Results. The presence of steady flow breaks the symmetry of forward and backward propagating MHD wave modes in prominences. The steady flow has dramatic influence on the propagation and damping of magnetoacoustic and thermal waves. Depending upon the direction and strength of flow the magnetoacoustic and thermal modes can show both the features of wave amplification and damping. At the wave period of 5 min where the photospheric power is maximum, the slow mode shows wave amplification. However, in the absence of steady flow the slow mode wave shows damping. Conclusions. For the wave period between 5 min and 15 min, the amplification length for slow mode, in the case of prominence regime 1.1, varies between 3.4*10^11 m to 2*10^12 m. Dramatic influence of steady flow on small-amplitude prominence oscillations is likely to play an important role in both wave detection and prominence seismology.",Physics
"We report low-temperature resistance measurements in a modulation-doped, (311)A GaAs two-dimensional hole system as a function of applied in-plane strain. The data reveal a strong but anisotropic piezoresistance whose magnitude depends on the density as well as the direction along which the resistance is measured. At a density of $1.6\times10^{11}$ cm$^{-2}$ and for a strain of about $2\times10^{-4}$ applied along [01$\bar{1}$], e.g., the resistance measured along this direction changes by nearly a factor of two while the resistance change in the [$\bar{2}$33] direction is less than 10% and has the opposite sign. Our accurate energy band calculations indicate a pronounced and anisotropic deformation of the heavy-hole dispersion with strain, qualitatively consistent with the experimental data. The extremely anisotropic magnitude of the piezoresistance, however, lacks a quantitative explanation.",Physics
"We study the energetic and dynamic stability of coreless vortices in nonrotated spin-1 Bose-Einstein condensates, trapped with a three-dimensional optical potential and a Ioffe-Pritchard field. The stability of stationary vortex states is investigated by solving the corresponding Bogoliubov equations. We show that the quasiparticle excitations corresponding to axisymmetric stationary states can be taken to be eigenstates of angular momentum in the axial direction. Our results show that coreless vortex states can occur as local or global minima of the condensate energy or become energetically or dynamically unstable depending on the parameters of the Ioffe-Pritchard field. The experimentally most relevant coreless vortex state containing a doubly quantized vortex in one of the hyperfine spin components turned out to have very non-trivial stability regions, and especially a quasiperiodic dynamic instability region which corresponds to splitting of the doubly quantized vortex.",Physics
We calculate the superfluid transition temperature of homogeneous interacting Bose gases in three and two spatial dimensions using large-scale Path Integral Monte Carlo simulations (with up to $N=10^5$ particles). In 3D we investigate the limits of the universal critical behavior in terms of the scattering length alone by using different models for the interatomic potential. We find that this type of universality sets in at small values of the gas parameter $na^3 \lesssim 10^{-4}$. This value is different from the estimate $na^3 \lesssim 10^{-6}$ for the validity of the asymptotic expansion in the limit of vanishing $na^3$. In 2D we study the Berezinskii-Kosterlitz-Thouless transition of a gas with hard-core interactions. For this system we find good agreement with the classical lattice $|\psi|^4$ model up to very large densities. We also explain the origin of the existing discrepancy between previous studies of the same problem.,Physics
"Our goal is to characterize AGN populations by comparing their X-ray and optical classifications. We present a sample of 99 spectroscopically identified X-ray point sources in the XMM-LSS survey which are significantly detected in the [2-10] keV band, and with more than 80 counts. We performed an X-ray spectral analysis for all of these 99 X-ray sources. Introducing the fourfold point correlation coefficient, we find only a mild correlation between the X-ray and the optical classifications, as up to 30% of the sources have differing X-ray and optical classifications: on one hand, 10% of the type 1 sources present broad emission lines in their optical spectra and strong absorption in the X-rays. These objects are highly luminous AGN lying at high redshift and thus dilution effects are totally ruled out, their discrepant nature being an intrinsic property. Their X-ray luminosities and redshifts distributions are consistent with those of the unabsorbed X-ray sources with broad emission lines. On the other hand, 25/32 are moderate luminosity AGN, which are both unabsorbed in the X-rays and only present narrow emission lines in their optical spectra. The majority of them have an optical spectrum which is representative of the host galaxy. We finally infer that dilution of the AGN by the host galaxy seems to account for their nature. 5/25 have been defined as Seyfert 2. In conclusion, most of these 32 discrepant cases can be accounted for by the standard AGN unified scheme, as its predictions are not met for only 12% of the 99 X-ray sources. ABRIDGED",Physics
"The recent surge in the network modeling of complex systems has set the stage for a new era in the study of fundamental and applied aspects of optimization in collective behavior. This Focus Issue presents an extended view of the state of the art in this field and includes articles from a large variety of domains where optimization manifests itself, including physical, biological, social, and technological networked systems.",Physics
"We compare stellar models produced by different stellar evolution codes for the CoRoT/ESTA project, comparing their global quantities, their physical structure, and their oscillation properties. We discuss the differences between models and identify the underlying reasons for these differences. The stellar models are representative of potential CoRoT targets. Overall we find very good agreement between the five different codes, but with some significant deviations. We find noticeable discrepancies (though still at the per cent level) that result from the handling of the equation of state, of the opacities and of the convective boundaries. The results of our work will be helpful in interpreting future asteroseismology results from CoRoT.",Physics
"(abridged) We utilize existing imaging and spectroscopic data for the galaxy clusters MS2137-23 and Abell 383 to present improved measures of the distribution of dark and baryonic material in the clusters' central regions. Our method, based on the combination of gravitational lensing and dynamical data, is uniquely capable of separating the distribution of dark and baryonic components at scales below 100 kpc. We find a variety of strong lensing models fit the available data, including some with dark matter profiles as steep as expected from recent simulations. However, when combined with stellar velocity dispersion data for the brightest member, shallower inner slopes than predicted by numerical simulations are preferred. For Abell 383, the preferred shallow inner slopes are statistically a good fit only when the multiple image position uncertainties associated with our lens model are assumed to be 0\farcs5, to account for unknown substructure. No statistically satisfactory fit was obtained matching both the multiple image lensing data and the velocity dispersion profile of the brightest cluster galaxy in MS2137-23. This suggests that the mass model we are using, which comprises a pseudo-elliptical generalized NFW profile and a brightest cluster galaxy component may inadequately represent the inner cluster regions. This may plausibly arise due to halo triaxiality or by the gravitational interaction of baryons and dark matter in cluster cores. However, the progress made via this detailed study highlights the key role that complementary observations of lensed features and stellar dynamics offer in understanding the interaction between dark and baryonic matter on non-linear scales in the central regions of clusters.",Physics
"We describe a sample of thermally emitting neutron stars discovered in the ROSAT All-Sky Survey. We discuss the basic observational properties of these objects and conclude that they are nearby, middle-aged pulsars with moderate magnetic fields that we see through their cooling radiation. While these objects are potentially very useful as probes of matter at very high densities and magnetic fields, our lack of understanding of their surface emission limits their current utility. We discuss this and other outstanding problems: the spectral evolution of one sources and the relation of this population to the overall pulsar population.",Physics
"We present a new technique for detecting scattered starlight from transiting, close-orbiting extrasolar giant planets (CEGPs) that has the virtues of simplicity, robustness, linearity, and model-independence. Given a series of stellar spectra obtained over various phases of the planetary orbit, the goal is to measure the strength of the component scattered by the planet relative to the component coming directly from the star. We use two complementary strategies, both of which rely on the predictable Doppler shifts of both components and on combining the results from many spectral lines and many exposures. In the first strategy, we identify segments of the stellar spectrum that are free of direct absorption lines and add them after Doppler-shifting into the planetary frame. In the second strategy, we compare the distribution of equivalent-width ratios of the scattered and direct components. Both strategies are calibrated with a ``null test'' in which scrambled Doppler shifts are applied to the spectral segments. As an illustrative test case, we apply our technique to spectra of HD 209458 taken when the planet was near opposition (with orbital phases ranging from 11 to 34$\arcdeg$, where 0$\arcdeg$ is at opposition), finding that the planet-to-star flux ratio is $(1.4 \pm 2.9)\times10^{-4}$ in the wavelength range 554$-$681 nm. This corresponds to a geometric albedo of $0.8 \pm 1.6$, assuming the phase function of a Lambert sphere. Although the result is not statistically significant, the achieved sensitivity and relatively small volume of data upon which it is based are very encouraging for future ground-based spectroscopic studies of scattered light from transiting CEGP systems.",Physics
This study investigates the catalytic properties of novel transition metal complexes for sustainable chemical reactions.,Chemistry
We explore the synthesis and characterization of organic molecules with potential applications in pharmaceuticals.,Chemistry
The effect of pH on the enzymatic activity in aqueous solutions was examined using spectroscopic methods.,Chemistry
A new approach for the selective oxidation of alcohols catalyzed by metal-organic frameworks is presented.,Chemistry
Thermodynamic properties of ionic liquids and their potential use as green solvents are analyzed.,Chemistry
The photochemical behavior of photosensitizers in solar energy conversion devices was evaluated.,Chemistry
Synthesis of nanoparticles with controlled size and morphology for drug delivery systems is discussed.,Chemistry
We report the use of electrochemical methods to investigate corrosion resistance in metal alloys.,Chemistry
The interaction between polymers and metal ions in aqueous media was studied to design better filtration membranes.,Chemistry
Development of novel fluorescent probes for detecting heavy metals in environmental samples is described.,Chemistry
This study investigates the catalytic properties of novel transition metal complexes for sustainable chemical reactions.,Chemistry
We explore the synthesis and characterization of organic molecules with potential applications in pharmaceuticals.,Chemistry
The effect of pH on the enzymatic activity in aqueous solutions was examined using spectroscopic methods.,Chemistry
A new approach for the selective oxidation of alcohols catalyzed by metal-organic frameworks is presented.,Chemistry
Thermodynamic properties of ionic liquids and their potential use as green solvents are analyzed.,Chemistry
The photochemical behavior of photosensitizers in solar energy conversion devices was evaluated.,Chemistry
Synthesis of nanoparticles with controlled size and morphology for drug delivery systems is discussed.,Chemistry
We report the use of electrochemical methods to investigate corrosion resistance in metal alloys.,Chemistry
The interaction between polymers and metal ions in aqueous media was studied to design better filtration membranes.,Chemistry
Development of novel fluorescent probes for detecting heavy metals in environmental samples is described.,Chemistry
This study investigates the catalytic properties of novel transition metal complexes for sustainable chemical reactions.,Chemistry
We explore the synthesis and characterization of organic molecules with potential applications in pharmaceuticals.,Chemistry
The effect of pH on the enzymatic activity in aqueous solutions was examined using spectroscopic methods.,Chemistry
A new approach for the selective oxidation of alcohols catalyzed by metal-organic frameworks is presented.,Chemistry
Thermodynamic properties of ionic liquids and their potential use as green solvents are analyzed.,Chemistry
The photochemical behavior of photosensitizers in solar energy conversion devices was evaluated.,Chemistry
Synthesis of nanoparticles with controlled size and morphology for drug delivery systems is discussed.,Chemistry
We report the use of electrochemical methods to investigate corrosion resistance in metal alloys.,Chemistry
The interaction between polymers and metal ions in aqueous media was studied to design better filtration membranes.,Chemistry
Development of novel fluorescent probes for detecting heavy metals in environmental samples is described.,Chemistry
This study investigates the catalytic properties of novel transition metal complexes for sustainable chemical reactions.,Chemistry
We explore the synthesis and characterization of organic molecules with potential applications in pharmaceuticals.,Chemistry
The effect of pH on the enzymatic activity in aqueous solutions was examined using spectroscopic methods.,Chemistry
A new approach for the selective oxidation of alcohols catalyzed by metal-organic frameworks is presented.,Chemistry
Thermodynamic properties of ionic liquids and their potential use as green solvents are analyzed.,Chemistry
The photochemical behavior of photosensitizers in solar energy conversion devices was evaluated.,Chemistry
Synthesis of nanoparticles with controlled size and morphology for drug delivery systems is discussed.,Chemistry
We report the use of electrochemical methods to investigate corrosion resistance in metal alloys.,Chemistry
The interaction between polymers and metal ions in aqueous media was studied to design better filtration membranes.,Chemistry
Development of novel fluorescent probes for detecting heavy metals in environmental samples is described.,Chemistry
This study investigates the catalytic properties of novel transition metal complexes for sustainable chemical reactions.,Chemistry
We explore the synthesis and characterization of organic molecules with potential applications in pharmaceuticals.,Chemistry
The effect of pH on the enzymatic activity in aqueous solutions was examined using spectroscopic methods.,Chemistry
A new approach for the selective oxidation of alcohols catalyzed by metal-organic frameworks is presented.,Chemistry
Thermodynamic properties of ionic liquids and their potential use as green solvents are analyzed.,Chemistry
The photochemical behavior of photosensitizers in solar energy conversion devices was evaluated.,Chemistry
Synthesis of nanoparticles with controlled size and morphology for drug delivery systems is discussed.,Chemistry
We report the use of electrochemical methods to investigate corrosion resistance in metal alloys.,Chemistry
The interaction between polymers and metal ions in aqueous media was studied to design better filtration membranes.,Chemistry
Development of novel fluorescent probes for detecting heavy metals in environmental samples is described.,Chemistry
This study investigates the catalytic properties of novel transition metal complexes for sustainable chemical reactions.,Chemistry
We explore the synthesis and characterization of organic molecules with potential applications in pharmaceuticals.,Chemistry
The effect of pH on the enzymatic activity in aqueous solutions was examined using spectroscopic methods.,Chemistry
A new approach for the selective oxidation of alcohols catalyzed by metal-organic frameworks is presented.,Chemistry
Thermodynamic properties of ionic liquids and their potential use as green solvents are analyzed.,Chemistry
The photochemical behavior of photosensitizers in solar energy conversion devices was evaluated.,Chemistry
Synthesis of nanoparticles with controlled size and morphology for drug delivery systems is discussed.,Chemistry
We report the use of electrochemical methods to investigate corrosion resistance in metal alloys.,Chemistry
The interaction between polymers and metal ions in aqueous media was studied to design better filtration membranes.,Chemistry
Development of novel fluorescent probes for detecting heavy metals in environmental samples is described.,Chemistry
This study investigates the catalytic properties of novel transition metal complexes for sustainable chemical reactions.,Chemistry
We explore the synthesis and characterization of organic molecules with potential applications in pharmaceuticals.,Chemistry
The effect of pH on the enzymatic activity in aqueous solutions was examined using spectroscopic methods.,Chemistry
A new approach for the selective oxidation of alcohols catalyzed by metal-organic frameworks is presented.,Chemistry
Thermodynamic properties of ionic liquids and their potential use as green solvents are analyzed.,Chemistry
The photochemical behavior of photosensitizers in solar energy conversion devices was evaluated.,Chemistry
Synthesis of nanoparticles with controlled size and morphology for drug delivery systems is discussed.,Chemistry
We report the use of electrochemical methods to investigate corrosion resistance in metal alloys.,Chemistry
The interaction between polymers and metal ions in aqueous media was studied to design better filtration membranes.,Chemistry
Development of novel fluorescent probes for detecting heavy metals in environmental samples is described.,Chemistry
This study investigates the catalytic properties of novel transition metal complexes for sustainable chemical reactions.,Chemistry
We explore the synthesis and characterization of organic molecules with potential applications in pharmaceuticals.,Chemistry
The effect of pH on the enzymatic activity in aqueous solutions was examined using spectroscopic methods.,Chemistry
A new approach for the selective oxidation of alcohols catalyzed by metal-organic frameworks is presented.,Chemistry
Thermodynamic properties of ionic liquids and their potential use as green solvents are analyzed.,Chemistry
The photochemical behavior of photosensitizers in solar energy conversion devices was evaluated.,Chemistry
Synthesis of nanoparticles with controlled size and morphology for drug delivery systems is discussed.,Chemistry
We report the use of electrochemical methods to investigate corrosion resistance in metal alloys.,Chemistry
The interaction between polymers and metal ions in aqueous media was studied to design better filtration membranes.,Chemistry
Development of novel fluorescent probes for detecting heavy metals in environmental samples is described.,Chemistry
This study investigates the catalytic properties of novel transition metal complexes for sustainable chemical reactions.,Chemistry
We explore the synthesis and characterization of organic molecules with potential applications in pharmaceuticals.,Chemistry
The effect of pH on the enzymatic activity in aqueous solutions was examined using spectroscopic methods.,Chemistry
A new approach for the selective oxidation of alcohols catalyzed by metal-organic frameworks is presented.,Chemistry
Thermodynamic properties of ionic liquids and their potential use as green solvents are analyzed.,Chemistry
The photochemical behavior of photosensitizers in solar energy conversion devices was evaluated.,Chemistry
Synthesis of nanoparticles with controlled size and morphology for drug delivery systems is discussed.,Chemistry
We report the use of electrochemical methods to investigate corrosion resistance in metal alloys.,Chemistry
The interaction between polymers and metal ions in aqueous media was studied to design better filtration membranes.,Chemistry
Development of novel fluorescent probes for detecting heavy metals in environmental samples is described.,Chemistry
This study investigates the catalytic properties of novel transition metal complexes for sustainable chemical reactions.,Chemistry
We explore the synthesis and characterization of organic molecules with potential applications in pharmaceuticals.,Chemistry
The effect of pH on the enzymatic activity in aqueous solutions was examined using spectroscopic methods.,Chemistry
A new approach for the selective oxidation of alcohols catalyzed by metal-organic frameworks is presented.,Chemistry
Thermodynamic properties of ionic liquids and their potential use as green solvents are analyzed.,Chemistry
The photochemical behavior of photosensitizers in solar energy conversion devices was evaluated.,Chemistry
Synthesis of nanoparticles with controlled size and morphology for drug delivery systems is discussed.,Chemistry
We report the use of electrochemical methods to investigate corrosion resistance in metal alloys.,Chemistry
The interaction between polymers and metal ions in aqueous media was studied to design better filtration membranes.,Chemistry
Development of novel fluorescent probes for detecting heavy metals in environmental samples is described.,Chemistry
This study investigates the catalytic properties of novel transition metal complexes for sustainable chemical reactions.,Chemistry
We explore the synthesis and characterization of organic molecules with potential applications in pharmaceuticals.,Chemistry
The effect of pH on the enzymatic activity in aqueous solutions was examined using spectroscopic methods.,Chemistry
A new approach for the selective oxidation of alcohols catalyzed by metal-organic frameworks is presented.,Chemistry
Thermodynamic properties of ionic liquids and their potential use as green solvents are analyzed.,Chemistry
The photochemical behavior of photosensitizers in solar energy conversion devices was evaluated.,Chemistry
Synthesis of nanoparticles with controlled size and morphology for drug delivery systems is discussed.,Chemistry
We report the use of electrochemical methods to investigate corrosion resistance in metal alloys.,Chemistry
The interaction between polymers and metal ions in aqueous media was studied to design better filtration membranes.,Chemistry
Development of novel fluorescent probes for detecting heavy metals in environmental samples is described.,Chemistry
This study investigates the catalytic properties of novel transition metal complexes for sustainable chemical reactions.,Chemistry
We explore the synthesis and characterization of organic molecules with potential applications in pharmaceuticals.,Chemistry
The effect of pH on the enzymatic activity in aqueous solutions was examined using spectroscopic methods.,Chemistry
A new approach for the selective oxidation of alcohols catalyzed by metal-organic frameworks is presented.,Chemistry
Thermodynamic properties of ionic liquids and their potential use as green solvents are analyzed.,Chemistry
The photochemical behavior of photosensitizers in solar energy conversion devices was evaluated.,Chemistry
Synthesis of nanoparticles with controlled size and morphology for drug delivery systems is discussed.,Chemistry
We report the use of electrochemical methods to investigate corrosion resistance in metal alloys.,Chemistry
The interaction between polymers and metal ions in aqueous media was studied to design better filtration membranes.,Chemistry
Development of novel fluorescent probes for detecting heavy metals in environmental samples is described.,Chemistry
This study investigates the catalytic properties of novel transition metal complexes for sustainable chemical reactions.,Chemistry
We explore the synthesis and characterization of organic molecules with potential applications in pharmaceuticals.,Chemistry
The effect of pH on the enzymatic activity in aqueous solutions was examined using spectroscopic methods.,Chemistry
A new approach for the selective oxidation of alcohols catalyzed by metal-organic frameworks is presented.,Chemistry
Thermodynamic properties of ionic liquids and their potential use as green solvents are analyzed.,Chemistry
The photochemical behavior of photosensitizers in solar energy conversion devices was evaluated.,Chemistry
Synthesis of nanoparticles with controlled size and morphology for drug delivery systems is discussed.,Chemistry
We report the use of electrochemical methods to investigate corrosion resistance in metal alloys.,Chemistry
The interaction between polymers and metal ions in aqueous media was studied to design better filtration membranes.,Chemistry
Development of novel fluorescent probes for detecting heavy metals in environmental samples is described.,Chemistry
This study investigates the catalytic properties of novel transition metal complexes for sustainable chemical reactions.,Chemistry
We explore the synthesis and characterization of organic molecules with potential applications in pharmaceuticals.,Chemistry
The effect of pH on the enzymatic activity in aqueous solutions was examined using spectroscopic methods.,Chemistry
A new approach for the selective oxidation of alcohols catalyzed by metal-organic frameworks is presented.,Chemistry
Thermodynamic properties of ionic liquids and their potential use as green solvents are analyzed.,Chemistry
The photochemical behavior of photosensitizers in solar energy conversion devices was evaluated.,Chemistry
Synthesis of nanoparticles with controlled size and morphology for drug delivery systems is discussed.,Chemistry
We report the use of electrochemical methods to investigate corrosion resistance in metal alloys.,Chemistry
The interaction between polymers and metal ions in aqueous media was studied to design better filtration membranes.,Chemistry
Development of novel fluorescent probes for detecting heavy metals in environmental samples is described.,Chemistry
This study investigates the catalytic properties of novel transition metal complexes for sustainable chemical reactions.,Chemistry
We explore the synthesis and characterization of organic molecules with potential applications in pharmaceuticals.,Chemistry
The effect of pH on the enzymatic activity in aqueous solutions was examined using spectroscopic methods.,Chemistry
A new approach for the selective oxidation of alcohols catalyzed by metal-organic frameworks is presented.,Chemistry
Thermodynamic properties of ionic liquids and their potential use as green solvents are analyzed.,Chemistry
The photochemical behavior of photosensitizers in solar energy conversion devices was evaluated.,Chemistry
Synthesis of nanoparticles with controlled size and morphology for drug delivery systems is discussed.,Chemistry
We report the use of electrochemical methods to investigate corrosion resistance in metal alloys.,Chemistry
The interaction between polymers and metal ions in aqueous media was studied to design better filtration membranes.,Chemistry
Development of novel fluorescent probes for detecting heavy metals in environmental samples is described.,Chemistry
This study investigates the catalytic properties of novel transition metal complexes for sustainable chemical reactions.,Chemistry
We explore the synthesis and characterization of organic molecules with potential applications in pharmaceuticals.,Chemistry
The effect of pH on the enzymatic activity in aqueous solutions was examined using spectroscopic methods.,Chemistry
A new approach for the selective oxidation of alcohols catalyzed by metal-organic frameworks is presented.,Chemistry
Thermodynamic properties of ionic liquids and their potential use as green solvents are analyzed.,Chemistry
The photochemical behavior of photosensitizers in solar energy conversion devices was evaluated.,Chemistry
Synthesis of nanoparticles with controlled size and morphology for drug delivery systems is discussed.,Chemistry
We report the use of electrochemical methods to investigate corrosion resistance in metal alloys.,Chemistry
The interaction between polymers and metal ions in aqueous media was studied to design better filtration membranes.,Chemistry
Development of novel fluorescent probes for detecting heavy metals in environmental samples is described.,Chemistry
This study investigates the catalytic properties of novel transition metal complexes for sustainable chemical reactions.,Chemistry
We explore the synthesis and characterization of organic molecules with potential applications in pharmaceuticals.,Chemistry
The effect of pH on the enzymatic activity in aqueous solutions was examined using spectroscopic methods.,Chemistry
A new approach for the selective oxidation of alcohols catalyzed by metal-organic frameworks is presented.,Chemistry
Thermodynamic properties of ionic liquids and their potential use as green solvents are analyzed.,Chemistry
The photochemical behavior of photosensitizers in solar energy conversion devices was evaluated.,Chemistry
Synthesis of nanoparticles with controlled size and morphology for drug delivery systems is discussed.,Chemistry
We report the use of electrochemical methods to investigate corrosion resistance in metal alloys.,Chemistry
The interaction between polymers and metal ions in aqueous media was studied to design better filtration membranes.,Chemistry
Development of novel fluorescent probes for detecting heavy metals in environmental samples is described.,Chemistry
This study investigates the catalytic properties of novel transition metal complexes for sustainable chemical reactions.,Chemistry
We explore the synthesis and characterization of organic molecules with potential applications in pharmaceuticals.,Chemistry
The effect of pH on the enzymatic activity in aqueous solutions was examined using spectroscopic methods.,Chemistry
A new approach for the selective oxidation of alcohols catalyzed by metal-organic frameworks is presented.,Chemistry
Thermodynamic properties of ionic liquids and their potential use as green solvents are analyzed.,Chemistry
The photochemical behavior of photosensitizers in solar energy conversion devices was evaluated.,Chemistry
Synthesis of nanoparticles with controlled size and morphology for drug delivery systems is discussed.,Chemistry
We report the use of electrochemical methods to investigate corrosion resistance in metal alloys.,Chemistry
The interaction between polymers and metal ions in aqueous media was studied to design better filtration membranes.,Chemistry
Development of novel fluorescent probes for detecting heavy metals in environmental samples is described.,Chemistry
This study investigates the catalytic properties of novel transition metal complexes for sustainable chemical reactions.,Chemistry
We explore the synthesis and characterization of organic molecules with potential applications in pharmaceuticals.,Chemistry
The effect of pH on the enzymatic activity in aqueous solutions was examined using spectroscopic methods.,Chemistry
A new approach for the selective oxidation of alcohols catalyzed by metal-organic frameworks is presented.,Chemistry
Thermodynamic properties of ionic liquids and their potential use as green solvents are analyzed.,Chemistry
The photochemical behavior of photosensitizers in solar energy conversion devices was evaluated.,Chemistry
Synthesis of nanoparticles with controlled size and morphology for drug delivery systems is discussed.,Chemistry
We report the use of electrochemical methods to investigate corrosion resistance in metal alloys.,Chemistry
The interaction between polymers and metal ions in aqueous media was studied to design better filtration membranes.,Chemistry
Development of novel fluorescent probes for detecting heavy metals in environmental samples is described.,Chemistry
This study investigates the catalytic properties of novel transition metal complexes for sustainable chemical reactions.,Chemistry
We explore the synthesis and characterization of organic molecules with potential applications in pharmaceuticals.,Chemistry
The effect of pH on the enzymatic activity in aqueous solutions was examined using spectroscopic methods.,Chemistry
A new approach for the selective oxidation of alcohols catalyzed by metal-organic frameworks is presented.,Chemistry
Thermodynamic properties of ionic liquids and their potential use as green solvents are analyzed.,Chemistry
The photochemical behavior of photosensitizers in solar energy conversion devices was evaluated.,Chemistry
Synthesis of nanoparticles with controlled size and morphology for drug delivery systems is discussed.,Chemistry
We report the use of electrochemical methods to investigate corrosion resistance in metal alloys.,Chemistry
The interaction between polymers and metal ions in aqueous media was studied to design better filtration membranes.,Chemistry
Development of novel fluorescent probes for detecting heavy metals in environmental samples is described.,Chemistry
